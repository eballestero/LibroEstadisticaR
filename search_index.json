[["index.html", "", " Elementos de Estad√≠stica Inferencial con R Autor: M.Sc. Esteban Ballestero Alfaro Fecha de publicaci√≥n: 30 de octubre de 2024 "],["introduccion.html", "Introduccion", " Introduccion Este libro contempla un compendio de herramientas disponibles en el lenguaje R esenciales para el an√°lisis de datos usando estad√≠stica inferencial. El material contempla tanto los elementos te√≥ricos b√°sicos priorizando la programaci√≥n para trabajar las diferentes pruebas estad√≠sticas en R, por lo que si el lector desea profundizar m√°s en la teor√≠a deber√° complementar este material con alg√∫n otro libro de su preferencia disponible en el mercado. Adicionalmente en cada una de las secciones el lector tendr√° acceso a ejemplos pr√°cticos resueltos y en algunos casos se dejan algunos ejercicios de car√°cter recomendativo para el lector, por si desea practicar por su cuenta y reforzar lo aprendido. Los temas que se abordan van desde los intervalos de confianza, pasando por las pruebas param√©tricas b√°sicas para medias, varianzas y proporciones, otras pruebas de hip√≥tesis como ANOVA y Tukey, bondad de ajuste o prueba de normalidad, prueba de independencia, modelos de regresi√≥n lineal y no lineal simple y m√∫ltiple, as√≠ como otras herramientas que ofrece R de gran utilidad que complementan el an√°lisis de datos. Es importarte indicarle al lector que las bases de datos utilizadas son de uso libre y en su mayor√≠a se encuentran disponibles en la suite de R. Este material est√° recomendado para aquellos estudiantes de las carreras de Ingenier√≠a en Computaci√≥n o Computadores que toman el curso de Estad√≠stica, sin embargo, puede ser de utilidad a cualquier usuario que desee aprender a dise√±ar este tipo de pruebas param√©tricas en sus an√°lisis de datos. Finalmente, quisiera agradecer al estudiante Isaac Ram√≠rez Rojas de la carrera de Ingenier√≠a en del Tecnol√≥gico de Costa Rica, Computaci√≥n del Campus Tecnol√≥gico Local San Carlos, por su colaboraci√≥n con el mejoramiento de algunos objetos como tablas y ecuaciones usando LateX, as√≠ como su asesor√≠a para que este libro fuese publicado en l√≠nea usando GitHub y la librer√≠a Bookdown de R. Sobre el autor El M.Sc. Esteban Ballestero Alfaro tiene formaci√≥n en Ense√±anza de la Matem√°tica y es acad√©mico, investigador y extensionista de la Escuela de Ciencias Naturales y Exactas del Instituto Tecnol√≥gico de Costa Rica, Campus Tecnol√≥gico Local San Carlos. Para contactar al autor puede escribir al correo eballestero@itcr.ac.cr "],["cargar-chunks.html", "Cap√≠tulo 1 Cargar Chunks", " Cap√≠tulo 1 Cargar Chunks Se inicia primeramente con un chunk para cargar las librer√≠as a utilizar, esto dar√° m√°s orden al documento. library(epitools) library(EnvStats) library(PASWR2) Este documento se dividir√° en dos secciones Casos para una poblaci√≥n Casos para dos poblaciones "],["i-parte-casos-para-una-poblacion.html", "Cap√≠tulo 2 I Parte: Casos para una poblacion 2.1 Simulacion de Intervalos de Confianza 2.2 Intervalos de confianza para el parameto p 2.3 Intervalo de confianza para la varianza de una poblacion normal", " Cap√≠tulo 2 I Parte: Casos para una poblacion 2.1 Simulacion de Intervalos de Confianza Se presenta ene esta secci√≥n, dos formas de simular Intervalos de Confianza (IC)El primero sigue un procedimiento m√°s rudimentario mienstras que la segunda opci√≥n se apoya en el paquete PASWR2 2.1.1 M√©todo de simulacion: Ejemplo 1 El siguiente ejemplo simula el funcionamiento de una IC para una distribuci√≥n normal. Consideramos una poblaci√≥n de 106 valores de una distribuci√≥n normal de par√°metros ùúá = 1.5 y ùúé = 1 : set.seed(1012) mu = 1.5; sigma = 1; alpha = 0.05 Poblacion = rnorm(10^6,mu,sigma) Notas: Si desea indagar m√°s sobre el uso del set.seed Seguidamente se generar√°n 100 muestras aleatorias simples de tama√±o 50, tomadas de la poblaci√≥n que se gener√≥ en el chunk anterior. ¬øQu√© se desea hacer con este muestreo? Generar un IC de 100(1-ùõº)% para ùúá para cada muestra. El siguiente c√≥digo crea una funci√≥n llamada ICZ que recibe los siguientes par√°metros: x: una muestra ùúé: desviaci√≥n est√°ndar ùõº: nivel de significancia ICZ &lt;- function(x, sigma, alpha){ c(mean(x) - qnorm(1-alpha/2)*sigma/sqrt(length(x)), mean(x) + qnorm(1-alpha/2)*sigma/sqrt(length(x)))} Usando la funci√≥n replicate de R generamos las muestras y los intervalos de confianza correspondientes usando la funci√≥n anterior: set.seed(2) muestra &lt;- sample(Poblacion, 50, replace = TRUE) str(muestra) ## num [1:50] 0.398 0.689 1.908 2.557 1.408 ... # num [1:50] 0.398 0.689 1.908 2.557 1.408 ... is.vector(muestra) ## [1] TRUE # [1] TRUE M &lt;- replicate(100, ICZ(sample(Poblacion, 50, replace = TRUE), sigma, alpha)) head(M, 1) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 1.158639 0.9551632 1.163733 1.207061 1.438323 1.308961 1.132598 1.050715 ## [,9] [,10] [,11] [,12] [,13] [,14] [,15] [,16] ## [1,] 1.280404 1.128913 1.054624 1.267924 1.110896 1.032606 0.9982519 1.380336 ## [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] ## [1,] 1.343976 0.9937222 1.287343 1.256967 1.063256 1.254104 1.134304 1.059416 ## [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32] ## [1,] 1.435412 1.212106 1.226458 1.223806 1.367424 1.088419 1.124183 1.389883 ## [,33] [,34] [,35] [,36] [,37] [,38] [,39] [,40] ## [1,] 1.314201 1.37684 1.306192 1.313516 1.075487 1.322901 1.364241 1.266041 ## [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] ## [1,] 1.185282 1.326725 1.282097 1.186015 0.8513774 1.21528 1.171624 0.9881411 ## [,49] [,50] [,51] [,52] [,53] [,54] [,55] [,56] ## [1,] 1.066967 1.436479 1.22599 1.054768 1.153213 1.478074 1.308575 1.090102 ## [,57] [,58] [,59] [,60] [,61] [,62] [,63] [,64] ## [1,] 1.304404 1.559555 1.181725 1.476088 1.421307 1.007944 1.176594 1.199082 ## [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] ## [1,] 1.220058 0.8194457 1.045293 1.343846 1.050605 1.257333 1.418103 1.134102 ## [,73] [,74] [,75] [,76] [,77] [,78] [,79] [,80] ## [1,] 1.773727 1.401352 1.293367 1.219326 1.056869 1.12021 1.025071 1.315759 ## [,81] [,82] [,83] [,84] [,85] [,86] [,87] [,88] ## [1,] 1.33369 1.240511 1.124048 1.341988 1.098884 1.52107 0.9612357 0.9459889 ## [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] ## [1,] 1.127343 1.177512 1.365101 1.007279 1.125135 1.066962 1.351357 1.032938 ## [,97] [,98] [,99] [,100] ## [1,] 1.190949 1.228983 1.272383 1.319815 # [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62] [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74] [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82] [,83] [,84] [,85] [,86] [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] [,97] [,98] [,99] [,100] # [1,] 1.158639 0.9551632 1.163733 1.207061 1.438323 1.308961 1.132598 1.050715 1.280404 1.128913 1.054624 1.267924 1.110896 1.032606 0.9982519 1.380336 1.343976 0.9937222 1.287343 1.256967 1.063256 1.254104 1.134304 1.059416 1.435412 1.212106 1.226458 1.223806 1.367424 1.088419 1.124183 1.389883 1.314201 1.37684 1.306192 1.313516 1.075487 1.322901 1.364241 1.266041 1.185282 1.326725 1.282097 1.186015 0.8513774 1.21528 1.171624 0.9881411 1.066967 1.436479 1.22599 1.054768 1.153213 1.478074 1.308575 1.090102 1.304404 1.559555 1.181725 1.476088 1.421307 1.007944 1.176594 1.199082 1.220058 0.8194457 1.045293 1.343846 1.050605 1.257333 1.418103 1.134102 1.773727 1.401352 1.293367 1.219326 1.056869 1.12021 1.025071 1.315759 1.33369 1.240511 1.124048 1.341988 1.098884 1.52107 0.9612357 0.9459889 1.127343 1.177512 1.365101 1.007279 1.125135 1.066962 1.351357 1.032938 1.190949 1.228983 El objeto ùëÄ de ùëÖ es una matriz de 2 filas y 100 columnas donde la columna ùëñ ‚àí √©ùë†ùëñùëöùëé representa el intervalo de confianza para la ùëñ ‚àí √©ùë†ùëñùëöùëé muestra generada, es decir, en cada columna habr√° dos datos donde uno corresponde al extremo inferior del IC y el otro al extremo superior del IC. Finalmente se dibujar√°n todos los intervalos anteriores y se resaltar√° en color rojo aqu√©llos en los que el par√°metro ùúá = 1.5 no est√© en ellos. Se espera que haya aproximadamente 5 en los que esta condici√≥n falle. plot(1:10, type = &quot;n&quot;, xlim =c(1.2, 1.8), ylim = c(0, 100), xlab = &quot;Valores&quot;, ylab = &quot;Replicaciones&quot;) seg.int &lt;- function(i){color = &quot;grey&quot;; if((mu&lt; M[1,i]) | (mu &gt; M[2,i])){color = &quot;red&quot;} segments(M[1,i], i, M[2,i],i, col = color,lwd = 3)} invisible(sapply(1:100, FUN = seg.int)) abline(v = mu,lwd = 3) 2.1.2 M√©todo de simulaci√≥n: Ejemplo 2 El segudo m√©todo muestra como realizar simulaciones de Intervalos de Confianza de manera gr√°fica, usando el paquete PASWR2. Los requerimientos para usar la funci√≥n cisim, son los siguientes: Samples: N√∫mero de muestras deseadas. n: Tama√±o de cada muestra. Parameter: El valor del par√°metro poblacional. Esto est√° sujeto al Type (media, varianza o porporci√≥n). Para el caso de type = ‚Äúmean‚Äù o type = ‚ÄúVar‚Äù el valor puede ser cualquiera, pero si se usa proporci√≥n con type = ‚ÄúPi‚Äù, entonces el valor del par√°metro debe ser un valor entre 0 y 1. Sigma: Desviaci√≥n est√°ndar de la poblaci√≥n, En el caso de usar type =‚ÄúPi‚Äù, no se requiere indica este valor. conf.level: Intervalo de confianza es un valor entre 0 y 1. Si es de 90%, debe escribirlo como 0.90. Cuando este par√°metro se omite, R toma por defecto el IC de 95%. type: Es una variable tipo character string,que ademite los siguiente valores: ‚ÄúMean‚Äù para la media, ‚ÄúVar‚Äù para la varianza o ‚ÄúPi‚Äù para proporci√≥n (de forma alternativa, puede usar solo la primera letra en casad caso). Si no se coloca type en la instrucci√≥n, se asume por defecto type = ‚ÄúMean‚Äù. Ejemplo Simulaci√≥n de 100 muestras de tama√±o 30, con media 100 y desviaci√≥n est√°ndar de 10. El IC es de 90% #install.packages(&quot;PASWR2&quot;, dependencies = T) cisim(samples = 100, n = 30, parameter = 100, sigma = 10, conf.level = 0.90) ## ## 9% of the random confidence intervals do not contain Mu = 100. Ejemplo Simulaci√≥n de 100 muestras de tama√±o 50, para una porporci√≥n de 0.5. El IC es de 92% cisim(100, 50, 0.5, type = &quot;Pi&quot;, conf.level = 0.92) ## ## 4% of the random confidence intervals do not contain Pi = 0.5. Ejemplo Simulaci√≥n de 100 muestras de tama√±o 30, con varianza 100 y desviaci√≥n est√°ndar de 10. El IC 95% cisim(100, 30, 100, 10, type = &quot;Var&quot;) ## ## 6% of the random confidence intervals do not contain Var = 100. Ejemplo de procesador de Intel Queremos analizar un sensor que mide la temperatura de un procesador en grados cent√≠grados, en concreto un Intel Core i7-2600K, que tiene como temperatura normal de 32¬∞ a 40¬∞. Para saber si est√° bien calibrado, dise√±amos un experimento en el que ponemos el procesador en las mismas condiciones y tomamos una muestra de 40 valores de su temperatura. Suponga que las medidas del sensor siguen una distribuci√≥n normal con varianza conocida. Calcular el IC de 90% para el resultado medio de temperatura del procesador. temperatura &lt;- c(36,35,38,38,36,37,38,36,37,36, 37,37,34,38,35,37,36,36,34,38, 36,37,35,35,35,35,36,36,36,35, 36,35,34,34,37,37,35,36,34,36) ICtemp &lt;- ICZ(temperatura, sd(temperatura), 0.1) ICtemp ## [1] 35.66065 36.28935 ## [1] 35.66065 36.28935 Para el caso de temperatura de los procesadores, calcule el tama√±o de muestra para obtener una temperatura media con un error menor que 0.05¬∞ a un nivel de confianza de 90% ## Funci√≥n para calcular el tama√±o de muestra &quot;n&quot; n &lt;- function(radio,sigma,alpha){ ceiling(((qnorm(alpha/2)*sigma)/radio)^2)} n(0.05, sd(temperatura), 0.1) ## [1] 1582 ## [1] 1582 Ejemplo base de datos Iris Hallemos un intervalo de confianza de 95% para la media de la longitud del p√©talo para una muestra de 30 flores de la tabla de datos iris. Aunque bien, el tema√±o de la muestra es justo para aplicar una distribuci√≥n z, vamos a hacer el c√°lculo con t-Student set.seed(1000) muestra.iris &lt;- sample(1:150,30,replace = TRUE) long.petalo.muestra &lt;- iris[muestra.iris, ]$Petal.Length t.test(long.petalo.muestra,conf.level = 0.95)$conf.int ## [1] 2.986537 4.106796 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 ## [1] 2.986537 4.106796 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 2.1.3 Experimento con la ‚ÄúConfianza‚Äù Vamos a comprobar con un experimento qu√© papel juega la ‚Äúconfianza‚Äù en los intervalos de confianza. Vamos a generar al azar una Poblaci√≥n de 10 000 000 (107 ) ‚Äúindividuos‚Äù con distribuci√≥n normal est√°ndard. Se va a tomar 200 muestras aleatorias simples de tama√±o 50 de esta poblaci√≥n y se calcular√° el intervalo de confianza para la media poblacional usando dicha f√≥rmula. Finalmente, la idea es contar cu√°ntos de estos intervalos de confianza contienen la media poblacional. Se fijar√° la semilla de aleatoriedad para que el experimento sea reproducible. # Se genera la poblaci√≥n de valores set.seed(2020) valores.poblacion &lt;- rnorm(10^7) # Se calcula la media poblacional mu &lt;- mean(valores.poblacion) # Se toman 200 muestras usando la funci√≥n &quot;replicate&quot; de R, que permite ejecutar una misma funci√≥n las veces que se le indique muestras &lt;- replicate(200, sample(valores.poblacion, 50, replace = TRUE)) str(muestras) ## num [1:50, 1:200] 0.59 -0.192 0.346 -0.524 -0.283 ... ## num [1:50, 1:200] 0.59 -0.192 0.346 -0.524 -0.283 ... # Note que la variable muestras es una matriz de 50 filas por 200 columnas, donde cada una de las columnas representa una muestra u observaci√≥n. # Usando t.test para cada una de las muestras, se calcular√° un IC de 95%, para posteriormente contar los aciertos, es decir, cu√°ntos de ellos continenen a la media poblacional. # Se define la funci√≥n IC.t que nos da el IC para la media dada para una muestra IC.t &lt;- function(X, confianza = 0.95){ t.test(X, conf.level = confianza)$conf.int } ICs &lt;- apply(muestras, FUN = IC.t, MARGIN = 2) # Conteo de aciertos Aciertos &lt;- length(which((mu &gt;= ICs[1,]) &amp; (mu &lt;= ICs[2,]))) Aciertos ## [1] 195 ## [1] 195 Note que se ha acertado en 195 veces. o sea. un 97.5% de las veces, lo cual es una buena aproximaci√≥n del valor 95% que era el esperado. Seguidamente, se puede visualizar gr√°ficamente estos intervalos: plot(1, type = &quot;n&quot;, xlim = c(-0.8, 0.8), ylim = c(0, 200), xlab = &quot;Valores&quot;, ylab = &quot;Repeticiones&quot;, main = &quot;&quot;) seg.int &lt;- function(i) { color &lt;- &quot;light blue&quot; if ((mu &lt; ICs[1, i]) | (mu &gt; ICs[2, i])) { color &lt;- &quot;red&quot; } segments(ICs[1, i], i, ICs[2, i], i, col = color, lwd = 2) } head(sapply(1:200, FUN = seg.int), 0) ## list() ## list() abline(v = mu, lwd = 2) 2.2 Intervalos de confianza para el parameto p Aunque en el curso s√≥lo de abord√≥ un m√©todo, en esta secci√≥n se estudiar√°n 3 m√©todos para estimar el par√°metro ùëù. 2.2.1 M√©todo ‚Äúexacto‚Äù o de Clopper-Pearson Consideremos lo siguiente: \\[ \\begin{equation*} \\begin{aligned} &amp; X \\text{ una v.a. Bernoulli con } p \\text{ desconocido} \\\\ &amp; X_1, \\ldots, X_n \\text{ son una muestra aleatoria simple (m.a.s.) de } X, \\\\ &amp; \\text{ con un n√∫mero de √©xitos } x. \\\\ &amp; \\text{ Por lo tanto, la frecuencia relativa de √©xitos es } \\hat{p}_X = \\frac{x}{n}. \\end{aligned} \\end{equation*} \\] En este caso, la distribuci√≥n de la variable \\(Y\\) = ‚Äún√∫mero de √©xitos en la muestra‚Äù es binomial de parametros \\(n \\text{ y } p \\text{,} Y \\text{ es } B(n,p)\\) Definici√≥n. Un intervalo de confianza \\((p_0 \\;\\text{, } p_1)\\) del \\((1 - a)100%\\) nivel de confianza para \\(p\\) de una poblaci√≥n \\(X\\) de Bernoulli se obtiene encontrando el \\(p_0\\) m√°s grande y el \\(p_1\\) m√°s peque√±o tales que: \\[ \\sum_{k=x}^{n} \\left( \\frac{n}{k} \\right) \\cdot p_0^k \\; \\cdot (1-p_0)^{n-k} \\leq \\frac{a}{2}, \\; \\; \\sum_{k=0}^{x} \\left( \\frac{n}{k} \\right) \\; \\cdot p_1^k \\; \\cdot (1-p_1)^{n-k} \\; \\leq \\frac{a}{2} \\] Para hallar el IC para la proporci√≥n usando este m√©todo, se usar√° la funi√≥n binom.exact que se encuentra en el paquete epitools que se cag√≥ al inicio: binom.exact(x,n,conf.level) x: n√∫mero de √©xitos n: tama√±o de la muestra conf.level nivel de confianza correspondiente a \\(1 ‚àí a\\) Se trabajar√° con la base de datos iris, donde se hallar√° un IC para las proporciones de la especie ‚Äúsetosa‚Äù a partir de una muestra de 60, con una confianza de 95%: # Muestra se 60 flores: summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ## str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... set.seed(1000) flores.elegidas &lt;- sample(1:150, 60, replace = T) # Se muestran las 10 primeras flores elegidas muestra.flores.prop &lt;- iris[flores.elegidas, ] head(muestra.flores.prop, 10) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 68 5.8 2.7 4.1 1.0 versicolor ## 43 4.4 3.2 1.3 0.2 setosa ## 51 7.0 3.2 4.7 1.4 versicolor ## 88 6.3 2.3 4.4 1.3 versicolor ## 29 5.2 3.4 1.4 0.2 setosa ## 99 5.1 2.5 3.0 1.1 versicolor ## 61 5.0 2.0 3.5 1.0 versicolor ## 146 6.7 3.0 5.2 2.3 virginica ## 150 5.9 3.0 5.1 1.8 virginica ## 102 5.8 2.7 5.1 1.9 virginica # N√∫mero de flores de tipo setosa numero.flores.setosa &lt;- table(muestra.flores.prop$Species == &quot;setosa&quot;)[2] numero.flores.setosa ## TRUE ## 21 # Calculemos ahora el IC de 95% para p binom.exact(numero.flores.setosa, 60, conf.level = 0.95) ## x n proportion lower upper conf.level ## TRUE 21 60 0.35 0.2313264 0.484028 0.95 2.2.2 Metodo de Wilson Definici√≥n: En estas condiciones, un intervalo de confianza del \\((1-a) \\; \\cdot \\; 100\\)% I.C. para \\(p\\) (donde) \\(\\left (\\hat{p}_X = 1 - \\hat{p}_X \\right)\\) es: \\[ \\left ( \\frac{\\hat{p}_X + \\frac{z_1^2 -a/2}{2n}-z_{1-a/2} \\; \\sqrt{\\frac{\\hat{p}_X \\cdot \\hat{q}_X}{n} + \\frac{z^2_{1-a/2}}{4n^2}}} {1 + \\frac{z_{1-a/2}}{n}} , \\frac{\\hat{p}_X + \\frac{z_{1-a/2}^2}{2n} + z_{1-a/2} \\sqrt{\\frac{\\hat{p}_X \\cdot \\hat{q}_X}{n} + \\frac{z_{1-a/2}^2}{4n^2}}} {1 + \\frac{z_{1-a/2}^2}{n}}\\right) \\cdot \\] Para hallar un intervalo de confianza para la proporci√≥n poblacional en R seg√∫n el m√©todo de Wilson, hay que usar la funci√≥n binom.wilson del mismo paquete epitools. Se usa la funci√≥n binom.wilson del paquete epitools: binom.wilson(x,n,conf.level) Los par√°metros requeridos son los mismo que el caso del m√©todo exacto binom.wilson(numero.flores.setosa, 60, conf.level = 0.95) ## x n proportion lower upper conf.level ## TRUE 21 60 0.35 0.2416777 0.4763738 0.95 2.2.3 Metodo de Laplace Supongamos que la muestra aleatoria simple es considerablemente m√°s grande que la usada en el m√©todo de Wilson y que, adem√°s, la proporci√≥n muestral de √©xitos $ _X $ est√° alejada de 0 y de 1. O sea, \\(n \\geq 100\\) y que \\(n\\hat{p}_X \\;\\geq \\; 10\\) y \\(n(1- \\hat{p}_X) \\geq 10\\). En este caso, podemos usar la f√≥rmula de Laplace: \\[ \\hat{p}_X \\pm z_{1 - a/2} \\cdot \\sqrt{\\frac{\\hat{p}_X(1-\\hat{p}_X)}{n}} \\] Se usa la funci√≥n binom.approx del paquete epitools: binom.approx(x,n,conf.level) Los par√°metros requeridos son los mismo que el caso del m√©todo exacto. Este m√©todo es que estudiamos en el curso, por cual debe ser considerado siempre que se utilicen muestras grandes. binom.approx(numero.flores.setosa, 60, conf.level = 0.95) ## x n proportion lower upper conf.level ## TRUE 21 60 0.35 0.2293123 0.4706877 0.95 2.3 Intervalo de confianza para la varianza de una poblacion normal Consideremos la siguiente situaci√≥n: Consideramos una \\(X\\) una v.a normal con \\(\\mu\\) y \\(\\sigma\\) desconocidas. Sea \\(X_1 \\dots, X_n\\) una m.a.s de X y varianza Muestral \\(\\hat{S}^{2}_X\\) En estas condiciones tenemos lo siguiente: Teorema La variable aleatyoria \\(\\frac{(n-1)\\hat{S}^2_X}{\\sigma^2}\\) se distribuye seg√∫n una distribuci√≥n \\(\\chi^2_{n-1}\\) Teorema En las condiciones anteriores, un intervalo de confianza del \\((1-a) \\cdot 100%\\) para la varianza de \\(\\sigma^2\\) de la poblaci√≥n \\(X\\) es \\[ \\left(\\frac{(n-1)\\hat{S}^2_X}{\\chi^2_{n-1 \\; ,\\; 1-\\frac{a}{2}}} \\; , \\; \\frac{(n-1)\\hat{S}^2_X}{\\chi^2_{n-1 \\; ,\\; \\frac{a}{2}}}\\right), \\] d√≥nde \\(\\chi^2_{v,q}\\) es el q-cuantil de la distribuci√≥n \\(\\chi^2{v}\\) Ejemplo Un algoritmo probabil√≠stico depende de la semilla de aleatorizaci√≥n que se genera en cada paso. Para saber si la semilla influye mucho en el resultado se ejecuta el algoritmo varias veces hasta obtener un resultado similar y se estudia la varianza de su tiempo de ejecuci√≥n. Queremos ver si la desviaci√≥n t√≠pica cumple que ùúé ‚â§30. Se supone que la distribuci√≥n del tiempo de ejecuci√≥n del algoritmo es aproximadamente normal. Se realizan 30 ejecuciones del algoritmo de las que se mide el tiempo de ejecuci√≥n. Los resultados son: tiempo &lt;- c(12, 13, 13, 14, 14, 14, 15, 15, 16, 17, 17, 18, 18, 19, 19, 25, 25, 26, 27, 30, 33, 34, 35, 40, 40, 51, 51, 58, 59, 83) Se requiere calcular un IC de 95% para \\(\\sigma^2\\) # Varianza muestral n &lt;- 30 s.tiempo &lt;- var(tiempo) # Calcular los valores de la distribuci√≥n o cuantiles alpha &lt;- 0.05 chi2.izq &lt;- qchisq(1-alpha/2, n-1) chi2.der &lt;- qchisq(alpha/2, n-1) # IC para la varianza: ICvar &lt;- c((n-1)*s.tiempo/chi2.izq, (n-1)*s.tiempo/chi2.der) ICvar ## [1] 191.2627 544.9572 # IC para la desviaci√≥n est√°ndar sqrt(ICvar) ## [1] 13.82977 23.34432 Ahora, si se automatiza el proceso, se puede usar una funci√≥n de R llamada varTest del paquete EnvStats cuya estuctura ser√≠a: varTest(X,conf.level)$conf.int donde: x: Vector que contiene la muestra de datos conf.level: nivel de confianza. Para el caso anterior: # IC para la varianza varTest(tiempo, conf.level = 0.95)$conf.int ## LCL UCL ## 191.2627 544.9572 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 # IC para al desviaci√≥n est√°ndar sqrt(varTest(tiempo, conf.level = 0.95)$conf.int) ## LCL UCL ## 13.82977 23.34432 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 Ejemplo Hallar un intervalo de confianza para la varianza de la amplitud del s√©palo de la tabla de datos iris a partir de la muestra anterior. Suponemos que dicha variable es normal. # Se extraen la mediciones de s√©palo de la muestra amplitud.sepalo.muestra &lt;- iris[flores.elegidas, ]$Sepal.Width head(amplitud.sepalo.muestra, 10) ## [1] 2.7 3.2 3.2 2.3 3.4 2.5 2.0 3.0 3.0 2.7 # Se calcula el IC de 95% para la varianza de las ampliudes de s√©palo de los datos iris varTest(amplitud.sepalo.muestra, conf.level = 0.95)$conf.int ## LCL UCL ## 0.1625640 0.3365786 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 "],["ii-parte-casos-con-dos-poblaciones.html", "Cap√≠tulo 3 II Parte: Casos con dos poblaciones 3.1 Diferencia de Promedios 3.2 Cociente de varianzas 3.3 Diferencia de proporciones", " Cap√≠tulo 3 II Parte: Casos con dos poblaciones 3.1 Diferencia de Promedios Utilizaremos como ejemplo los datos de sobre medidas del cuerpo para hombres y mujeres de diferentes edades # Se lee la base de datos desde el enlace y se almacena en datos url &lt;- &#39;https://raw.githubusercontent.com/fhernanb/datos/master/medidas_cuerpo&#39; datos &lt;- read.table(file = url, header = T) #Se extraen datos de hombres y mujeres hombres &lt;- datos[datos$sexo == &quot;Hombre&quot;, ] mujeres &lt;- datos[datos$sexo == &quot;Mujer&quot;, ] dim(hombres) ## [1] 18 6 dim(mujeres) ## [1] 18 6 str(hombres) ## &#39;data.frame&#39;: 18 obs. of 6 variables: ## $ edad : int 43 65 45 37 55 33 25 35 28 26 ... ## $ peso : num 87.3 80 82.3 73.6 74.1 85.9 73.2 76.3 65.9 90.9 ... ## $ altura: num 188 174 176 180 168 ... ## $ sexo : chr &quot;Hombre&quot; &quot;Hombre&quot; &quot;Hombre&quot; &quot;Hombre&quot; ... ## $ muneca: num 12.2 12 11.2 11.2 11.8 12.4 10.6 11.3 10.2 12 ... ## $ biceps: num 35.8 35 38.5 32.2 32.9 38.5 38.3 35 32.1 40.4 ... str(mujeres) ## &#39;data.frame&#39;: 18 obs. of 6 variables: ## $ edad : int 22 20 19 25 21 23 26 22 28 40 ... ## $ peso : num 51.6 59 49.2 63 53.6 59 47.6 69.8 66.8 75.2 ... ## $ altura: num 161 168 160 157 156 ... ## $ sexo : chr &quot;Mujer&quot; &quot;Mujer&quot; &quot;Mujer&quot; &quot;Mujer&quot; ... ## $ muneca: num 9.2 9.9 8.9 9.5 9.1 10 9.4 10.7 9.8 11.5 ... ## $ biceps: num 24.3 27.8 24 28 26.9 26.5 24.1 29.2 29 33.6 ... Note que tanto para hombres como para mujeres, se tienen 18 datos con 6 variables diferentes a escoger: edad, peso, altura, sexo, mu√±eca y biceps Para calcular un IC de 95% para la diferencia promedio de altura de los hombres y con respecto a las mujeres, dato que el tama√±o de la muestra es peque√±o, se usar√° un t.test. # Media de hombres menos media de mujeres t.test(hombres$altura, mujeres$altura,conf.level = 0.95)$conf.int ## [1] 10.05574 20.03315 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 # Media de mujeres menos media de hombres t.test(mujeres$altura, hombres$altura, conf.level = 0.95)$conf.int ## [1] -20.03315 -10.05574 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 3.2 Cociente de varianzas Con estos mismo datos, se pueden realizar otras pruebas, como el cociente de varianzas. Usasemos una funci√≥n llamada var.test del paquete stests, que seguidamente se puede instalar con el siguiente c√≥digo (solo debe ejecutarse una vez para instalar): if (!require(&#39;devtools&#39;)) install.packages(&#39;devtools&#39;) devtools::install_github(&#39;fhernanb/stests&#39;, force=TRUE) La funci√≥n var.test tambi√©n existe en el paquete stats, por lo que si se desea utilizar dicha funci√≥n, se va a generar un conflicto. Con las siguientes instrucciones de llamado, se le puede indicar a R cu√°l paquete se desea usar: stats::var.test() # Para usar la fuci√≥n del paquete stats stests::var.test() # Para usar la fuci√≥n del paquete stests var.test del paquete stests es una versi√≥n ampliada de var.test del paquete stats. ¬øCu√°l ser√≠a la diferencia entre una y otra versi√≥n? Recuerde que: stats::var.test() s√≥lo sirve para 1 poblaci√≥n, mientras que stests::var.test() sirve para 1 o 2 poblaciones. # IC para el cociente de varianzas stests :: var.test(hombres$altura, mujeres$altura,conf.level = 0.95)$conf.int ## [1] 0.2327398 1.6632830 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 # IC para el cociente de desviaciones est√°ndar sqrt(stests :: var.test(hombres$altura, mujeres$altura,conf.level = 0.95)$conf.int) ## [1] 0.4824311 1.2896833 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 3.3 Diferencia de proporciones El siguiente y √∫ltimo caso se trabajar√° para diferencia de proporciones, donde se estar√° comparando la proporci√≥n de hombres que tienen menos de 30 a√±os con respecto a la de mujeres que tienen menos de 30 a√±os. # La funci√≥n wich permite realizar los conteos w &lt;- which((hombres$edad &lt;= 30)) w ## [1] 7 9 10 12 13 15 16 exitos.hombres &lt;- length(which(hombres$edad &lt;= 30)) exitos.mujeres &lt;- length(which(mujeres$edad &lt;= 30)) exitos.hombres ## [1] 7 exitos.mujeres ## [1] 15 length(hombres$edad) ## [1] 18 Para construir intervalos de confianza bilaterales para la proporci√≥n a partir de la funci√≥n prop.test es necesario definir 3 argumentos: x: Vector con el conteo de √©xitos de las dos muestras. n: Vector con el n√∫mero de ensayos de ambas muestras. conf.level: Nivel de confianza. Seguidamente se construye un IC para la diferencia de proporciones entre hombres y mujeres menores de 30 a√±os, con un nivel de confianza de 90% # Proporci√≥n de hombres menos proporci√≥n de mujeres prop.test(x = c(exitos.hombres, exitos.mujeres), n = c(length(hombres$edad), length(mujeres$edad)), conf.level = 0.90)$conf.int ## [1] -0.7379022 -0.1509867 ## attr(,&quot;conf.level&quot;) ## [1] 0.9 # Proporci√≥n de mujeres menos proporci√≥n de hombres prop.test(x = c(exitos.mujeres, exitos.hombres), n = c(length(mujeres$edad), length(hombres$edad)), conf.level = 0.90)$conf.int ## [1] 0.1509867 0.7379022 ## attr(,&quot;conf.level&quot;) ## [1] 0.9 "],["pruebas-de-hipotesis-para-una-poblacion.html", "Cap√≠tulo 4 Pruebas de hipotesis para una poblacion 4.1 Prueba de hipotesis para Micro 4.2 Prueba de hipotesis para p 4.3 Prueba de hipotesis para sigma de una variable aleatoria con comportamiento normal", " Cap√≠tulo 4 Pruebas de hipotesis para una poblacion En este documento se estudiar√°n pruebas de hip√≥tesis param√©tricas para una y dos poblaciones, a partir de los par√°metros \\(\\mu\\), \\(\\sigma\\) \\(p\\). Otros tipos de pruebas de hip√≥tesos tales como bondad de ajuste, independencia y ANOVAS,se abordar√°n en otra secci√≥n. Primeramente, se cargar√°n las librer√≠as a utilizar: library(MASS) library(TeachingDemos) 4.1 Prueba de hipotesis para Micro Para las pruebas de hip√≥tesis de medias, se puede usar, dependiendo de las condiciones la prueba z o la prueba t. Z-test vs T-test En el caso que se conozca \\(\\sigma:\\) Z-test En el caso de una poblaci√≥n con \\(\\sigma\\) desconocida: Si la muestra es peque√±a y la poblaci√≥n es normal: T-test Si la muestra es grande \\(n \\geq 30 \\; o \\; 40\\) y la poblaci√≥n no es normal, se puede tomar \\(\\sigma = S_x :\\) Z-test Si la muestra es grande y la poblaci√≥n es normal: Z-test o T-test. Nota: este √∫ltimo caso, os recomendamos que us√©is el T-test debido a que es m√°s preciso. t.test(x, y, mu=..., alternative=..., conf.level=..., paired=..., var.equal=..., na.omit=...) x es el vector de datos que forma la muestra que analizamos. mu es el valor Œº‚ÇÄ de la hip√≥tesis nula:\\(H_o : \\mu = \\mu_0\\) El par√°metro alternative puede tomar tres valores: \"two.sided\" para contrastes bilaterales, \"less\" y \"greater\" para contrastes unilaterales. En esta funci√≥n, y en todas las que explicamos en esta lecci√≥n, su valor por defecto, que no hace falta especificar, es \"two.sided\". El significado de estos valores depende del tipo de test que efectuemos: \"two.sided\" representa la hip√≥tesis alternativa \\(H_1 : \\mu \\ne \\mu_0\\). \"less\" corresponde a \\(H_1 : \\mu &lt; \\mu_0\\) \"greater\" corresponde a \\(H_1 : \\mu &gt; \\mu_0\\). El valor del par√°metro conf.level es el nivel de confianza \\(1- \\alpha\\). Su valor por defecto es 0.95, que corresponde a un nivel de confianza del 95%, es decir, a un nivel de significaci√≥n \\(\\alpha = 0.05\\) El par√°metro na.action sirve para especificar qu√© queremos hacer con los valores NA. Es un par√°metro gen√©rico que se puede usar en casi todas las funciones de estad√≠stica inferencial y an√°lisis de datos. Sus valores m√°s √∫tiles son: na.omit, su valor por defecto, elimina las entradas NA de los vectores (o los pares que contengan alg√∫n NA, en el caso de muestras emparejadas). Por ahora, esta opci√≥n por defecto es la adecuada, por lo que no hace falta usar este par√°metro, pero conviene saber que hay alternativas. na.fail hace que la ejecuci√≥n pare si hay alg√∫n NA en los vectores. na.pass no hace nada con los NA y permite que las operaciones internas de la funci√≥n sigan su curso y los manejen como les corresponda. Ejemplo Veamos si dada una muestra de tama√±o 40 de flores de la tabla de datos iris, podemos considerar que la media de la longitud del s√©palo es mayor que 5.7. Para este caso, tome en cuenta que la prueba es de cola superior y sus hip√≥tesis respectivas son: \\[ H_0: \\mu = 5.7 \\left(\\leq\\right) \\\\ H_1: \\mu &gt; 5.7 \\] # Se hace el muestreo de 40 de la base de datos iris set.seed(230) flores.elegidas=sample(1:150,40,replace=TRUE) # Seleccionamos solo la longitud de s√©palo de la muestra long.sepalo.muestra &lt;- iris[flores.elegidas, ]$Sepal.Length sd(long.sepalo.muestra) ## [1] 1.002225 var(long.sepalo.muestra) ## [1] 1.004455 # Se realiza la prueba T-test t.test(long.sepalo.muestra,mu=5.7,alternative = &quot;greater&quot;) ## ## One Sample t-test ## ## data: long.sepalo.muestra ## t = 0.23664, df = 39, p-value = 0.4071 ## alternative hypothesis: true mean is greater than 5.7 ## 95 percent confidence interval: ## 5.470505 Inf ## sample estimates: ## mean of x ## 5.7375 4.2 Prueba de hipotesis para p 4.2.1 Muestas Peque√±as Este test est√° implementado en la funci√≥n binom.test, cuya sintaxis es binom.test(x, n, p=..., alternative=..., conf.level=...) x y n son n√∫meros naturales: el n√∫mero de √©xitos y el tama√±o de la muestra. p es la probabilidad de √©xito que queremos contrastar Puede ser √∫til saber que el intervalo de confianza para la \\(p\\) que da binom.test en un contraste bilateral es el de Clopper-Pearson. Ejemplo Tenemos un test para detectar un determinado microorganismo. En una muestra de 25 cultivos con este microorganismo, el test lo detect√≥ en 21 casos. ¬øHay evidencia que la sensibilidad del test sea superior al 80%? Para este caso, tome en cuenta que la prueba es de cola superior y sus hip√≥tesis respectivas son: \\[ H_0 : p = 0.8 \\left(0.8\\right) \\\\ H_1 : p &gt; 0.8 \\] # Verificacamos las condiciones de np y nq 25*0.8 ## [1] 20 25*0.2 ## [1] 5 # Aplicamos prueba binomial test binom.test(21,25,p=0.8,alternative=&quot;greater&quot;,conf.level=0.95) ## ## Exact binomial test ## ## data: 21 and 25 ## number of successes = 21, number of trials = 25, p-value = 0.4207 ## alternative hypothesis: true probability of success is greater than 0.8 ## 95 percent confidence interval: ## 0.6703917 1.0000000 ## sample estimates: ## probability of success ## 0.84 En este caso note que no se encontr√≥ suficiente evidencia para rechazar \\(H_0\\), pues \\(0.8 \\in \\; ]0.6703917,1.0000000[.\\) Ejemplo Considere la tabla de datos birthwt del paquete MASS. Dicha tabla de datos contiene informaci√≥n acerca de 189 reci√©n nacidos en un hospital de Springfield en el a√±o 1986. low: Indicador de si el peso del reci√©n nacido ha sido menor que 2.5 kg. age: Edad de la madre en a√±os. lwt: Peso de la madre en libras durante el √∫ltimo per√≠odo. race: Raza de la madre (1: blanca, 2: negra, 3: otra). smoke: Indicador de si la madre fumaba durante el embarazo (0 si no fumaba y 1 si fumaba). ptl: N√∫mero de embarazos previos de la madre. ht: Indicador de si la madre es hipertensa. ui: Indicador de irritabilidad uterina en la madre. ftw: N√∫mero de visitas m√©dicas realizadas durante el primer trimestre. bwt: Peso del reci√©n nacido en gramos. Para realizar la prueba, se consideran las siguientes hip√≥tesis: \\[ H_0 : p = 0.3 \\left(\\leq\\right) \\\\ H_1: p &gt; 0.3 \\] d√≥nde p representa la proporci√≥n de madres que eran fumadoras durante el ambarazo y la prueba a realizar es de cola derecha. str(birthwt) ## &#39;data.frame&#39;: 189 obs. of 10 variables: ## $ low : int 0 0 0 0 0 0 0 0 0 0 ... ## $ age : int 19 33 20 21 18 21 22 17 29 26 ... ## $ lwt : int 182 155 105 108 107 124 118 103 123 113 ... ## $ race : int 2 3 1 1 1 3 1 3 1 1 ... ## $ smoke: int 0 0 1 1 1 0 0 0 1 1 ... ## $ ptl : int 0 0 0 0 0 0 0 0 0 0 ... ## $ ht : int 0 0 0 0 0 0 0 0 0 0 ... ## $ ui : int 1 0 0 1 1 0 0 0 0 0 ... ## $ ftv : int 0 3 1 2 0 0 1 1 1 0 ... ## $ bwt : int 2523 2551 2557 2594 2600 2622 2637 2637 2663 2665 ... dim(birthwt) [1] ## [1] 189 # Se toma una muestra de tama√±o 30 de la base de datos birthwt del paquete MASS set.seed(1001) madres.elegidas &lt;- sample(1:dim(birthwt) [1], 30, replace=TRUE) muestra.madres.elegidas &lt;- birthwt[madres.elegidas, ] # Se cuenta el n√∫mero de √©xitos en la muestra, quen en este caso correponde a madre fumadoras table(muestra.madres.elegidas$smoke) ## ## 0 1 ## 14 16 # Calculemos el n√∫mero de madres fumadoras num.madres.fumadoras &lt;- table(muestra.madres.elegidas$smoke) [2] # Aplicamos la prueba binom.test binom.test(num.madres.fumadoras, 30, p = 0.3, alternative = &quot;greater&quot;) ## ## Exact binomial test ## ## data: num.madres.fumadoras and 30 ## number of successes = 16, number of trials = 30, p-value = 0.00637 ## alternative hypothesis: true probability of success is greater than 0.3 ## 95 percent confidence interval: ## 0.3699476 1.0000000 ## sample estimates: ## probability of success ## 0.5333333 Note que en este caso se encontr√≥ suficiente evidencia en contra de \\(H_0\\), pues 0.3 \\(\\notin \\; ]0.3699476,1.0000000[\\) por lo tanto se rechaza \\(H_0\\) y se asume que la cantidad de madres que fumaron durante el embarazo est√° por arriba de 0,3. 4.2.2 Muestas Grandes Si indicamos con \\(p\\) la proporci√≥n poblacional y \\(\\hat{p}_X\\) la proporci√≥n muestral, sabemos que si la muestra es grande entonces: \\[ \\left(n \\geq 40\\right) \\; Z = \\frac{\\hat{p}_X -p}{\\sqrt{\\frac{p\\left(1-p\\right)}{n}}} \\approx N\\left(0,1\\right) \\] Y si la hip√≥tesis nula \\(H_0 : p = p_0\\) es verdadera, entonces: \\[ Z = \\frac{\\hat{p}_X - p}{\\sqrt{\\frac{p\\left(1-p\\right)}{n}}} \\approx N(0,1). \\] Podemos usar los mismos p valores que en el Z-test. Se tiene que ir aletar con el intervalo de confianza. Si tenemos \\(n \\geq 100 \\; , n\\hat{p}_X \\geq 10\\) y \\(n\\left(1-\\hat{p}_X\\right) \\geq 10\\), se puede usar el de Laplace. En caso contrario, se tiene que usar el de Wilson. Ejemplo Una asociaci√≥n ganadera afirma que, en las matanzas caseras en las Baleares, como m√≠nimo el 70% de los cerdos han sido analizados de triquinosis. En una investigaci√≥n, se visita una muestra aleatoria de 100 matanzas y resulta que en 53 de √©stas se ha realizado el an√°lisis de triquinosis. ¬øPodemos aceptar la afirmaci√≥n de los ganaderos? Para realizar la prueba, se consideran las siguientes hip√≥tesis: \\[ H_0 : p = 0.7 \\left(\\leq\\right) \\\\ H_1 : p &lt; 0.7 \\] D√≥nde p representa la proporci√≥n de que en una matanza elegida al azar, esta sea analizada de triquinosis y la prueba a realizar es de cola izquierda. En R est√° implementado la funci√≥n prop.test, que adem√°s tambi√©n sirve para contrastar dos proporciones por medio de muestras independientes grandes. prop.test(x, n, p =..., alternative=..., conf.level=...) D√≥nde: x: Puede ser dos cosas: Un n√∫mero natural: en este caso, \\(R\\) entiende que es el n√∫mero de √©xitos en una muestra. Un vector de dos n√∫meros naturales: en este caso, \\(R\\) entiende que es un contraste de dos proporciones y que √©stos son los n√∫meros de √©xitos en las muestras. n: Cuando trabajamos con una sola muestra, \\(n\\) es su tama√±o. Cuando estamos trabajando con dos muestras, \\(n\\) es el vector de dos entradas de sus tama√±os. p: Cuando trabajamos con una sola muestra, \\(p\\) es la proporci√≥n poblacional que contrastamos. En el caso de un contraste de dos muestras, no hay que especificarlo. alternative y conf.level: El significado de estos y sus posibles valores, son los usuales. prop.test(53, 100, p = 0.7,alternative = &quot;less&quot;, conf.level = 0.95) ## ## 1-sample proportions test with continuity correction ## ## data: 53 out of 100, null probability 0.7 ## X-squared = 12.964, df = 1, p-value = 0.0001587 ## alternative hypothesis: true p is less than 0.7 ## 95 percent confidence interval: ## 0.0000000 0.6150364 ## sample estimates: ## p ## 0.53 Note que en este caso se encontr√≥ suficiente evidencia en contra de \\(H_0\\), pues \\(0.7 \\notin ]0.0000000,0.6150364[\\) , por lo tanto se rechaza \\(H_0\\) y se asume que la cantidad de madres que fumaron durante el embarazo est√° por debajo de 0.7. R usa como estad√≠stico de constraste \\(Z^2\\) donde Z recordemos que es: \\(z = \\frac{\\hat{p}-p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}\\) Si se toma \\(Z_0^2\\) se obtiene: z0=(0.53-0.7)/sqrt(0.7*(1-0.7)/100) z0^2 ## [1] 13.7619 No da exactamente el mismo valor en la salida de R de la funci√≥n prop.test debido a que R hace una peque√±a correcci√≥n a la continuidad. Este hecho tambi√©n se manifiesta en la peque√±a diferencia que hay entre los intervalos de confianza en caso de clacularse a mano y en la salida de R. 4.3 Prueba de hipotesis para sigma de una variable aleatoria con comportamiento normal Recordamos que si \\(X_1 \\dots , X_n\\) es una m.a.s de una v.a \\(X ~ N \\left(\\mu, \\sigma\\right)\\), entonces el **estad√≠stico \\(\\chi_{n-1}^2 = \\frac{(n-1)\\hat{S}_X^2}{\\sigma^2}\\) sigue una distribuci√≥n \\(\\chi^2\\) con \\(n-1\\) grados de libertad. Por lo tanto, si la hip√≥sis nula \\(H_0 : \\sigma = \\sigma_0\\) es verdadera, \\(X_{n-1}^2 = \\frac{(n-1)\\hat{S}_X^2}{\\sigma_0^2}\\) tendr√° una distribuci√≥n \\(\\mu^2\\) con \\((n-1)\\) grados de libertad. Calculamos su valor \\(\\mu_0^2\\) sobre la muestra. Nos planteamos los siguientes contrastes: \\[ \\begin{array}{rl} \\text{a.} &amp; \\begin{cases} H_0: \\sigma = \\sigma_0, &amp; (0 \\text{ bajo } H_0: \\sigma \\leq \\sigma_0), \\\\ H_1: \\sigma &gt; \\sigma_0, \\end{cases} \\\\ \\text{b.} &amp; \\begin{cases} H_0: \\sigma = \\sigma_0, &amp; (0 \\text{ bajo } H_0: \\sigma \\geq \\sigma_0), \\\\ H_1: \\sigma &lt; \\sigma_0, \\end{cases} \\\\ \\text{c.} &amp; \\begin{cases} H_0: \\sigma = \\sigma_0, \\\\ H_1: \\sigma \\neq \\sigma_0. \\end{cases} \\end{array} \\] Los p-valores ser√°n los siguientes: p-valor: \\(P(\\chi^2_{n-1} \\geq \\chi^2_0)\\). p-valor: \\(P(\\chi^2_{n-1} \\leq \\chi^2_0)\\). p-valor: \\(2 \\min \\{ P(\\chi^2_{n-1} \\leq \\chi^2_0), P(\\chi^2_{n-1} \\geq \\chi^2_0) \\}\\). Para trabajar este tipo de casos, se usar√° la funci√≥n sigma.test del paquete TeachingDemos y tambi√©n, la funci√≥n var.test del paquete stests Su sintaxis es la misma que la funci√≥n t.test para una muestra, substituyendo el par√°metros mu de t.test por el par√°metro sigma (para especificar el valor de la desviaci√≥n t√≠pica que constrastamos, \\(\\sigma_0\\) O sigmasq (por ‚Äúsigma al cuadrado‚Äù, para especificar el valor de la varianza que constrastamos, \\(\\sigma_0^2\\)). Ejemplos Se han medido los siguientes valores en miles de personas para la audiencia de un programa de radio en n = 10 d√≠as: 521, 742, 593, 635, 788,717, 606, 639, 666, 624 Contrastar si la varianza de la audiencia es 6400 al nivel de significaci√≥n del 5%, suponiendo que la poblaci√≥n es normal. Esta prueba ser√° de dos colas, con las siguientes hip√≥tesis: \\[ H_0: \\sigma = \\sqrt{6400} = 80 \\\\ H_1: \\sigma \\neq 80 \\] Mediante paquete TeachingDemos # Agregamos los datos a un vector x &lt;- c(521,742,593,635,788,717,606,639,666,624) # Se realiza la prueba con el dato de sigma sigma.test(x, sigma = 80, alternative = &quot;two.sided&quot;, conf.level = 0.95) ## ## One sample Chi-squared test for variance ## ## data: x ## X-squared = 8.5945, df = 9, p-value = 0.951 ## alternative hypothesis: true variance is not equal to 6400 ## 95 percent confidence interval: ## 2891.53 20369.25 ## sample estimates: ## var of x ## 6111.656 Note que el IC mostrado por la prueba, est√° dado para \\(\\sigma^2\\), por lo que debemos extraer la rea√≠z cuadrada a este para obtener un IC interpretable para \\(\\sigma\\): sigmatest &lt;- sigma.test(x, sigma = 80, alternative = &quot;two.sided&quot;, conf.level = 0.95) str(sigmatest) ## List of 9 ## $ statistic : Named num 8.59 ## ..- attr(*, &quot;names&quot;)= chr &quot;X-squared&quot; ## $ parameter : Named num 9 ## ..- attr(*, &quot;names&quot;)= chr &quot;df&quot; ## $ p.value : num 0.951 ## $ conf.int : num [1:2] 2892 20369 ## ..- attr(*, &quot;conf.level&quot;)= num 0.95 ## $ estimate : Named num 6112 ## ..- attr(*, &quot;names&quot;)= chr &quot;var of x&quot; ## $ null.value : Named num 6400 ## ..- attr(*, &quot;names&quot;)= chr &quot;variance&quot; ## $ alternative: chr &quot;two.sided&quot; ## $ method : chr &quot;One sample Chi-squared test for variance&quot; ## $ data.name : chr &quot;x&quot; ## - attr(*, &quot;class&quot;)= chr &quot;htest&quot; sigmatest$conf.int ## [1] 2891.53 20369.25 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 sqrt(sigmatest$conf.int) ## [1] 53.77295 142.72087 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 Con este nuevo IC para \\(\\sigma\\), se puede ver que 80 \\(\\in ]53.77295142.72087[\\) y por tanto se puede concluir que no se encontr√≥ suficiente evidencia en contra de H_0. por lo que se puede asumir que \\(\\sigma = 80\\). Mediante paquete stests Seguidamente se realiza la misma prueba de hip√≥tesis, pero utilizando la funci√≥n var.test. stests::var.test(x, null.value = 6400, alternative = &quot;two.sided&quot;, conf.level = 0.95) ## ## X-squared test for variance ## ## data: x ## X-squared = 8.5945, df = 9, p-value = 0.951 ## alternative hypothesis: true variance is not equal to 6400 ## 95 percent confidence interval: ## 2891.53 20369.25 ## sample estimates: ## variance of x ## 6111.656 Observe que los resultados son an√°logos. Ejemplo Vamos a contrastar si la varianza de la amplitud del s√©palo de las flores de la tabla de datos iris es menor que 0.2. Esta prueba ser√° de cola izquierda, con las siguientes hip√≥tesis: \\[ H_0: \\sigma^2 = 0.2 \\left(\\geq \\right) \\\\ H_1 : \\sigma^2 &lt; 0.2 \\] # Se toma una muestra de 40 flores set.seed(2019) flores.elegidas &lt;- sample(1:150, 40, replace = TRUE) muestra.flores.elegidas &lt;- iris[flores.elegidas, ] # Se aplica la prueba sigma.test(muestra.flores.elegidas$Sepal.Width, sigmasq = 0.2, alternative = &quot;less&quot;) ## ## One sample Chi-squared test for variance ## ## data: muestra.flores.elegidas$Sepal.Width ## X-squared = 45.369, df = 39, p-value = 0.7763 ## alternative hypothesis: true variance is less than 0.2 ## 95 percent confidence interval: ## 0.0000000 0.3531275 ## sample estimates: ## var of muestra.flores.elegidas$Sepal.Width ## 0.2326603 En este caso se puede apreciar que 0.2 \\(\\in ]0.0000000,0.3531275[\\) y por tanto se puede concluir que no se encontr√≥ suficiente evidencia en contra de \\(H_0\\), por lo que se puede asumir que \\(\\sigma^2 = 0.2\\) "],["pruebas-de-hipotesis-para-dos-poblaciones.html", "Cap√≠tulo 5 Pruebas de hipotesis para dos poblaciones 5.1 Introducci√≥n 5.2 Casos de Dos poblaciones 5.3 Prueba de hipotesis para dos proporciones \\(p_1, p_2\\) 5.4 Prueba de hipotesis para dos varianzas de \\(\\sigma_1^2\\), \\(\\sigma_2^2\\)", " Cap√≠tulo 5 Pruebas de hipotesis para dos poblaciones 5.1 Introducci√≥n En esta secci√≥n se estudiar√° el uso de pruebas de hip√≥tesis para constrastar un mismo par√°metro en dos grupos o poblaciones diferentes. Para hacer dicho contraste se dispondr√° de una muestra de cada poblaci√≥n, las cu√°les podr√≠a cumplir con alguna de las siguientes condiciones: Muestas Independientes: Las dos muestras se han obtenido de forma independiente. Recordemos que dos eventos son independientes si la probabilidad de uno no afecta la probabilidad del otro. Ejemplo: Se toma un grupo de hombres y otro de mujeres, se prueba un medidcamento sobre dos muestras de enfermos diferentes, se toma una muestra de estudiantes de un grupo y otra de otro grupo Muestas emparejadas o pareadas: ocurre cuando las dos muestras corresponden a los mismos individuos. Ejemplos: se toma nuesta muestra de personas y se estudia su antes y despu√©s, se prueban dos medicamento sobre el mismo grupo de enfermos. De los casos que interesa estudiar est√°n: diferencia de medias, diferencia de proporciones y cociente de varianzas. Como es de costrumbre al iniciar, se cargar√°n las librer√≠as a utilizar: library(MASS) ## ## Attaching package: &#39;MASS&#39; ## The following object is masked from &#39;package:EnvStats&#39;: ## ## boxcox library(tidyverse) #para utilizar pipes ## ‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ ## ‚úî dplyr 1.1.4 ‚úî readr 2.1.5 ## ‚úî forcats 1.0.0 ‚úî stringr 1.5.1 ## ‚úî lubridate 1.9.3 ‚úî tibble 3.2.1 ## ‚úî purrr 1.0.2 ‚úî tidyr 1.3.1 ## ‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ ## ‚úñ dplyr::filter() masks stats::filter() ## ‚úñ dplyr::lag() masks stats::lag() ## ‚úñ dplyr::select() masks MASS::select() ## ‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors 5.2 Casos de Dos poblaciones 5.2.1 Prueba de hipotesis para dos medias poblacionales \\(\\mu_1\\) y \\(\\mu_2\\) Tenemos dos v.a \\(X_1\\) y \\(X_2\\), de medias \\(\\mu_1\\) y \\(\\mu_2\\) Tomamos una m.a.s de cada variable: \\[ X_{1,1}, X_{2,1}, \\dots , X_{1,n_1}, \\text{ de } X_1 X_{2,1}, X_{2,2}, \\dots , X_{1,n_2}, \\text{ de } X_2 \\] Sean \\(\\bar{X_1}\\) y \\(\\bar{X_2}\\) sus medias, respectivamente. La hip√≥tesis nula ser√° del tipo: \\[ H_0 : \\mu_1 = \\mu_2 \\text{, o, equivalentemente, } H_0 : \\mu_1 - \\mu_2 = 0 \\] La hip√≥tesis alternativa que nos plantearemos ser√°n del tipo: \\[ \\mu_1 &lt; \\mu_2 \\text{, o, equivalentemente, } \\mu_1 - \\mu_2 &lt; 0 \\mu_1 &gt; \\mu_2 \\text{, o, equivalentemente, } \\mu_1 - \\mu_2 &gt; 0 \\mu_1 \\neq \\mu_2 \\text{, o, equivalentemente, } \\mu_1 - \\mu_2 \\neq 0 \\] En las pruebas de hipotesis para la diferencia de medias, se deben considerar varios casos: Estad√≠stico de contraste o cr√≠tico Condiciones \\(Z_c = \\frac{\\bar{x_1}-\\bar{x_2}}{\\sqrt{\\frac{sp^2}{n_1}+\\frac{sp^2}{n_2}}}\\) \\(\\bar{x_1}, \\bar{x_2}\\) se distribuye normalmente, \\(n_1, n_2 \\geq 30 \\; \\text{o } 40\\), donde \\(\\sigma_1, \\sigma_2\\) se conocen. \\(T_c = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{sp^2}{n_1} + \\frac{sp^2}{n_2}}} \\\\ \\text{Con: } v = n_1 + n_2 -2 \\;gl\\) Poblaciones normales o \\(n_1, n_2 \\geq 30 \\text{ o } 40, \\sigma_1, \\sigma_2\\) no se conocen, pero se asumen \\(\\sigma_1 \\ = \\sigma_2 \\\\ sp^2 = \\frac{(n_1 -1)s_1^2 + (n_2 -1)s_2^2}{n_1 + n_2 -2}\\) \\(T_c = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}} \\\\ \\text{donde:} \\quad v = \\frac{\\left( \\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2} \\right)^2}{\\frac{\\left( \\frac{s_1^2}{n_1} \\right)^2}{n_1 - 1} + \\frac{\\left( \\frac{s_2^2}{n_2} \\right)^2}{n_2 - 1}}\\) Poblaciones normales o \\(n_1,n_2 \\geq 30 \\text{ o } 40, \\sigma_1, \\sigma_2\\) No se conocen y se asume \\(\\sigma_1 \\neq \\sigma_2\\) 5.2.2 Contraste para dos medias independientes en R: funcion t.test Para el contraste de dos medias, se usar√° la fuci√≥n t.test de R, cuya sintaxis se presenta a continuaci√≥n: t.test(x, y, mu=..., alternative=..., conf.level=..., paired=..., var.equal=..., na.omit=...) D√≥nde: * x: Es el vector de los datos de la primera muestra. * y: Es el vector de datos de la segunda muestra. * alternative: Indica si la prueba es de cola izquierda(less), derecha(greater) o de dos colas(two.sided). * var.equal: Es para indicar que se asumen varianzas iguales(True o T) o diferentes(False o F). Ejemplo Imaginemos ahora que nos planteamos si la media de la longitud del p√©talo es la misma para las flores de las especies setosa y versicolor. Sea: \\(\\mu_5\\) la media de la longitud del p√©talo de las flores de la variedad setosa \\(\\mu_v\\) la media de la longitud del p√©talo de las flores de la variedad versicolor Para realizar esta prueba, se considerar√°n las siguientes hip√≥tesis: \\[ H_0: \\mu_5 - \\mu_v = 0 \\\\ H_1: \\mu_5 - \\mu_v \\ne 0\\\\ \\] Se trabajar√° con una muestra de 40 flores de cada especie. Primero para explicar el muestreo que se desea hacer, echemos una mirada a los datos de iris: datosiris &lt;- iris Note que la variable Species ya viene ordenada de manera que los datos de 1 a 50 corresponde a la especie setosa y del 51 al 100 corresponden a la especie versicolor. Seguidamente se procede con el muestreo: # Se planta la semilla set.seed(45) # Se establecen los √≠ndices para la muestra flores.elegidas.setosa &lt;- sample(1:50, 40, replace = TRUE) flores.elegidas.versicolor &lt;- sample(51:100, 40, replace = TRUE) # Se extraen las muestras muestra.setosa &lt;- iris[flores.elegidas.setosa, ] muestra.versicolor &lt;- iris[flores.elegidas.versicolor, ] # Se aplica la prueba de hip√≥tesis con valores por defecto de nivel de confianza de 95% y varianzas diferentes(var.equal = F) t.test(muestra.setosa$Petal.Length, muestra.versicolor$Petal.Length, alternative = &quot;two.sided&quot;) ## ## Welch Two Sample t-test ## ## data: muestra.setosa$Petal.Length and muestra.versicolor$Petal.Length ## t = -42.766, df = 49.953, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.913186 -2.651814 ## sample estimates: ## mean of x mean of y ## 1.4075 4.1900 El p-valor del contraste ha sido pr√°cticamente cero, lo que hace que se tenga evidencia suficiente para concluir que las medias de la longitud del p√©talo son diferentes para las dos especies. Adem√°s, se observa en el intervalo de confianza que este no contiene el valor cero y est√° totalmente a la izquierda de cero. Por tanto, debemos rechazar la hip√≥tesis nula. Note que se ha considerado que las varianzas de las dos variables son diferentes y en caso de haberlas considerado como iguales, se debe hacer lo siguiente: t.test(muestra.setosa$Petal.Length, muestra.versicolor$Petal.Length, alternative=&quot;two.sided&quot;, var.equal = TRUE) ## ## Two Sample t-test ## ## data: muestra.setosa$Petal.Length and muestra.versicolor$Petal.Length ## t = -42.766, df = 78, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.91203 -2.65297 ## sample estimates: ## mean of x mean of y ## 1.4075 4.1900 En este caso, el p-valor tambi√©n es despreciable, por lo que llegamos a la misma conclusi√≥n anterior: las medias son diferentes. Es importante tomar en cuenta que el asumir varianzas iguales no es una decisi√≥n que se tome a la ligera, en este caso se requiere que, antes de aplicar la prueba T, se realice una prueba de contraste para las varianzas y dependiendo de su resultado, se procede con la prueba de contraste de medias, asumiendo varianzas iguales o no. 5.3 Prueba de hipotesis para dos proporciones \\(p_1, p_2\\) Estad√≠stico de contraste o cr√≠tico ¬ø Cu√°ndo ? \\(Z_c = \\frac{\\hat{p_1} - \\hat{p_2}}{\\sqrt{\\frac{\\hat{p_1}\\hat{q_1}}{n_1} + \\frac{\\hat{p_2}\\hat{q_2}}{n_2}}}\\) La muestra es grande. \\(n_ip_i &gt; 5 \\text{ o } 10, i = 1,2\\) Y \\(n_1, n_2 \\ge 50\\) Para las pruebas de contraste de proporciones para muestras grandes, se utilizar√° la funci√≥n prop.test prop.test(x, n, p =..., alternative=..., conf.level=...) D√≥nde: * x: En el caso de un constraste de proporciones es el un vector de dos n√∫meros naturales que representan los √©xitos de ambas muestas. n: En el caso de trabajar con dos muestras, es un vector de dos entradas de sus respectivos tama√±os para las muestras. alternative y Conf.level y sus posibles valores, son los usuales. Ejemplo Se contrastar√© si la proporci√≥n de madres fumadoras de raza blanca es la misma que la proporci√≥n de madres fumadoras de raza negra, en la tabla de datos birthwt Para realizar esta prueba, se considerar√°n las siguientes hip√≥tesis: \\[ H_0: p_b - p_n = 0 \\\\ H_1: p_b - p_n \\ne 0 \\\\ \\] # Se revisa primeramente la comporisi√≥n de la tabla birthwt str(birthwt) ## &#39;data.frame&#39;: 189 obs. of 10 variables: ## $ low : int 0 0 0 0 0 0 0 0 0 0 ... ## $ age : int 19 33 20 21 18 21 22 17 29 26 ... ## $ lwt : int 182 155 105 108 107 124 118 103 123 113 ... ## $ race : int 2 3 1 1 1 3 1 3 1 1 ... ## $ smoke: int 0 0 1 1 1 0 0 0 1 1 ... ## $ ptl : int 0 0 0 0 0 0 0 0 0 0 ... ## $ ht : int 0 0 0 0 0 0 0 0 0 0 ... ## $ ui : int 1 0 0 1 1 0 0 0 0 0 ... ## $ ftv : int 0 3 1 2 0 0 1 1 1 0 ... ## $ bwt : int 2523 2551 2557 2594 2600 2622 2637 2637 2663 2665 ... head(birthwt, 5) ## low age lwt race smoke ptl ht ui ftv bwt ## 85 0 19 182 2 0 0 0 1 0 2523 ## 86 0 33 155 3 0 0 0 0 3 2551 ## 87 0 20 105 1 1 0 0 0 1 2557 ## 88 0 21 108 1 1 0 0 1 2 2594 ## 89 0 18 107 1 1 0 0 1 0 2600 b &lt;- birthwt # Se extraen las etiquetas (n√∫mero de fila) de las madres de cada raza madres.raza.blanca &lt;- rownames(birthwt[birthwt$race == 1, ]) madres.raza.blanca ## [1] &quot;87&quot; &quot;88&quot; &quot;89&quot; &quot;92&quot; &quot;94&quot; &quot;95&quot; &quot;100&quot; &quot;101&quot; &quot;103&quot; &quot;105&quot; &quot;107&quot; &quot;108&quot; ## [13] &quot;112&quot; &quot;113&quot; &quot;114&quot; &quot;118&quot; &quot;120&quot; &quot;123&quot; &quot;124&quot; &quot;125&quot; &quot;126&quot; &quot;127&quot; &quot;129&quot; &quot;131&quot; ## [25] &quot;132&quot; &quot;133&quot; &quot;134&quot; &quot;136&quot; &quot;138&quot; &quot;140&quot; &quot;141&quot; &quot;151&quot; &quot;160&quot; &quot;162&quot; &quot;167&quot; &quot;169&quot; ## [37] &quot;170&quot; &quot;173&quot; &quot;174&quot; &quot;175&quot; &quot;182&quot; &quot;183&quot; &quot;184&quot; &quot;185&quot; &quot;187&quot; &quot;188&quot; &quot;189&quot; &quot;190&quot; ## [49] &quot;191&quot; &quot;192&quot; &quot;193&quot; &quot;195&quot; &quot;196&quot; &quot;197&quot; &quot;200&quot; &quot;203&quot; &quot;204&quot; &quot;205&quot; &quot;207&quot; &quot;209&quot; ## [61] &quot;210&quot; &quot;211&quot; &quot;213&quot; &quot;215&quot; &quot;217&quot; &quot;219&quot; &quot;220&quot; &quot;221&quot; &quot;222&quot; &quot;223&quot; &quot;224&quot; &quot;225&quot; ## [73] &quot;226&quot; &quot;10&quot; &quot;20&quot; &quot;22&quot; &quot;23&quot; &quot;26&quot; &quot;27&quot; &quot;29&quot; &quot;33&quot; &quot;34&quot; &quot;35&quot; &quot;36&quot; ## [85] &quot;42&quot; &quot;45&quot; &quot;51&quot; &quot;56&quot; &quot;57&quot; &quot;65&quot; &quot;67&quot; &quot;68&quot; &quot;69&quot; &quot;77&quot; &quot;79&quot; &quot;84&quot; madres.raza.negra &lt;- rownames(birthwt[birthwt$race == 2, ]) madres.raza.negra ## [1] &quot;85&quot; &quot;102&quot; &quot;115&quot; &quot;116&quot; &quot;117&quot; &quot;119&quot; &quot;121&quot; &quot;128&quot; &quot;130&quot; &quot;161&quot; &quot;166&quot; &quot;168&quot; ## [13] &quot;172&quot; &quot;202&quot; &quot;206&quot; &quot;11&quot; &quot;18&quot; &quot;28&quot; &quot;40&quot; &quot;43&quot; &quot;50&quot; &quot;59&quot; &quot;60&quot; &quot;61&quot; ## [25] &quot;71&quot; &quot;83&quot; # Se eligen las muestras de tama√±o 50 para cada raza set.seed(2000) madres.elegidas.blanca &lt;- sample(madres.raza.blanca, 50, replace = TRUE) madres.elegidas.negra &lt;- sample(madres.raza.negra, 50, replace = TRUE) muestra.madres.raza.blanca &lt;- birthwt[madres.elegidas.blanca, ] muestra.madres.raza.negra &lt;- birthwt[madres.elegidas.negra, ] Se calculan cuantas madres fumadoras hay en cada una de las muestras usando la funci√≥n table y las almacenamos en una nueva variable: table(muestra.madres.raza.blanca$smoke) ## ## 0 1 ## 24 26 table(muestra.madres.raza.negra$smoke) ## ## 0 1 ## 33 17 # n√∫mero de madres fumadoras de raza blanca x.blanca &lt;- table(muestra.madres.raza.blanca$smoke)[2] # n√∫mero de madres fumadoras de raza negra x.negra &lt;- table(muestra.madres.raza.negra$smoke)[2] Finalmente, se realiza el contraste de hip√≥tesis: # Se hace el contraste de hip√≥tesis prop.test(c(x.blanca, x.negra), c(50, 50)) ## ## 2-sample test for equality of proportions with continuity correction ## ## data: c(x.blanca, x.negra) out of c(50, 50) ## X-squared = 2.6112, df = 1, p-value = 0.1061 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.03083246 0.39083246 ## sample estimates: ## prop 1 prop 2 ## 0.52 0.34 El p-valor del contraste ha sido 0.1061 y mayor que 0.1. Se concluye que no se tiene evidencia para rechazar que las proporciones de madres fumadoras de razas blanca y negra sean iguales. Si se revisa el IC, se puede ver que el 0 est√° dentro de dicho intervalo, hecho que reafirma la conclusi√≥n anterior 5.4 Prueba de hipotesis para dos varianzas de \\(\\sigma_1^2\\), \\(\\sigma_2^2\\) F√≥rmula Condiciones \\(F_c = \\frac{s_2^2}{s_1^2}\\) \\[v_1 = n_1 - 1gl \\\\ v_2 = n_2 -1gl \\\\ \\text{Ambas poblaciones normales.}\\] La funci√≥n para efectuar este test en R es var.test y su sintaxis b√°sica es la misma que la de t.test para dos muestras, como se muestra a continuaci√≥n: var.test(x, y, alternative=..., conf.level=...) D√≥nde: x,y: Son los vectores de datos. alternative y Conf.level y sus posibles valores: Son los usuales. null.value que por defecto es 1 considerando que la relaci√≥n entre las varianzas es 1. Se puede cambiar si se desea probar otra relaci√≥n. Ejemplo Recordemos que cuando se explic√≥ el contraste para dos medias independientes, se contrast√≥ si las medias de las longitudes del p√©talo para las especies setosa y versicolor eran iguales o no, pero tambi√©n se necesitaba saber si las varianzas eran iguales o no, esto como un insumo previo a considerar antes de poder usar la funci√≥n t.test. Con una prueba de hip√≥tesis para varianzas, se podr√≠a tener informaci√≥n para adoptar la condici√≥n de igualdad o no de las varianzas. Las muestras eran muestra.setosa y muestra.versicolor #Se realiza el contraste de varianza var.test(muestra.setosa$Petal.Length, muestra.versicolor$Petal.Length) ## ## F test to compare two variances ## ## data: muestra.setosa$Petal.Length and muestra.versicolor$Petal.Length ## F = 0.14331, num df = 39, denom df = 39, p-value = 1.738e-08 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.07579578 0.27095614 ## sample estimates: ## ratio of variances ## 0.1433085 El p-valor del contraste ha sido pr√°cticamente cero, por tanto, se concluye que tiene evidencias suficientes para afirmar que las varianzas de las longitudes del p√©talo de las flores de las especies setosa y versicolor son diferentes. Note que adem√°s que, el IC no contiene el valor 1, de hecho est√° a la izquierda de √©l. Este hecho reafirma la conclusi√≥n anterior. "],["una-visi√≥n-grafica-de-las-pruebas-de-hipotesis.html", "Cap√≠tulo 6 Una visi√≥n grafica de las pruebas de hipotesis", " Cap√≠tulo 6 Una visi√≥n grafica de las pruebas de hipotesis Cuando una prueba de hip√≥tesis para dos poblaciones se concluye que ùêª0 es rechazada significa que se ha detectado una varianci√≥n siginificativa entre los par√°metros comparados para ambos grupos que no es posible explicarla por el azar. Se tomar√°n seguidamente dos ejemplos que ya fueron abordados en secciones previas de este documento, con la finalidad de mostrar los que ocurre gr√°ficamente con el par√°metro en estudio y su respectivo intervalo de confianza, esto con el fin de que se pueda comprender de una mejor manera el trasfondo del resultado de la prueba de hip√≥tesis. El primer caso a ilustrar el la prueba T aplicada sobre la diferencia de promedios entre la longitud del p√©talo de las flores iris de las especies setosa y versicolor: # Se planta la semilla set.seed(45) # Se establecen los √≠ndices para la muestra flores.elegidas.setosa &lt;- sample(1:50, 40, replace = TRUE) flores.elegidas.versicolor &lt;- sample(51:100, 40, replace = TRUE) # Se extraen las muestras muestra.setosa &lt;- iris[flores.elegidas.setosa, ] muestra.versicolor &lt;- iris[flores.elegidas.versicolor, ] # Se aplica la prueba de hip√≥tesis t.test(muestra.setosa$Petal.Length, muestra.versicolor$Petal.Length, alternative = &quot;two.sided&quot;) ## ## Welch Two Sample t-test ## ## data: muestra.setosa$Petal.Length and muestra.versicolor$Petal.Length ## t = -42.766, df = 49.953, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.913186 -2.651814 ## sample estimates: ## mean of x mean of y ## 1.4075 4.1900 La prueba en este caso detect√≥ diferencia significativa entre los promedios y por tanto \\(H_0\\) fue rechazada. Seguidamanete trateremos de ilustrar el comportamiento de los intervalos de confianza para cada una de las medias de las 3 especies de flores iris (estamos incluyendo una tercera especie que no fue usada en la prueba T anterior) de manera que se pueda ver si esta diferencia que la prueba ha detectado es marcada. Primeramente, se preparan los datos para crear esos intervalos de confianza, para lo cual utilizaremos la funci√≥n pipe o pipeline del paquete tidyverse mediante la instrucci√≥ %&gt;%: # Limpia el entorno de trabajo rm(list = ls()) # Instala el paquete dplyr si no est√° ya instalado if (!require(dplyr)) install.packages(&quot;dplyr&quot;) # Carga el paquete dplyr library(dplyr) iris.ic &lt;- iris %&gt;% group_by(Species) %&gt;% summarise( media = mean(Petal.Length), n = n(), de = sd(Petal.Length), ee = de / sqrt(n), li = media - 1.95996 * ee, ls = media + 1.95996 * ee ) iris.ic ## # A tibble: 3 √ó 7 ## Species media n de ee li ls ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 setosa 1.46 50 0.174 0.0246 1.41 1.51 ## 2 versicolor 4.26 50 0.470 0.0665 4.13 4.39 ## 3 virginica 5.55 50 0.552 0.0780 5.40 5.70 ## # A tibble: 3 √ó 7 ## Species media n de ee li ls ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 setosa 1.46 50 0.174 0.0246 1.41 1.51 ## 2 versicolor 4.26 50 0.470 0.0665 4.13 4.39 ## 3 virginica 5.55 50 0.552 0.0780 5.40 5.70 La nueva base de datos resumen iris.ic contiene la informaci√≥n que necesitamos para contruir los intervalos de confianza de 95% para la media de la longitud del p√©talo de las tres especies de flores iris. Usando el paquete ggplot2, que se carga por defecto al cargar la librer√≠a tidyverse, graficaremos estos intervalos de confianza de la siguiente forma: ggplot(iris, aes(x = Species, y = Petal.Length)) + geom_errorbar(data = iris.ic, aes(Species, media, ymin = li, ymax = ls), width = 0.2, color =&quot;red&quot;) + geom_point(data = iris.ic, aes(Species, media)) + theme_minimal() Note que los IC no se superpone entre ellos, sino que quedan muy separados, lo que permite visualmente comprender que no es posible una igualdad entre las medias de las tres especies de iris, algo que refuerza lo conclu√≠do en la pruena T. Analicemos ahora el caso de proporciones de las mujeres negras que fumaron durante el embarazo con respecto a las muejres blancas que tambi√©n lo hicieron. Previamente en esta prueba no se encontr√≥ evidencia en contra de \\(H_0\\), como seguidamente se muestra: # Se extraen las etiquetas (n√∫mero de fila) de las madres de cada raza madres.raza.blanca &lt;- birthwt[birthwt$race == 1, ] madres.raza.blanca ## low age lwt race smoke ptl ht ui ftv bwt ## 87 0 20 105 1 1 0 0 0 1 2557 ## 88 0 21 108 1 1 0 0 1 2 2594 ## 89 0 18 107 1 1 0 0 1 0 2600 ## 92 0 22 118 1 0 0 0 0 1 2637 ## 94 0 29 123 1 1 0 0 0 1 2663 ## 95 0 26 113 1 1 0 0 0 0 2665 ## 100 0 18 100 1 1 0 0 0 0 2769 ## 101 0 18 100 1 1 0 0 0 0 2769 ## 103 0 25 118 1 1 0 0 0 3 2782 ## 105 0 28 120 1 1 0 0 0 1 2821 ## 107 0 31 100 1 0 0 0 1 3 2835 ## 108 0 36 202 1 0 0 0 0 1 2836 ## 112 0 28 167 1 0 0 0 0 0 2877 ## 113 0 17 122 1 1 0 0 0 0 2906 ## 114 0 29 150 1 0 0 0 0 2 2920 ## 118 0 24 90 1 1 1 0 0 1 2948 ## 120 0 25 155 1 0 0 0 0 1 2977 ## 123 0 29 140 1 1 0 0 0 2 2977 ## 124 0 19 138 1 1 0 0 0 2 2977 ## 125 0 27 124 1 1 0 0 0 0 2922 ## 126 0 31 215 1 1 0 0 0 2 3005 ## 127 0 33 109 1 1 0 0 0 1 3033 ## 129 0 19 189 1 0 0 0 0 2 3062 ## 131 0 21 160 1 0 0 0 0 0 3062 ## 132 0 18 90 1 1 0 0 1 0 3062 ## 133 0 18 90 1 1 0 0 1 0 3062 ## 134 0 32 132 1 0 0 0 0 4 3080 ## 136 0 24 115 1 0 0 0 0 2 3090 ## 138 0 22 120 1 0 0 1 0 1 3100 ## 140 0 22 130 1 1 0 0 0 0 3132 ## 141 0 30 95 1 1 0 0 0 2 3147 ## 151 0 28 140 1 0 0 0 0 0 3234 ## 160 0 20 141 1 0 2 0 1 1 3317 ## 162 0 22 112 1 1 2 0 0 0 3317 ## 167 0 16 135 1 1 0 0 0 0 3374 ## 169 0 25 140 1 0 0 0 0 1 3416 ## 170 0 32 134 1 1 1 0 0 4 3430 ## 173 0 23 190 1 0 0 0 0 0 3459 ## 174 0 22 131 1 0 0 0 0 1 3460 ## 175 0 32 170 1 0 0 0 0 0 3473 ## 182 0 23 130 1 0 0 0 0 0 3586 ## 183 0 36 175 1 0 0 0 0 0 3600 ## 184 0 22 125 1 0 0 0 0 1 3614 ## 185 0 24 133 1 0 0 0 0 0 3614 ## 187 0 19 235 1 1 0 1 0 0 3629 ## 188 0 25 95 1 1 3 0 1 0 3637 ## 189 0 16 135 1 1 0 0 0 0 3643 ## 190 0 29 135 1 0 0 0 0 1 3651 ## 191 0 29 154 1 0 0 0 0 1 3651 ## 192 0 19 147 1 1 0 0 0 0 3651 ## 193 0 19 147 1 1 0 0 0 0 3651 ## 195 0 30 137 1 0 0 0 0 1 3699 ## 196 0 24 110 1 0 0 0 0 1 3728 ## 197 0 19 184 1 1 0 1 0 0 3756 ## 200 0 23 110 1 0 0 0 0 1 3770 ## 203 0 30 112 1 0 0 0 0 1 3799 ## 204 0 22 169 1 0 0 0 0 0 3827 ## 205 0 18 120 1 1 0 0 0 2 3856 ## 207 0 32 186 1 0 0 0 0 2 3860 ## 209 0 29 130 1 1 0 0 0 2 3884 ## 210 0 33 117 1 0 0 0 1 1 3912 ## 211 0 20 170 1 1 0 0 0 0 3940 ## 213 0 14 135 1 0 0 0 0 0 3941 ## 215 0 25 120 1 0 0 0 0 2 3983 ## 217 0 20 158 1 0 0 0 0 1 3997 ## 219 0 21 115 1 0 0 0 0 1 4054 ## 220 0 22 129 1 0 0 0 0 0 4111 ## 221 0 25 130 1 0 0 0 0 2 4153 ## 222 0 31 120 1 0 0 0 0 2 4167 ## 223 0 35 170 1 0 1 0 0 1 4174 ## 224 0 19 120 1 1 0 0 0 0 4238 ## 225 0 24 116 1 0 0 0 0 1 4593 ## 226 0 45 123 1 0 0 0 0 1 4990 ## 10 1 29 130 1 0 0 0 1 2 1021 ## 20 1 21 165 1 1 0 1 0 1 1790 ## 22 1 32 105 1 1 0 0 0 0 1818 ## 23 1 19 91 1 1 2 0 1 0 1885 ## 26 1 25 92 1 1 0 0 0 0 1928 ## 27 1 20 150 1 1 0 0 0 2 1928 ## 29 1 24 155 1 1 1 0 0 0 1936 ## 33 1 19 102 1 0 0 0 0 2 2082 ## 34 1 19 112 1 1 0 0 1 0 2084 ## 35 1 26 117 1 1 1 0 0 0 2084 ## 36 1 24 138 1 0 0 0 0 0 2100 ## 42 1 22 130 1 1 1 0 1 1 2187 ## 45 1 17 110 1 1 0 0 0 0 2225 ## 51 1 20 121 1 1 1 0 1 0 2296 ## 56 1 31 102 1 1 1 0 0 1 2353 ## 57 1 15 110 1 0 0 0 0 0 2353 ## 65 1 30 142 1 1 1 0 0 0 2410 ## 67 1 22 130 1 1 0 0 0 1 2410 ## 68 1 17 120 1 1 0 0 0 3 2414 ## 69 1 23 110 1 1 1 0 0 0 2424 ## 77 1 26 190 1 1 0 0 0 0 2466 ## 79 1 28 95 1 1 0 0 0 2 2466 ## 84 1 21 130 1 1 0 1 0 3 2495 madres.raza.negra &lt;- birthwt[birthwt$race == 2, ] madres.raza.negra ## low age lwt race smoke ptl ht ui ftv bwt ## 85 0 19 182 2 0 0 0 1 0 2523 ## 102 0 15 98 2 0 0 0 0 0 2778 ## 115 0 26 168 2 1 0 0 0 0 2920 ## 116 0 17 113 2 0 0 0 0 1 2920 ## 117 0 17 113 2 0 0 0 0 1 2920 ## 119 0 35 121 2 1 1 0 0 1 2948 ## 121 0 25 125 2 0 0 0 0 0 2977 ## 128 0 21 185 2 1 0 0 0 2 3042 ## 130 0 23 130 2 0 0 0 0 1 3062 ## 161 0 22 158 2 0 1 0 0 2 3317 ## 166 0 16 112 2 0 0 0 0 0 3374 ## 168 0 18 229 2 0 0 0 0 0 3402 ## 172 0 20 121 2 1 0 0 0 0 3444 ## 202 0 25 241 2 0 0 1 0 0 3790 ## 206 0 16 170 2 0 0 0 0 4 3860 ## 11 1 34 187 2 1 0 1 0 0 1135 ## 18 1 24 128 2 0 1 0 0 1 1701 ## 28 1 21 200 2 0 0 0 1 2 1928 ## 40 1 20 120 2 1 0 0 0 3 2126 ## 43 1 27 130 2 0 0 0 1 0 2187 ## 50 1 18 110 2 1 1 0 0 0 2296 ## 59 1 23 187 2 1 0 0 0 1 2367 ## 60 1 20 122 2 1 0 0 0 0 2381 ## 61 1 24 105 2 1 0 0 0 0 2381 ## 71 1 17 120 2 0 0 0 0 2 2438 ## 83 1 17 142 2 0 0 1 0 0 2495 madres.raza.otras &lt;- birthwt[birthwt$race == 3, ] madres.raza.otras ## low age lwt race smoke ptl ht ui ftv bwt ## 86 0 33 155 3 0 0 0 0 3 2551 ## 91 0 21 124 3 0 0 0 0 0 2622 ## 93 0 17 103 3 0 0 0 0 1 2637 ## 96 0 19 95 3 0 0 0 0 0 2722 ## 97 0 19 150 3 0 0 0 0 1 2733 ## 98 0 22 95 3 0 0 1 0 0 2751 ## 99 0 30 107 3 0 1 0 1 2 2750 ## 104 0 20 120 3 0 0 0 1 0 2807 ## 106 0 32 121 3 0 0 0 0 2 2835 ## 109 0 28 120 3 0 0 0 0 0 2863 ## 111 0 25 120 3 0 0 0 1 2 2877 ## 135 0 19 132 3 0 0 0 0 0 3090 ## 137 0 22 85 3 1 0 0 0 0 3090 ## 139 0 23 128 3 0 0 0 0 0 3104 ## 142 0 19 115 3 0 0 0 0 0 3175 ## 143 0 16 110 3 0 0 0 0 0 3175 ## 144 0 21 110 3 1 0 0 1 0 3203 ## 145 0 30 153 3 0 0 0 0 0 3203 ## 146 0 20 103 3 0 0 0 0 0 3203 ## 147 0 17 119 3 0 0 0 0 0 3225 ## 148 0 17 119 3 0 0 0 0 0 3225 ## 149 0 23 119 3 0 0 0 0 2 3232 ## 150 0 24 110 3 0 0 0 0 0 3232 ## 154 0 26 133 3 1 2 0 0 0 3260 ## 155 0 20 169 3 0 1 0 1 1 3274 ## 156 0 24 115 3 0 0 0 0 2 3274 ## 159 0 28 250 3 1 0 0 0 6 3303 ## 163 0 31 150 3 1 0 0 0 2 3321 ## 164 0 23 115 3 1 0 0 0 1 3331 ## 176 0 30 110 3 0 0 0 0 0 3544 ## 177 0 20 127 3 0 0 0 0 0 3487 ## 179 0 23 123 3 0 0 0 0 0 3544 ## 180 0 17 120 3 1 0 0 0 0 3572 ## 181 0 19 105 3 0 0 0 0 0 3572 ## 186 0 21 134 3 0 0 0 0 2 3629 ## 199 0 24 110 3 0 1 0 0 0 3770 ## 201 0 20 120 3 0 0 0 0 0 3770 ## 208 0 18 120 3 0 0 0 0 1 3884 ## 212 0 28 134 3 0 0 0 0 1 3941 ## 214 0 28 130 3 0 0 0 0 0 3969 ## 216 0 16 95 3 0 0 0 0 1 3997 ## 218 0 26 160 3 0 0 0 0 0 4054 ## 4 1 28 120 3 1 1 0 1 0 709 ## 13 1 25 105 3 0 1 1 0 0 1330 ## 15 1 25 85 3 0 0 0 1 0 1474 ## 16 1 27 150 3 0 0 0 0 0 1588 ## 17 1 23 97 3 0 0 0 1 1 1588 ## 19 1 24 132 3 0 0 1 0 0 1729 ## 24 1 25 115 3 0 0 0 0 0 1893 ## 25 1 16 130 3 0 0 0 0 1 1899 ## 30 1 21 103 3 0 0 0 0 0 1970 ## 31 1 20 125 3 0 0 0 1 0 2055 ## 32 1 25 89 3 0 2 0 0 1 2055 ## 37 1 17 130 3 1 1 0 1 0 2125 ## 44 1 20 80 3 1 0 0 1 0 2211 ## 46 1 25 105 3 0 1 0 0 1 2240 ## 47 1 20 109 3 0 0 0 0 0 2240 ## 49 1 18 148 3 0 0 0 0 0 2282 ## 52 1 21 100 3 0 1 0 0 4 2301 ## 54 1 26 96 3 0 0 0 0 0 2325 ## 62 1 15 115 3 0 0 0 1 0 2381 ## 63 1 23 120 3 0 0 0 0 0 2410 ## 75 1 26 154 3 0 1 1 0 1 2442 ## 76 1 20 105 3 0 0 0 0 3 2450 ## 78 1 14 101 3 1 1 0 0 0 2466 ## 81 1 14 100 3 0 0 0 0 2 2495 ## 82 1 23 94 3 1 0 0 0 0 2495 table(madres.raza.blanca$smoke) ## ## 0 1 ## 44 52 table(madres.raza.negra$smoke) ## ## 0 1 ## 16 10 table(madres.raza.otras$smoke) ## ## 0 1 ## 55 12 n1 &lt;- length(madres.raza.blanca$smoke) n2 &lt;- length(madres.raza.negra$smoke) n3 &lt;- length(madres.raza.otras$smoke) # n√∫mero de madres fumadoras de raza blanca x.blanca &lt;- table(madres.raza.blanca$smoke)[2] # n√∫mero de madres fumadoras de raza negra x.negra &lt;- table(madres.raza.negra$smoke)[2] # n√∫mero de madres fumadoras de otras razas x.otras &lt;- table(madres.raza.otras$smoke)[2] # Se hace el contraste de hip√≥tesis prop.test(c(x.blanca, x.negra), c(n1, n2)) ## ## 2-sample test for equality of proportions with continuity correction ## ## data: c(x.blanca, x.negra) out of c(n1, n2) ## X-squared = 1.4396, df = 1, p-value = 0.2302 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.07929433 0.39339689 ## sample estimates: ## prop 1 prop 2 ## 0.5416667 0.3846154 Siguiendo la idea de los hechos con los datos de iris, se contruir√° un intervalo de confianza de 95% para las proporciones de las muejeres que fumaron durante el embaraso seg√∫n su raza. Primeramente se prepara el resumen de datos: # Carga el paquete MASS que contiene el dataset birthwt if (!require(MASS)) install.packages(&quot;MASS&quot;) library(MASS) nacimientos &lt;- birthwt str(nacimientos) ## &#39;data.frame&#39;: 189 obs. of 10 variables: ## $ low : int 0 0 0 0 0 0 0 0 0 0 ... ## $ age : int 19 33 20 21 18 21 22 17 29 26 ... ## $ lwt : int 182 155 105 108 107 124 118 103 123 113 ... ## $ race : int 2 3 1 1 1 3 1 3 1 1 ... ## $ smoke: int 0 0 1 1 1 0 0 0 1 1 ... ## $ ptl : int 0 0 0 0 0 0 0 0 0 0 ... ## $ ht : int 0 0 0 0 0 0 0 0 0 0 ... ## $ ui : int 1 0 0 1 1 0 0 0 0 0 ... ## $ ftv : int 0 3 1 2 0 0 1 1 1 0 ... ## $ bwt : int 2523 2551 2557 2594 2600 2622 2637 2637 2663 2665 ... ## &#39;data.frame&#39;: 189 obs. of 10 variables: ## $ low : int 0 0 0 0 0 0 0 0 0 0 ... ## $ age : int 19 33 20 21 18 21 22 17 29 26 ... ## $ lwt : int 182 155 105 108 107 124 118 103 123 113 ... ## $ race : int 2 3 1 1 1 3 1 3 1 1 ... ## $ smoke: int 0 0 1 1 1 0 0 0 1 1 ... ## $ ptl : int 0 0 0 0 0 0 0 0 0 0 ... ## $ ht : int 0 0 0 0 0 0 0 0 0 0 ... ## $ ui : int 1 0 0 1 1 0 0 0 0 0 ... ## $ ftv : int 0 3 1 2 0 0 1 1 1 0 ... ## $ bwt : int 2523 2551 2557 2594 2600 2622 2637 2637 2663 2665 ... nacimientos$race &lt;- ifelse(birthwt$race == 1, &quot;Blanca&quot;, ifelse (birthwt$race == 2,&quot;Negra&quot; , &quot;Otras&quot;) ) nacimientos$race &lt;- factor(nacimientos$race, levels = c(&quot;Blanca&quot;,&quot;Negra&quot; ,&quot;Otras&quot;)) La base de datos birthwt utiliza una etiqueta num√©rica para clasificar la raza de las muejeres, por lo que en la instrucci√≥n anterior se cambi√≥ dicha etiqueta por un texto m√°s significativo seg√∫n el tipo de raza. Una vez hecho el cambio, se procede a construir la tabla resumen que usaremos para el gr√°fico: nacimientos.ic &lt;- nacimientos %&gt;% group_by(race) %&gt;% summarise(n = n(), x = table(smoke)[2], p = x/n, ee = sqrt(p*(1-p)/n()), li = p - 1.95996*ee, ls = p + 1.95996*ee ) nacimientos.ic ## # A tibble: 3 √ó 7 ## race n x p ee li ls ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Blanca 96 52 0.542 0.0509 0.442 0.641 ## 2 Negra 26 10 0.385 0.0954 0.198 0.572 ## 3 Otras 67 12 0.179 0.0468 0.0873 0.271 ## # A tibble: 3 √ó 7 ## race n x p ee li ls ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Blanca 96 52 0.542 0.0509 0.442 0.641 ## 2 Negra 26 10 0.385 0.0954 0.198 0.572 ## 3 Otras 67 12 0.179 0.0468 0.0873 0.271 ggplot(nacimientos, aes(x = race)) + geom_errorbar(data = nacimientos.ic, aes(race, p, ymin = li, ymax = ls), width = 0.2, color =&quot;red&quot;) + geom_point(data = nacimientos.ic, aes(race, p)) Haciendo un an√°lisis se puede ver que en el caso de raza Negra y Blanca se evidencia un traslape en los intervalos de confianza donde el IC de raza Negra con el de raza blanca , por lo que la prueba de hip√≥tesis no puede descar una posible igualdad para las proporciones. A pesar no haber hecho pruebas comparando las proporciones de las otras razas, se podr√≠a intuir que la prueba de hip√≥tesis encontrar√° evidencia en contra para la diferencia de proporciones entre las razas Blanca y Otras como se muestra a continuaci√≥n: prop.test(c(x.blanca, x.otras), c(n1, n3)) ## ## 2-sample test for equality of proportions with continuity correction ## ## data: c(x.blanca, x.otras) out of c(n1, n3) ## X-squared = 20.257, df = 1, p-value = 6.769e-06 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## 0.2143770 0.5107474 ## sample estimates: ## prop 1 prop 2 ## 0.5416667 0.1791045 En el caso del los IC para raza Negra y Otras, tambi√©n se evidencia traslape de estos y por tanto, se esperar√≠a que mediante una prueba de hip√≥tesis se pueda asumir igualdad de proporciones, es decir, que la diferencia no sea significativa y que por tanto, \\(H_0\\) no sea rechazada como se muestra seguidamente: prop.test(c(x.negra, x.otras), c(n2, n3)) ## ## 2-sample test for equality of proportions with continuity correction ## ## data: c(x.negra, x.otras) out of c(n2, n3) ## X-squared = 3.3164, df = 1, p-value = 0.06859 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.02950876 0.44053057 ## sample estimates: ## prop 1 prop 2 ## 0.3846154 0.1791045 "],["otras-pruebas-de-hipotesis.html", "Cap√≠tulo 7 Otras pruebas de Hipotesis", " Cap√≠tulo 7 Otras pruebas de Hipotesis En las secciones anteriore se ha venido desarrollando un compilado de pruebas o contrastes de hip√≥tesis, basados en par√°metros de poblaciones, como podemos recordar la media poblacional (\\(\\mu\\)), la desviaci√≥n est√°ndar (\\(\\sigma\\)), la proporci√≥n de √©xitos (\\(p\\)), entre otros. Ahora, es importante tener claro que en este tipo de pruebas, se parte del supuesto de que se conoce la distribuci√≥n de la poblaci√≥n, es decir, sabemos que la variable \\(X\\), que nos da los valores de la poblaci√≥n, es normal, binomial, o de otro tipo. Lo que no se conoce y que a la postre, la raz√≥n de ser de estos contrastes es validar el valor de uno o m√°s par√°metros de los que depende la distribuci√≥n de variable \\(X \\left( \\mu, \\sigma, p \\right)\\) Por ejemplo, si se supone que \\(X\\) es normal y se realiza un contraste de hip√≥tesis para la media, se tienen por un lado el caso cuando ùúé se conoce y cuando no. De igual forma, se estudiaron los casos en los comparamos dos poblaciones a partir de sus par√°metros. Todos estos tipos de pruebas se conocen como contrastes param√©tricos. Seguramente al trabajar estos contrastes param√©tricos, se ha tenido la inquietud sobre c√≥mo es que se define, por ejemplo, la condici√≥n de que una variable \\(X\\) sea normal, ¬øen qu√© se basan para hacer tal afirmaci√≥n?, ¬øqu√© evidencias, basadas en la informaci√≥n sobre valores de una muestra, se tienen con respecto a la normalidad de \\(X\\)?. Este tipo de preguntas son las que se intenta responder mediante las pruebas o contrastes NO param√©tricos que se estudianran en esta secci√≥n. Estos contrastes son del tipo en los que la hip√≥tesis nula NO consiste en averiguar si un determinado par√°metro adopta o no cierto valor, sino m√°s bien, busca determinar si la variable \\(X\\) es de un tipo u otro. Una l√≥gica adecuada de estos an√°lisis, por ejemplo, podr√≠a llevar a analizar la variable \\(X\\) y su posible normalidad, una vez que se tenga la informaci√≥n se puede pasar a una segunda fase que consiste en estudiar los par√°metros de esta distribuci√≥n mediante contrastes param√©tricos, siempre que se cumplan las condiciones para estos. Se estudiar√° la forma de trabajar en R las siguientes pruebas: 1. Prueba de Bondad de Ajuste 1. Prueba de Independencia 1. Prueba de An√°lisis de Varianza (ANOVA) Primeramente se cargaran las librer√≠as a utilizar: library(stats) library(car) library(nortest) library(fBasics) library(moments) "],["prueba-de-bondad-de-ajuste.html", "Cap√≠tulo 8 Prueba de Bondad de Ajuste 8.1 Visualizaci√≥n de datos 8.2 Pruebas formales de normalidad", " Cap√≠tulo 8 Prueba de Bondad de Ajuste Para esta pueba se usar√° la funci√≥n chisq.test del paquete stats que requiere de los siguientes par√°metros: x: es el vector (o la tabla de contingencia calculada con table) de frecuencias absolutas observadas de las clases en la muestra p : es el vector de probabilidades te√≥ricas de las clases para la distribuci√≥n que queremos contrastar. En caso de NO especificarlo, se asume equiprobabilidad para todas las clases simulate.p.value: es un par√°metro l√≥gico que indica a la funci√≥n si debe optar por una simulaci√≥n para el c√°lculo del p-valor del contraste. Por defecto es FALSE Esta herramienta debe tomarse en cuenta cuando falla una o m√°s condiciones al aplicar la prueba de bondad de ajuste, en ese caso se indica como TRUE y R realizar√° una serie de r√©plicas aelatorias a partir el m√©todo de Monte Carlo test. Este n√∫mero de r√©plicas es de 2000 por defecto, pero si se desea otra cantidad, se debe indicar mediante el par√°metro B. Consideremos el ejemplo visto en clase: Ejemplo 1 Un grupo de ratas baja 90 veces por una rampa que conecta con 3 puertas. Se observa que en 23 ocasiones las ratas pasaron por la puerta 1, 36 veces por la puerta 2 y 31 veces por la puerta 3. Se desea probar que las ratas no tienen preferencias por alguna de las puertas en particular. Use un nivel de significancia e 0.05. Seguidamente, construimos la tabla resumen Puerta 1 Puerta 2 Puerta 3 Frecuencia observada 23 30 36 Para realizar esta prueba, se considerar√°n las siguientes hip√≥tesis: \\(H_0: p_1 = p_2 = p_3 = \\frac{1}{3}\\), d√≥nde \\(p_i\\) es la probabilidad de que una rata elija la puerta \\(i = 1,2,3\\) \\(H_1\\): las ratas tienen preferencia por alguna puerta en particular freq.empiricas &lt;- c(23, 36, 31) #prob.teoricas &lt;- c(1/3,1/3,1/3) chisq.test(freq.empiricas) ## ## Chi-squared test for given probabilities ## ## data: freq.empiricas ## X-squared = 2.8667, df = 2, p-value = 0.2385 Conclusi√≥n Note que al ser valor \\(P &gt; a\\)se concluye que no se cuenta con suficiente eivdencia en contra para rechazar \\(H_0\\) y por tanto, es v√°lido asumir que las ratas no tienen preferencia por alguna de las puertas. Ejemplo 2 El curso Estructura de Datos II, es impartido en el segundo a√±o de la carrera de Ingenier√≠a en Sistemas de una Universidad. Un profesor considera que las edades de los estudiantes que llevan dicho curso, sigue una distribuci√≥n normal. En una muestra de 200 estudiantes se obtuvieron los resultados de la tabla adjunta. ¬øConsidera correcta la afirmaci√≥n del profesor?. Edad: X Frecuencia observada \\(X &lt; 18\\) 30 \\(18 \\leq X &lt; 19\\) 100 \\(19 \\leq &lt; 20\\) 50 \\(20 \\leq X &lt; 21\\) 15 \\(X \\geq 21\\) 5 Tome en cuenta lo siguiente: \\(\\bar{x} = 18.825\\) y \\(s = 0.907464855\\) Para realizar esta prueba, se considerar√°n las siguientes hip√≥tesis: \\(H_0: X \\sim N(18.825,0.823492)\\) (Los datos de las edades son normales, con media y varianza dadas) \\[ H_1: X \\nsim N(18.825,0.823492) \\] Seguidamente se resuelve el caso en R extremos.izquierdos &lt;- c(-Inf, 18, 19, 20, 21) extremos.derechos &lt;- c(18, 19, 20, 21, Inf) frecuencias.empiricas &lt;- c(30, 100, 50, 15, 5) u &lt;- 18.825 sigma &lt;- 0.907464855 probabilidades.teoricas &lt;- pnorm(extremos.derechos, u, sigma) - pnorm(extremos.izquierdos, u, sigma) chisq.test(frecuencias.empiricas, p = probabilidades.teoricas) ## Warning in chisq.test(frecuencias.empiricas, p = probabilidades.teoricas): ## Chi-squared approximation may be incorrect ## ## Chi-squared test for given probabilities ## ## data: frecuencias.empiricas ## X-squared = 17.472, df = 4, p-value = 0.001564 Note que aparece un mensaje indicando que la aproximaci√≥n podr√≠a ser incorrecta, ¬øA qu√© se debe esto? Se calcular√° seguidamente, las frecuencias te√≥ricas: n = sum(frecuencias.empiricas) frecuencias.teoricas &lt;- n*probabilidades.teoricas frecuencias.teoricas ## [1] 36.328356 78.963603 65.169670 17.884418 1.653953 Se puede evidencia que en la √∫ltima categor√≠a, la frecuencia es menos que 5, incumpliendo la condici√≥n necesaria. Lo anterior se puede resolver de dos maneras: 1. Se pueden fusionar intervalos 1. Se puede usar la opci√≥n de simular un p-valor con R Fusi√≥n de intervalos La tabla, quedar√≠a de la siguiente forma: Edad: X Frecuencia Observada X &lt; 18 30 18 \\(\\leq\\) X &lt; 19 100 19 \\(\\leq\\) X &lt; 20 50 Edad: X Frecuencia Observada X \\(\\geq\\) 20 20 extremos.izquierdos2 &lt;- c(-Inf, 18, 19, 20) extremos.derechos2 &lt;- c(18, 19, 20, Inf) frecuencias.empiricas2 &lt;- c(30, 100, 50, 20) u &lt;- 18.825 sigma &lt;- 0.907464855 probabilidades.teoricas2 &lt;- pnorm(extremos.derechos2, u, sigma) - pnorm(extremos.izquierdos2, u, sigma) chisq.test(frecuencias.empiricas2, p = probabilidades.teoricas2) ## ## Chi-squared test for given probabilities ## ## data: frecuencias.empiricas2 ## X-squared = 10.249, df = 3, p-value = 0.01657 Con esto se logra resolver el problema, concluyendo que se encuentra suficiente evidencia para rechazar \\(H_0\\) Simulando p-valor chisq.test(frecuencias.empiricas, p = probabilidades.teoricas, simulate.p.value = TRUE, B=2000) ## ## Chi-squared test for given probabilities with simulated p-value (based ## on 2000 replicates) ## ## data: frecuencias.empiricas ## X-squared = 17.472, df = NA, p-value = 0.003998 Note que se obtiene un ùëÉ- valor distinto, pero se coincide en la conclusi√≥n. Conclusi√≥n Se encuentra suficiente evidencia para rechazar \\(H_0\\), por lo que no se puede asumir normalidad para las edades de los estudiantes del curso Estructuras de Datos II. Dentro de este segmento de Bondad de ajuste, cobra un especial inter√©s las pruebas de normalidad, esto por cuanto si una persona desea usar pruebas param√©tricas, debe primero verificar que se cumplen las condiciones de normalidad para tal fin. El enfoque de pruebas de normalidad se puede abordar desde 3 dimensiones: Visualizaci√≥n de datos mediante Histogarmas o QQ-Plot Pruebas formales de Normalidad Evaluar simetr√≠a (skewness) y la curtosis (kurtosis) 8.1 Visualizaci√≥n de datos Para mostrar esta t√©cnica se usar√°n datos de la tabla Iris, espec√≠ficamente Sepal.with. muestra &lt;- iris$Sepal.Width par(mfrow = c(1, 2)) # crea un matriz de tama√±o 1x2 para imprimir dos gr√°ficos de manera simult√°nea hist(muestra, main=&quot;Histograma de muestra&quot;) plot(density(muestra), main=&quot;Estimaci√≥n de la densidad&quot;) De entrada, pareciera que la curva de densidad adopta una forma similar a la campana de Gauss, por lo que podr√≠a ser v√°lida la siguiente comparaci√≥n: plot(density(muestra), main = &quot;Estimaci√≥n de la densidad&quot;) # Se generan valores para estimar la distribuci√≥n normal de media y desviaci√≥n est√°andar igual a los datos de la muerta de iris x &lt;- seq(from = 1,to = 5, by = 0.01) u &lt;- mean(iris$Sepal.Width) sigma &lt;- sd(iris$Sepal.Width) lines(x, dnorm(x, mean = u, sd = sigma), col = &quot;red&quot;) Se observa en la imagen que ambas curvas son muy similares, pero ¬øser√° ese parecido suficiente para garantizar normalidad? En la siguiente secci√≥n se estudiar√°n otras t√©cnicas. Para ampliar el tema de la curva de densidad Curva de densidad|Khan Academy Otro tipo de gr√°fico que permite estudiar la normalidad de los datos es el QQ-plot, conocido como el cuantil-cuantil La funci√≥n u objetivo de este gr√°fico es comparar los cuantiles observados en la muestra con los cuantiles te√≥ricos de la distribuci√≥n te√≥rica. Para entender con m√°s detalle la forma en que se construyen este tipo de gr√°ficos, se recomienda ver el siguiente v√≠deo: QQ-plots La sintaxis para crear un QQ-plot es la siguiente: qqPlot(x, distribution=..., par√°metros, id=FALSE, ...) donde: x: vector que contiene a la muestra de datos distribution: nombre de la familia de distribuciones, la cu√°l, debe escribirse entre comillas: ‚Äúnorm‚Äù,‚Äúbinom‚Äù, ‚Äúpoisson‚Äù, ‚Äút‚Äù, etc. El QQ-plot agrega varias opciones que se pueden ocultar: Ocultar los QQ-puntos con ordenadas m√°s extremas: id = FALSE Rejilla del gr√°fico: grid = FALSE L√≠nea recta que une los QQ-puntos del primer y tercer cuartil, conocida como recta cuartil-cuartil. Se puede ocultar con line = \"none\" Curvas discontinuas que abrazan una regi√≥n de confianza de 95%. Se puede ocultar con envelope = FALSE Se pueden usar los par√°metros usuales de plot para poner nombres a los ejes, t√≠tulo, modificar el estilo de los puntos, etc., y otros par√°metros espec√≠ficos para modificar el aspecto del gr√°fico. Por ejemplo, col.lines sirve para especificar el color de las l√≠neas que a√±ade. Seguidamente se muestra el QQ-plot para el ejemplo anterior: # Cargar el paquete car library(car) ## Loading required package: carData ## ## Attaching package: &#39;car&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## recode ## The following object is masked from &#39;package:purrr&#39;: ## ## some ## The following object is masked from &#39;package:EnvStats&#39;: ## ## qqPlot # Calcular la media y la desviaci√≥n est√°ndar de Sepal.Width u &lt;- mean(iris$Sepal.Width) sigma &lt;- sd(iris$Sepal.Width) # Crear el QQ-plot qqPlot(iris$Sepal.Width, distribution = &quot;norm&quot;, mean = u, sd = sigma) ## [1] 16 34 En este caso, miesntras m√°s se ajusten los puntos a la recta, mejor es el ajuste de normalidad de los datos. Para el ejemplo anterior, se nota que la mayoria de los puntos quedaron dentro de la regi√≥n del IC de 95%, lo cu√°l es un buen indicador de normalidad. 8.2 Pruebas formales de normalidad En esta secci√≥n se estudiar√°n 4 pruebas que pueden ser de utilidad al estudiar la normalidad de los datos. 8.2.1 Test de Kolmogorov-Smirnov-Lilliefors o K-S-L test Basada en el paquete nortest lillie.test(muestra) ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: muestra ## D = 0.10566, p-value = 0.0003142 Note que en este caso la muestra detecta que s√≠ hay suficiente evidencia en contra para no aceptar normalidad en los datos, algo que gr√°ficamente parec√≠a tener esa condici√≥n. El test K-S-L tiene un inconveniente: aunque es muy sensible a las diferencias entre la muestra y la distribuci√≥n te√≥rica alrededor de sus valores medios, le cuesta detectar diferencias prominentes en un extremo u otro de la distribuci√≥n. Su potencia se ve afectada por dicho inconveniente. Veamos un ejemplo de este hecho intentando ver si una muestra de una distribuci√≥n t de Student nos acepta que es normal o no: set.seed(100) x &lt;- rt(50,3) #se generan 50 datos aleatorio de una distribuci√≥n t con 3 gl lillie.test(x) ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: x ## D = 0.10332, p-value = 0.2013 Nos dice que no podemos rechazar que la muestra x sea normal. Esto es debido a que la funci√≥n de densidad de la distribuci√≥n \\(t\\) de Student es algo m√°s aplanada que la distribuci√≥n normal, donde en los dos extremos est√° por encima de la de la normal. Como el test K-S-L no detecta las diferencias en los extremos, acepta que x es normal. 8.2.2 Test de normalidad de Anderson-Darling o A-D test El test de normalidad de Anderson-Darling resuelve el inconveniente del test de K-S-L y se est√° implementado en el paquete nortest. Note que al aplicar esta prueba al caso anterior con los valores generados de una distrubuc√≥n t, la noramlidad queda rechazada. ad.test(x) ## ## Anderson-Darling normality test ## ## data: x ## A = 1.1657, p-value = 0.004334 Ahora se le aplicar√° la prueba a la muestra de Iris ad.test(muestra) ## ## Anderson-Darling normality test ## ## data: muestra ## A = 0.90796, p-value = 0.02023 Donde el resulta indica por su p-valor, que no se debe aceptar normalidad de los datos. 8.2.3 Test de Shapiro-Wilks o S-W test Un inconveniente com√∫n a los tests K-S-L y A-D es que, si bien pueden usarse con muestras peque√±as (pongamos de m√°s de 5 elementos), se comportan mal con muestras grandes, de varios miles de elementos. En muestras de este tama√±o, cualquier peque√±a divergencia de la normalidad se magnifica y en estos dos tests aumenta la probabilidad de errores de tipo I. Un test que viene a resolver el problema es Shapiro-Wilk que se encuentra por defecto en R. Se aplica la prueba a los dos casos trabajados anteriormente: shapiro.test(muestra) ## ## Shapiro-Wilk normality test ## ## data: muestra ## W = 0.98492, p-value = 0.1012 Note que en este caso no se encontr√≥ evidencia en contra para asumir normalidad, cosa que no ocurri√≥ con las otras pruebas y posiblemente por una raz√≥n, esta muestra consta de 150 datos, un tama√±o grande para las pruebas anteriores de K-S-L y A-D. shapiro.test(x) ## ## Shapiro-Wilk normality test ## ## data: x ## W = 0.89494, p-value = 0.0003285 El el otro caso donde se simularon datos de una distribuci√≥n t-student, se concluye que la normalidad para los datos no es una condici√≥n v√°lida de asumir, claro est√° que los datos provienen de una distribuci√≥n t-student. Si nuestra muestra de valores tiene empates, los p-valores de los contrastes calculados a partir de las distribuciones de los estad√≠sticos usados en los tests K-S-L, A-D y S-W se pueden ver afectados hasta el punto de que, si hay muchos empates, su significado no tenga ning√∫n sentido. Hay que decir que el menos afectado por los empates es el test de S-W. 8.2.4 Test omnibus de D‚ÄôAgostino-Pearson Un test que no es sensible a los empates es el test de normalidad de D‚ÄôAgostino Pearson. Este test se encuentra implementado en la funci√≥n dagoTest del paquete fBasics, y lo que hace es cuantificar los diferentes que son la asimetr√≠a y la curtosis de la muestra (dos par√°metros estad√≠sticos relacionados con la forma de la gr√°fica de la funci√≥n de densidad muestral) respecto de los esperados en una distribuci√≥n normal, y resume esta discrepancia en un p-valor con el significado usual. No debe darse mucha relevancia a los datos de STATISTIC en este caso, pues esto difieren, como se ver√° m√°s adelante, de los valores de curtosis y simetr√≠a dados por otras funciones de R, posiblemente porque los valores dados no corresponden espec√≠ficamente a valores en las distribuciones donde se realizan los tres tests: chi cuadrado, simetr√≠a y curtosis. Se priorizar√° el valor P de cada prueba. Para poder aplicar dicho test, el tama√±o de la muestra debe ser 20 como m√≠nimo. dagoTest(x) ## ## Title: ## D&#39;Agostino Normality Test ## ## Test Results: ## STATISTIC: ## Chi2 | Omnibus: 21.8125 ## Z3 | Skewness: 2.8069 ## Z4 | Kurtosis: 3.7328 ## P VALUE: ## Omnibus Test: 1.834e-05 ## Skewness Test: 0.005001 ## Kurtosis Test: 0.0001894 Vemos que seg√∫n el test de D‚ÄôAgostino-Pearson, la muestra x correspondiente a la distribuci√≥n t de Student no sigue una distribuci√≥n normal, pues todos los valores P est√°n por debajo de 0.05. dagoTest(muestra) ## ## Title: ## D&#39;Agostino Normality Test ## ## Test Results: ## STATISTIC: ## Chi2 | Omnibus: 3.1238 ## Z3 | Skewness: 1.616 ## Z4 | Kurtosis: 0.7157 ## P VALUE: ## Omnibus Test: 0.2097 ## Skewness Test: 0.1061 ## Kurtosis Test: 0.4742 En este caso admite normalidad para los datos. Si se desea calcular la curtosis y la simetr√≠a, se pueden usar las siguiente funciones del paquete moments: curtosis &lt;- kurtosis(x) simetria &lt;- skewness(x) plot (density(x), main = &quot;Normal&quot;, xlab = paste(&quot;Curtosis &quot;, round(curtosis, 2), &quot;\\n&quot;, &quot;Simetr√≠a &quot;, round(simetria,2))) curtosis &lt;- kurtosis(muestra) simetria &lt;- skewness(muestra) plot (density(muestra), main = &quot;Normal&quot;, xlab = paste(&quot;Curtosis &quot;, round(curtosis, 2), &quot;\\n&quot;, &quot;Simetr√≠a &quot;, round(simetria,2))) Para interpretaciones, considere lo siguiente: **Simetr√≠a hace referencia a la distancia de la media al menor valor en la proporci√≥n a la distancia de la media al valor mayor. Simetr√≠a hace referencia a la distancia de la media al menor valor en proporci√≥n a la distancia de la media al valor mayor. Si el valor de la simetr√≠a se acerca a 0, indica que la distribuci√≥n es sim√©trica, es decir ambos valores extremos est√°n aproximadamente a la misma distancia de la media. Si el valor de la simetr√≠a es positivo (S &gt; 0) indica que el valor menor est√° m√°s cerca de la media que el valor mayor, inclinando la media hacia la izquierda. Si el valor de la simetr√≠a es negativo (S &lt; 0) indica que el valor mayor est√° m√°s cerca de la media que el valor menor, inclinando la media hacia la derecha. Figure 8.1: Simetr√≠a en la distribuci√≥n de los datos La curtosis indica qu√© tan pronunciada es la forma de campana en una distribuci√≥n normal. Una curtosis muy alta denota una campana alargada y con las colas muy bajas - Leptoc√∫rtica Un valor intermedio denota una campana ‚Äúideal‚Äù con la punta semicircular y la curva de las colas pronunciada - Mesoc√∫rtica Una curtosis muy baja indica una campana chata y ancha con la curva de las colas poco pronunciada - Platic√∫rtica En una distribuci√≥n normal ‚Äúideal‚Äù, la curtosis tiene un valor cercano a 3. Figure 8.2: Forma de la curva seg√∫n el tipo de curtosis "],["prueba-de-independencia.html", "Cap√≠tulo 9 Prueba de Independencia", " Cap√≠tulo 9 Prueba de Independencia Se utiliza la misma funci√≥n de chisq.test con el siguiente formato: chisq.test(tabala.contingencia, correct) donde: tabla.contingencia: es la tabla de contiengencia o de frecuencias emp√≠ricas(tomadas de la muestra) correct: es un par√°metro l√≥gico. Se usa TRUE si se desea aplicar una correcci√≥n a la continuidad para tablas de 2x2. Ejemplo 3: Los empleados de una empresa trabajan una jornada de 8 horas distribuidas en dos tandas de horario: el primero corresponde al bloque de la ‚Äúma√±ana‚Äù en horario 8:00- 12:00, luego se da una hora para el almuerzo y posteriormente llega el bloque de la ‚Äútarde‚Äù en horario 13:00-17:00. Se valor√≥ si su desempe√±o, en cada uno de los bloques (ma√±ana o tarde), era bueno, regular o malo. Con un nivel de significancia del 5%, ¬øse puede asegurar que el desempe√±o de los empleados en ambos bloques de horarios son independientes? Bueno Regular Malo Bueno 56 71 12 Regular 47 163 38 Malo 14 42 85 Se plantean las siguientes hip√≥tesis: Sea \\(X\\): desempe√±o en la ma√±ana y \\(Y\\): desempe√±o en la tarde \\(H_0\\): \\(X\\) e \\(Y\\) son independientes. \\(H_1\\): \\(X\\) e \\(Y\\) no son independientes. Seguidamente se resuelve el problema en R: chisq.test(matrix(c(56, 71, 12, 47, 163, 38, 14, 42, 85), 3, 3, byrow = T)) ## ## Pearson&#39;s Chi-squared test ## ## data: matrix(c(56, 71, 12, 47, 163, 38, 14, 42, 85), 3, 3, byrow = T) ## X-squared = 145.78, df = 4, p-value &lt; 2.2e-16 Conclusi√≥n No se puede aceptar independencia del desempe√±o de los empleados entre los dos bloques de horario de trabajo. "],["prueba-de-analisis-de-varianza-anova.html", "Cap√≠tulo 10 Prueba de Analisis de Varianza (ANOVA)", " Cap√≠tulo 10 Prueba de Analisis de Varianza (ANOVA) Para realizar la prueba de an√°lisis de varianza, utilizaremos la funci√≥n aov del paquete stats. Ejemplo 4: Se quiere determinar si la dosis de determinado tratamiento (Baja, Media, Alta) influye en el tiempo de sue√±o (en minutos) de los que la consumen. Se plantea el problema de determinar si la tiempos de sue√±o var√≠an o no, seg√∫n la dosis del medicamento. ¬øPuede afirmarse que los tiempos de sue√±o no var√≠an seg√∫n la dosis de medicamento?, use un nivel de significancia de 5%. Para responder al problema planteado, se cuenta con los siguientes datos tomados de varios voluntarios expuestos a la aplicaci√≥n de 3 dosis de medicamento (Alta, Media, Baja), registrando el n√∫mero de minutos que duerme, una vez injerido la dosis: Baja Media Alta 67 96 74 69 98 24 72 130 15 79 65 33 17 Se plantean las siguientes hip√≥tesis: Sea: \\(X\\) : tiempo de sue√±o de los clientes que consumen el tratamiento (Variable cuantitiativa) \\(Y\\) : las dosis de medicamento sumininstradas a los clientes (Variable cualitativa) \\(\\mu_1\\), \\(\\mu_2\\) y \\(\\mu_3\\) respectivamente los tiempos promedio de sue√±o de los clientes para cada una de las d√≥sis \\(H_0\\) : \\(\\mu_1 = \\mu_2 = \\mu_3\\) \\(H_1\\): al menos dos de las medias no son iguales. Los datos mostados en la tabla anterior, no pueden ser le√≠dos en R de manera adecuada para realizar un an√°lisis de varianza, por lo que se procede a cargar estos datos en el siguiente formato: datos &lt;- read.csv(&quot;DosisSueno.csv&quot;, sep = &quot;;&quot;) head(datos, 5) ## tiempo dosis ## 1 67 B ## 2 69 B ## 3 72 B ## 4 79 B ## 5 96 M Aplicamos la prueba de varianza: aov(tiempo ~ dosis, data = datos) ## Call: ## aov(formula = tiempo ~ dosis, data = datos) ## ## Terms: ## dosis Residuals ## Sum of Squares 9588.531 4538.700 ## Deg. of Freedom 2 10 ## ## Residual standard error: 21.30422 ## Estimated effects may be unbalanced Los datos de la prueba anterior, se pueden mostrar de la siguiente forma, a manera de resumen: summary(aov(tiempo ~ dosis, data = datos)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## dosis 2 9589 4794 10.56 0.00342 ** ## Residuals 10 4539 454 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 En esta prueba el p-valor est√° dado por el resultado Pr(&gt;F), que en este caso al ser menor que \\(a\\), se rechaza la hip√≥tesis nula. Otros datos importantes que podemos extraer del resumen de la prueba: SSA: 9589 SSE: 4539 SST=SSA+SSE = 9589 + 4539 = 14128 \\[ f_{obs} = 10.56 \\\\ \\text{valor} \\; p = 0.00342 \\] gl dosis = 2 gl datos o residuales = 10 El resultado anterior s√≥lo indica que existe afectaci√≥n de la dosis en el tiempo de sue√±o de las personas, pero no provee informaci√≥n detallada acerca de qu√© forma viene dada dicha afectaci√≥n. Para despejar esta duda, se recomienda utilizar la prueba Tuckey que permite calcular la diferencia de impacto de cada calor en cla variable independiente. # Almacenamos la prueba de ANOVA en una nueva variable anova.dosis.sueno &lt;- aov(tiempo ~ dosis, data = datos) #Pasamo la prueba ANOVa a la prueba Tuckey TukeyHSD(anova.dosis.sueno) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = tiempo ~ dosis, data = datos) ## ## $dosis ## diff lwr upr p adj ## B-A 39.15 -0.0266945 78.32669 0.0501530 ## M-A 64.65 25.4733055 103.82669 0.0028702 ## M-B 25.50 -15.7958619 66.79586 0.2550212 Del resumen anterior, debe comprenderse lo siguiente: diff: corresponde a la resta de los promedios muestrales entre las dos categor√≠as comparadas. Por ejemplo, \\(M - B\\) corresponde a \\(\\bar{x_2} - \\bar{x_1} = 97.5 ‚àí 71.75 = 25.5\\) lwr: extremo izquierdo del IC upr: extremo derecho del IC p adj: valorP ajustado (para efectos pr√°cticos, el valor \\(P\\) de la prueba) Conclusi√≥n: La prueba muestra que hay una diferencia significativa entre dosis Media y Alta donde \\(\\text{valor} \\; P = 0.0028702 &lt; a = 0.05\\), no as√≠ en el resto de comparaciones. Sin embargo, el valor p en el caso de la comparaci√≥n Baja con Alta, result√≥ estar al l√≠mite de ser rechazada, pero no puede rechazarse porque en el IC reportado el cero para la diferencia de medias est√° presente. "],["regresion-y-correlacion-lineal.html", "Cap√≠tulo 11 Regresion y correlacion lineal 11.1 Generando el modelo de regresion 11.2 Coeficientes de determinaci√≥n y correlacion 11.3 Prueba para los residuos 11.4 Intervalos de confianza para la pendiente y el intercepto 11.5 Intervalo de confianza y prediccion 11.6 Constraste de hipotesis 11.7 Comprobacion de las variabilidades presentes 11.8 Cuidado con el coeficiente de correlacion y de determinaci√≥n 11.9 EJEMPLO 2: CORRELACIONES", " Cap√≠tulo 11 Regresion y correlacion lineal C√≥mo se ha estudado durante las clases, es importante comprender la diferencia entre lo que es regresi√≥n y correlaci√≥n: Regresi√≥n lineal: donde una variable (exploratoria) es utilizada para predecir los valores de la otra variable (respuesta). Correlaci√≥n: donde se mide la intensidad de la relaci√≥n lineal entre las variables. En este material, vamos a conocer algunas herramientas que ofrece R a sus usuarios para el trabajo, tanto de la Regresi√≥n Lineal Simple, el caso en una variable, como de la Correlaci√≥n. Seguidamente, los paquetes que vamos a utilizar: library(stats) library(ggplot2) library(nortest) library(corrplot) ## corrplot 0.94 loaded library(corrr) library(ggcorrplot) 11.1 Generando el modelo de regresion Ejemplo 1 En un experimento donde se quer√≠a estudiar la asociaci√≥n entre consumo de sal y presi√≥n arterial, se asign√≥ aleatoriamente a algunos individuos una cantidad diaria constante de sal en su dieta, y al cabo de un mes se les midi√≥ la presi√≥n arterial media. Algunos resultados fueron los siguientes: \\(X\\)(sal en g) \\(Y\\)(presi√≥n en mm de Hg) 1.8 100 2.2 98 3.5 110 4.0 110 4.3 112 5.0 120 Vamos a hallar la recta de regresi√≥n lineal por m√≠nimos cuadrados de \\(Y\\) en funci√≥n de \\(X\\), usando la funci√≥n lm que calcula el ajuste lineal usando la t√©cnica de m√≠nimos cuadrados: # Creamos la tabla de valores sal &lt;- c(1.8, 2.2, 3.5, 4.0, 4.3, 5.0) # vector datos de sal tension &lt;- c(100, 98, 110, 110, 112, 120) # vector de datos de presi√≥n datos.sal &lt;- cbind(sal, tension) # se juntan las columnas datos.sal.df &lt;- as.data.frame(datos.sal) # se crea un objeto dataframe names(datos.sal.df) # verificamos los nombres de las columnas ## [1] &quot;sal&quot; &quot;tension&quot; # Se crea un gr√°fico de dispersi√≥n para ver de manera exporatoria los datos gsal &lt;- ggplot(datos.sal.df, aes(sal, tension)) gsal + geom_point(width = 0.3, alpha = 0.4) ## Warning in geom_point(width = 0.3, alpha = 0.4): Ignoring unknown parameters: ## `width` modelo &lt;- lm(tension ~ sal, data = datos.sal.df) modelo ## ## Call: ## lm(formula = tension ~ sal, data = datos.sal.df) ## ## Coefficients: ## (Intercept) sal ## 86.371 6.335 Por tanto, el modelo de RLS para los datos ser√≠a \\(\\text{tension} = 86.371 + 6.335 \\cdot sal\\) 11.2 Coeficientes de determinaci√≥n y correlacion Para medir la calidad del modelo, hacemos uso del Coeficiente de correlarci√≥n y el Coeficiente de determinaci√≥n, haciendo uso nuevamente de la funci√≥n lm y la herramienta summary junto con el par√°metro r.squared. ## Coeficiente de determinaci√≥n summary(lm(tension ~ sal))$r.squared ## [1] 0.9343685 ## Coeficiente de correlaci√≥n sqrt(summary(lm(tension ~ sal))$r.squared) ## [1] 0.9666274 En el caso anterior se puede indicar que, como $R = 0.9666274 $ la correlaci√≥n lineal entre los datos consumo de sal y presi√≥n es fuerte y positiva. Por otra parte como \\(R^2 = 0.9343685\\), se interpreta que el \\(93.44\\%\\) de la variaci√≥n en la presi√≥n arterial, se debe a la variaci√≥n en el consumo de sal, el restante \\(6.56\\%\\) se debe a otros factores. Otra forma de calcular las correlaciones, se presentan en los siguientes chunks: c &lt;- cor(datos.sal) c ## sal tension ## sal 1.0000000 0.9666274 ## tension 0.9666274 1.0000000 # Se toma solo la celda que contiene la correlaci√≥n de inter√©s c[1,2] ## [1] 0.9666274 c[2, 1] ## [1] 0.9666274 Note que la funci√≥n corgenera una matriz de correlaciones, que en este caso los valores de la diagonal no tienen sentido, porque al ser la relaci√≥n entre cada variable consigomisma, esta siempre es 1, es perfecta. La matriz resulta m√°s interesante cuando tenemos m√°s variables para comparar en nuestra base de datos, pero en este caso solo tenemos dos. Note que las celdas c[1,2] y c[2,1] tienen el mismo resultado para la correlaci√≥n, esto se debe a lo estudiado en clase donde este estad√≠stico nos indica el grado o fuerza de dependencia lineal entre las variables, pero no discrimina entre variables respuesta o exploratoria, as√≠ la correlaci√≥n de \\(X\\) con \\(Y\\), es igual a la correlaci√≥n de \\(Y\\) con \\(X\\). Existen versiones gr√°ficas que permiten ver de forma visual las correlaciones: corrplot(c) # cargue el paquete corrplot ggcorrplot(c) Desde luego, que estas herramientas resultan m√°s interesantes cuando se trata de ver correlaciones entre m√°s combinaciones de casos. Al final de este documento, a manera de ejemplo, se mostrar√° un ejemplo como complemento para el lector. Seguidamente, graficamos los puntos junto con el modelo de Regresi√≥n Lineal Simple que encontramos: gsal + geom_point(width = 0.3, alpha = 0.4) + geom_smooth(method = &quot;lm&quot;) ## Warning in geom_point(width = 0.3, alpha = 0.4): Ignoring unknown parameters: ## `width` ## `geom_smooth()` using formula = &#39;y ~ x&#39; La funci√≥n geom_smooth con la opci√≥n para el par√°metromethod = \"lm\" dibuja por defecto una franja sombreada alrededor de la recta de ajuste que representa el IC de \\(95%\\) para el modelo (corresponde al IC para \\(\\mu_{y|x_0}\\)), no obstante, este IC puede ser modificado a preferencia del usuario mediante el par√°metro level. A manera de ejemplo, se vuelve a realizar el gr√°fico anterior, pero usando respectivamente un IC de \\(90\\%\\) y de \\(99\\%\\): gsal + geom_point(width = 0.3, alpha = 0.4) + geom_smooth(method = &quot;lm&quot;, level = 0.90) ## Warning in geom_point(width = 0.3, alpha = 0.4): Ignoring unknown parameters: ## `width` ## `geom_smooth()` using formula = &#39;y ~ x&#39; gsal + geom_point(width = 0.3, alpha = 0.4) + geom_smooth(method = &quot;lm&quot;, level = 0.99) ## Warning in geom_point(width = 0.3, alpha = 0.4): Ignoring unknown parameters: ## `width` ## `geom_smooth()` using formula = &#39;y ~ x&#39; 11.3 Prueba para los residuos Uno de los principios que debe cumplir un grupo de datos para ser sujeta a ajustarse de forma lineal, es que la distribuci√≥n de sus errores o residuos se comporten de manera normal. Seguidamente se har√° una prueba de normalidad para estos residuos. b0 &lt;- 86.371 b1 &lt;- 6.335 tension.estimada &lt;- b0 + b1*datos.sal.df$sal errores &lt;- tension.estimada - datos.sal.df$tension lillie.test(errores) ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: errores ## D = 0.2803, p-value = 0.147 Como \\(P - \\text{valor}\\) es grande, no existe evidencia suficiente para rechazar \\(H_0\\), por tanto se puede asumir normalidad para dichos errores, por lo que se cumplir√≠a el principio. 11.4 Intervalos de confianza para la pendiente y el intercepto Para hallar los intervalos de confianza de los par√°metros \\(\\beta_0\\) y \\(\\beta_1\\) en \\(R\\) hay que aplicar la funci√≥n confint al objeto lm(...). El par√°metro level nos da el nivel de confianza cuyo valor por defecto es \\(\\textbf{0.95}\\). confint(lm(datos.sal.df$tension ~ datos.sal.df$sal),level = 0.95) ## 2.5 % 97.5 % ## (Intercept) 77.869064 94.872509 ## datos.sal.df$sal 4.004434 8.666266 11.5 Intervalo de confianza y prediccion Tambi√©n se estudi√≥ en clases el c√°clulo del Intervalo de Confianza para \\(\\mu_{Y|x=x_0}\\), es decir, un IC para la media de los valores \\(Y\\) que se pueden generar para un valor fijo de \\(x = x_0\\). Para realizar dichos c√°lculo en \\(R\\) se utilizar√° la funci√≥n predict.lm del paquete stats. # Para un dato x0 &lt;- data.frame(sal = 4.5) predict.lm(modelo, x0, interval = &quot;confidence&quot;, level = 0.95) ## fit lwr upr ## 1 114.8799 111.3041 118.4556 # Para una lista de datos x0s &lt;-data.frame(sal = c(4.5, 3.1, 2.35)) predict.lm(modelo, x0s, interval = &quot;confidence&quot;, level = 0.95) ## fit lwr upr ## 1 114.8799 111.30410 118.4556 ## 2 106.0104 103.23276 108.7880 ## 3 101.2589 97.54948 104.9682 Si se toma una persona al azar que consume una cantidad definida de sal, tambi√©n podemos calcular un Intervalo de Predicci√≥n para el dato correspondiente a la presi√≥n, haciendo interval = ‚Äúprediction‚Äù como se muestra en el siguiente c√≥digo: # Para un dato x0 &lt;- data.frame(sal = 4.5) predict.lm(modelo, x0, interval = &quot;prediction&quot;, level = 0.95) ## fit lwr upr ## 1 114.8799 107.4843 122.2754 # Para una lista de datos x0s &lt;-data.frame(sal = c(4.5, 3.1, 2.35)) predict.lm(modelo, x0s, interval = &quot;prediction&quot;, level = 0.95) ## fit lwr upr ## 1 114.8799 107.48433 122.2754 ## 2 106.0104 98.96601 113.0547 ## 3 101.2589 93.79780 108.7199 11.6 Constraste de hipotesis Para el contraste de hip√≥tesis en R, se debe usar nuevamente la herramienta summary aplicada al modelo generado mediante la funci√≥n lm. Tome en cuenta que para esta prueba: \\[ H_0: \\beta = 0 \\\\ H_1: \\beta \\neq 0 \\\\ \\] summary(modelo) ## ## Call: ## lm(formula = tension ~ sal, data = datos.sal.df) ## ## Residuals: ## 1 2 3 4 5 6 ## 2.226 -2.309 1.455 -1.712 -1.613 1.952 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 86.3708 3.0621 28.206 9.4e-06 *** ## sal 6.3354 0.8395 7.546 0.00165 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.332 on 4 degrees of freedom ## Multiple R-squared: 0.9344, Adjusted R-squared: 0.918 ## F-statistic: 56.95 on 1 and 4 DF, p-value: 0.001652 Del informe anterior interesa los estimadores del intercepto y la pendiente, as√≠ el modelo de regresi√≥n lineal coincide con el encontrado previamente. El Std. Error no ser√° relevante en este an√°lisis, el \\(t \\; \\text{value}\\) corresponde al valor del \\(t_{obs}\\) de la prueba de hip√≥tesis y al final de cada l√¨nea vemos el Valor P indicando que los coeficientes estimados son estad√¨sticamete significativos, al ser un valor menor que el nivel de significancia de la prueba \\(a = 0.05\\). Al rechazar \\(H_0\\) en este caso, se est√° indicando que existe dependencia lineal entre las variables. En la l√≠nea final tenemos el Residual standar error, el cu√°l se calcula de la siguiente manera: # Residual standar error (RSE) residuals &lt;- c(2.226, -2.309, 1.455, -1.712, -1.613, 1.952 ) RSE &lt;- sqrt(sum(residuals^2)/4) RSE ## [1] 2.331662 Note que el modelo posee 4 grados de libertad \\((n-2)\\), dos valores para el coeficiente de determinaci√≥n: Multiple R-squared corresponde al valor que hemos trabajado en el curso este es recomendable para un modelo RLS, en caso de que se incluyan m√°s variables como en los modelos de RLM (Regresi√≥n Lineal M√∫ltiple) debe preferirse el Adjusted R-squared porque contempla una penalizaci√≥n debido a la inclusi√≥n de m√°s variables al modelo que lo hacen m√°s complejo. Finalmente F-statistic corresponde al cuadrado del \\(t_{obs}\\) asociado a la pendiente del modelo y el p-value que aparece al final, es el que usamos para contrastar \\(H_0\\) y es el mismo valor asociado al valor de P de la pendiente. 11.7 Comprobacion de las variabilidades presentes Se estudi√≥ en la clase que, la suma de la variabilidad total\\((SS_T)\\), es igual a la variabilidad del modelo de regresi√≥n \\((SS_R)\\) m√°s la variabilidad asociada al error \\((SS_E)\\), as√≠, si la variabilidad del modelo es similar a la variabilidad total, entonces el modelo ser√≠a muy preciso y bueno, caso contrario se debe pensar en otro modelo que no sea lineal. Los anterior, se resume en la siguiente ecuaci√≥n: \\[ SS_T = SS_R + SS_E \\] Seguidamente, se comprobar√° que esta ecuaci√≥n se cumple para el caso en estudio. Variabilidad total: tension.media &lt;- mean(tension) SST &lt;- sum((tension - tension.media)^2) SST ## [1] 331.3333 Variabilidad de la regresion: tension.estimada &lt;- b0 + b1*sal SSR &lt;- sum((tension.estimada - tension.media)^2) SSR ## [1] 309.5532 Variabilidad asociada al error: SSE &lt;- sum((tension - tension.estimada)^2) SSE ## [1] 21.7459 Comprobando la igualdad: SST ## [1] 331.3333 SSR + SSE ## [1] 331.2991 11.8 Cuidado con el coeficiente de correlacion y de determinaci√≥n Usar solamente el coeficiente de determinaci√≥n para medir la calidad de la regresi√≥n es un error, pues nos pone en riesgo de hacer conjeturas sobre un modelo cuyos datos pordr√≠an confundir su significado. Tenemos que observar m√°s informaci√≥n para poder afirmar que la regresi√≥n obtenida es adecuada y se ajusta bien a nuestros datos, as√≠ la correlaci√≥n debe ir acompa√±ada de otros filtros complementarios. En R existe una tabla de datos denominada anscombe que pone de manifiesto este hecho. Vamos a echarle un vistazo: data(anscombe) str(anscombe) ## &#39;data.frame&#39;: 11 obs. of 8 variables: ## $ x1: num 10 8 13 9 11 14 6 4 12 7 ... ## $ x2: num 10 8 13 9 11 14 6 4 12 7 ... ## $ x3: num 10 8 13 9 11 14 6 4 12 7 ... ## $ x4: num 8 8 8 8 8 8 8 19 8 8 ... ## $ y1: num 8.04 6.95 7.58 8.81 8.33 ... ## $ y2: num 9.14 8.14 8.74 8.77 9.26 8.1 6.13 3.1 9.13 7.26 ... ## $ y3: num 7.46 6.77 12.74 7.11 7.81 ... ## $ y4: num 6.58 5.76 7.71 8.84 8.47 7.04 5.25 12.5 5.56 7.91 ... anscombe ## x1 x2 x3 x4 y1 y2 y3 y4 ## 1 10 10 10 8 8.04 9.14 7.46 6.58 ## 2 8 8 8 8 6.95 8.14 6.77 5.76 ## 3 13 13 13 8 7.58 8.74 12.74 7.71 ## 4 9 9 9 8 8.81 8.77 7.11 8.84 ## 5 11 11 11 8 8.33 9.26 7.81 8.47 ## 6 14 14 14 8 9.96 8.10 8.84 7.04 ## 7 6 6 6 8 7.24 6.13 6.08 5.25 ## 8 4 4 4 19 4.26 3.10 5.39 12.50 ## 9 12 12 12 8 10.84 9.13 8.15 5.56 ## 10 7 7 7 8 4.82 7.26 6.42 7.91 ## 11 5 5 5 8 5.68 4.74 5.73 6.89 Note que si calculamos los coeficientes de determinaci√≥n para las 4 parejas, se obtiene un resultado similar: summary(lm(y1~x1,data=anscombe))$r.squared ## [1] 0.6665425 summary(lm(y2~x2,data=anscombe))$r.squared ## [1] 0.666242 summary(lm(y3~x3,data=anscombe))$r.squared ## [1] 0.666324 summary(lm(y4~x4,data=anscombe))$r.squared ## [1] 0.6667073 En cambio, si vemos su representaci√≥n gr√°fica, su aspecto es muy distinto: par(mfrow = c(2, 2)) g1 &lt;- ggplot(anscombe, aes(x1, y1)) g1 + geom_point(width = 0.3, alpha = 0.4) + geom_smooth(method = &quot;lm&quot;) ## Warning in geom_point(width = 0.3, alpha = 0.4): Ignoring unknown parameters: ## `width` ## `geom_smooth()` using formula = &#39;y ~ x&#39; g2 &lt;- ggplot(anscombe, aes(x2, y2)) g2 + geom_point(width = 0.3, alpha = 0.4) + geom_smooth(method = &quot;lm&quot;) ## Warning in geom_point(width = 0.3, alpha = 0.4): Ignoring unknown parameters: ## `width` ## `geom_smooth()` using formula = &#39;y ~ x&#39; g3 &lt;- ggplot(anscombe, aes(x3, y3)) g3 + geom_point(width = 0.3, alpha = 0.4) + geom_smooth(method = &quot;lm&quot;) ## Warning in geom_point(width = 0.3, alpha = 0.4): Ignoring unknown parameters: ## `width` ## `geom_smooth()` using formula = &#39;y ~ x&#39; g4 &lt;- ggplot(anscombe, aes(x4, y4)) g4 + geom_point(width = 0.3, alpha = 0.4) + geom_smooth(method = &quot;lm&quot;) ## Warning in geom_point(width = 0.3, alpha = 0.4): Ignoring unknown parameters: ## `width` ## `geom_smooth()` using formula = &#39;y ~ x&#39; Observamos que en el caso de la tabla de datos \\((x1, y1)\\) ha sido un modelo bueno, \\((x3, y3)\\) es bueno pero tiene el problema de outlier (valores extremos), la recta de regresi√≥n ha sido efectiva pero en los dem√°s hemos obtenido un error considerable, por ejemplo \\((x2, y2)\\) presenta una curvatura y el peor caso es el de la tabla de datos \\((x4, y4)\\). Por tanto, considerar s√≥lo el valor del coeficiente de determinaci√≥n para medir el ajuste de la recta de regresi√≥n a nuestros datos no es conveniente. EL recurso gr√°fico es bastante √∫til en estos casos, pues permite visualizar lo que est√° ocurriendo. 11.9 EJEMPLO 2: CORRELACIONES El siguiente ejemplo toma los datos correspondientes a las notas de 6 estudiantes, obtenidas en los cursos de Matem√°ticas, Ciencias, Espa√±ol, Historia y Educaci√≥n F√≠sica. estudiantes &lt;- read.csv(&quot;./data/EjemploEstudiantes.csv&quot;, sep = &quot;;&quot;, dec =&quot;,&quot;, header = T,row.names = 1) head(estudiantes) ## Matematicas Ciencias Espanol Historia EdFisica ## Lucia 7.0 6.5 9.2 8.6 8.0 ## Pedro 7.5 9.4 7.3 7.0 7.0 ## Ines 7.6 9.2 8.0 8.0 7.5 ## Luis 5.0 6.5 6.5 7.0 9.0 ## Andres 6.0 6.0 7.8 8.9 7.3 ## Ana 7.8 9.6 7.7 8.0 6.5 Seguidamente calculamos las correlaciones para todas las variables (asignaturas) presentes en la base de datos: c &lt;- cor(estudiantes) c ## Matematicas Ciencias Espanol Historia EdFisica ## Matematicas 1.0000000 0.8106706 0.4786264 0.1168622 -0.7942102 ## Ciencias 0.8106706 1.0000000 -0.1077795 -0.3979567 -0.6602394 ## Espanol 0.4786264 -0.1077795 1.0000000 0.7453201 -0.2296214 ## Historia 0.1168622 -0.3979567 0.7453201 1.0000000 -0.2488004 ## EdFisica -0.7942102 -0.6602394 -0.2296214 -0.2488004 1.0000000 Pueden usar redondeo a dos decimales: c &lt;- round(cor(estudiantes), 2) c ## Matematicas Ciencias Espanol Historia EdFisica ## Matematicas 1.00 0.81 0.48 0.12 -0.79 ## Ciencias 0.81 1.00 -0.11 -0.40 -0.66 ## Espanol 0.48 -0.11 1.00 0.75 -0.23 ## Historia 0.12 -0.40 0.75 1.00 -0.25 ## EdFisica -0.79 -0.66 -0.23 -0.25 1.00 Veamos seguidamente algunos modelos gr√°ficos: # Explore otras opciones: corrplot(c, method = &quot;number&quot;) / corrplot(c, method = &quot;square&quot;) / corrplot(c, method = &quot;ellipse&quot;) / corrplot(c, method = &quot;pie&quot;) / corrplot(c, method = &quot;shade&quot;) / corrplot(c, method = &quot;shade&quot;,type = &quot;upper&quot;) / corrplot(c, method = &quot;shade&quot;, type = &quot;low&quot;) corrplot(c) #requiere el paqeute corrplot # Explore: ggcorrplot(c, method = &quot;circle&quot;) / ggcorrplot(c, method = &quot;square&quot;, lab = TRUE) / ggcorrplot(c) # Usaremos funciones del paquete ggcorrplot # Se crea un data frame c_df &lt;- correlate(estudiantes) # Usa el paquete corrr ## Correlation computed with ## ‚Ä¢ Method: &#39;pearson&#39; ## ‚Ä¢ Missing treated using: &#39;pairwise.complete.obs&#39; # Explore: rplot(cor_df, colours = c(&quot;yellow&quot;,&quot;white&quot;,&quot;red&quot;)) / rplot(cor_df, shape = 2, colours = c(&quot;yellow&quot;,&quot;white&quot;,&quot;red&quot;)) / rplot(cor_df, shape = 2, colours = c(&quot;yellow&quot;,&quot;white&quot;,&quot;red&quot;), print_cor = TRUE) / rplot(c_df) Finalmente, se tiene una variante m√°s que se basa en l√≠neas de conexi√≥n. Para interpretar la intensidad de la correlaci√≥n, tome en cuenta el grosor de las l√≠neas, las tonalidades de los colores seg√∫n la escala que aparece a la derecha, mientras m√°s rojo: fuerte y decreciente o negativa, mientras m√°s azul: fuerte y creciente y cercana a blanco: no hay correlaci√≥n o muy d√©bil # Otro gr√°fico interesante de correlaciones network_plot(c_df) # Paquete corrr "],["regresion-no-lineal-simple.html", "Cap√≠tulo 12 Regresion no lineal simple", " Cap√≠tulo 12 Regresion no lineal simple En este material se trabajar√°n algunos ejemplos que ilustran la forma en que se puede proceder a la modelaci√≥n de datos mediante el Regresi√≥n No Lineal Simple. En adelante, se usar√° las siguientes abreviaturas: Modelo de Regresi√≥n Lineal Simple: MRLS Modelo de Regresi√≥n No Lineal Simple: MRNLS Seguidamente, los paquetes que vamos a utilizar: #library(stats) library(ggplot2) #library(nortest) Ejemplo 1: Considere los datos de la siguiente tabla: X Y 18 19 19 40 19.5 79 19.7 130 19.9 397 Escoja y justifique un modelo de regresi√≥n para ùëå como funci√≥n de ùëã, sabiendo que la variable ùëã por su naturaleza, toma valores menores que 20. Determine el valor esperado de \\(Y\\) cuando \\(x = 17\\) Determine un Intervalo de Confianza para los par√°metros \\(\\alpha\\) y \\(\\beta\\), seg√∫n el modelo escogido previamente. Para escoger el modelo, se recomienda primeramente construir un gr√°fico de dispersi√≥n para ver la tendencia de los datos: # Creamos la tabla de valores X &lt;- c(18, 19, 19.5, 19.7, 19.9) Y &lt;- c(19, 40, 79, 130, 397) datos &lt;- cbind(X, Y) # se juntan las columnas datos.df &lt;- as.data.frame(datos) # se crea un objeto dataframe names(datos.df) # verificamos los nombres de las columnas ## [1] &quot;X&quot; &quot;Y&quot; # Se crea un gr√°fico de dipsersi√≥n para ver de manera exporatoria los datos g1 &lt;- ggplot(datos.df, aes(X, Y)) g1 + geom_point(shape = 21, width = 0.3, alpha = 0.4, fill = &quot;blue&quot;, size = 1, stroke = 1) ## Warning in geom_point(shape = 21, width = 0.3, alpha = 0.4, fill = &quot;blue&quot;, : ## Ignoring unknown parameters: `width` De los datos anteriores, se considera que un buen modelo de RNLS para los datos, puede ser el Modelo Hiperb√≥lico, es decir: Modelo Transformaci√≥n \\(y = \\frac{x}{\\alpha x + \\beta}\\) Aplicando logaritmo natural: \\(\\frac{1}{y} = a + \\beta \\cdot \\frac{1}{x}\\) Condiciones Cambios de variable: \\(y_1 = \\frac{1}{y}; \\; x_1 = \\frac{1}{x}; \\; \\beta_0 = \\alpha; \\; \\beta_1 = \\beta\\) Posee as√≠ntotas verticales y horizontales que no necesariamente son los ejes Modelo lineal obtenido: \\(y_1 = \\beta_0 + \\beta_1 \\cdot x_1\\) Foto Lo anterior debido a que se percibe del gr√°fico que conforme \\(x \\rightarrow 20^-\\), los valores de \\(y\\) crecen r√°pidamente, semejando en \\(x = 20\\) una as√≠ntota vertical. Otros modelos como el exponencial se descarta por no tener as√≠ntotas verticales y el potencial o rec√≠proco solo tienen as√≠ntota vertical en \\(x = 0\\) Procedemos con las modificaciones en la tabla de datos, para transformar el modelo en un caso lineal, es decir, se hace una linealizaci√≥n de los datos: Seg√∫n la transformaci√≥n recomendada, se debe hacer dos cambios de variable: \\(X_2 = \\frac{1}{X}\\) y \\(Y_2 = \\frac{1}{Y}\\), para luego suministrarle estos valores a la funci√≥n lm de R para crear una MRL: X2 &lt;- 1/X Y2 &lt;- 1/Y datos2 &lt;- cbind(X2, Y2) datos2.df &lt;- as.data.frame(datos2) modelolm &lt;- lm(Y2 ~ X2, data = datos2.df) modelolm ## ## Call: ## lm(formula = Y2 ~ X2, data = datos2.df) ## ## Coefficients: ## (Intercept) X2 ## -0.4698 9.4032 Del modelo anterior se tiene que: \\(a = -0.4698\\) y \\(\\beta = 9.4032\\) Por lo que haciendo nuevamente la transformaci√≥n, el modelo buscado ser√≠a: \\[ y = \\frac{x}{-0.4698x + 9.4032} \\] Los siguiente c√≥digos ayudar√°n a mostrar gr√°ficamente el modelo obtenido con respecto a los datos del gr√°fico de dispersi√≥n: # Se genera una secuencia de puntos, para simular continuidad en la gr√°fica xo &lt;- seq(from = min(X) - 0.2, to = max(X) + 0.2, by = 0.01) yo &lt;- xo/(-0.4698*xo + 9.4032) # Graficamos dispersi√≥n y el modelo de ajuste en un mismo plot plot(X,Y, main = &quot;Modelo de RNLS f(x)=-x/(0.4698*x + 9.4032)&quot;, col =&quot;darkblue&quot;, lwd = 2) lines(xo, yo, type = &quot;l&quot;) Otra opci√≥n para el gr√°fico es usar ggplot2, como se muestra en el siguente c√≥digo: data &lt;- cbind(X, Y, xo, yo) # se juntan las columnas ## Warning in cbind(X, Y, xo, yo): number of rows of result is not a multiple of ## vector length (arg 1) data.df &lt;- as.data.frame(data) # se crea un objeto dataframe names(data.df) # verificamos los nombres de las columnas ## [1] &quot;X&quot; &quot;Y&quot; &quot;xo&quot; &quot;yo&quot; # Se crea un gr√°fico de dipsersi√≥n para ver de manera exploratoria los datos y se sobrepone el modelo de RNLS que encontramos f(x)=-x/(0.4698*x + 9.4032. Note que dentro de las opciones, para dar un mejor acabado al gr√°fico, se limita el intervalo de &quot;x&quot; e &quot;y&quot; g3 &lt;- ggplot(data.df, aes(X, Y, xmin = 17.7, xmax = 20.3, ymin = -100, ymax = 500 )) g3 + geom_point(shape = 21, alpha = 0.4, fill = &quot;red&quot;, size = 1, stroke =1) + geom_line(aes(x = xo, y = yo), colour = &quot;darkblue&quot;) + labs(colour = &quot;Modelo RNLS&quot;) Tome en cuenta que los vectores \\(X\\) e \\(Y\\) son m√°s peque√±os que los vectores \\(Xo\\) e \\(Yo\\) que fueron creados solamente con fines est√©ticos de la graficaci√≥n, entonces, R se encarga de equilibrar en dimensi√≥n los vectores generando secuencias repedidas de los vectores \\(X\\) e \\(Y\\) hasta completar las filas, pero, sin alterar los pares ordenados originales. Seguidamente a manera de ilustraci√≥n, se muestran las tablas: head(datos.df) ## X Y ## 1 18.0 19 ## 2 19.0 40 ## 3 19.5 79 ## 4 19.7 130 ## 5 19.9 397 head(data.df, 15) ## X Y xo yo ## 1 18.0 19 17.80 17.10289 ## 2 19.0 40 17.81 17.19009 ## 3 19.5 79 17.82 17.27809 ## 4 19.7 130 17.83 17.36689 ## 5 19.9 397 17.84 17.45652 ## 6 18.0 19 17.85 17.54696 ## 7 19.0 40 17.86 17.63825 ## 8 19.5 79 17.87 17.73039 ## 9 19.7 130 17.88 17.82339 ## 10 19.9 397 17.89 17.91727 ## 11 18.0 19 17.90 18.01203 ## 12 19.0 40 17.91 18.10770 ## 13 19.5 79 17.92 18.20428 ## 14 19.7 130 17.93 18.30178 ## 15 19.9 397 17.94 18.40023 Seguidamente se determina el IC para los par√°metros \\(\\alpha\\) y \\(\\beta\\): confint(lm(Y2 ~ X2, data = datos2.df),level = 0.95) ## 2.5 % 97.5 % ## (Intercept) -0.4781531 -0.461396 ## X2 9.2425203 9.563962 Finalmente, evaluamos el modelo en \\(x = 17\\) modelohiper1 &lt;- function(x){ y &lt;- x/(-0.4698*x + 9.4032) return(y) } modelohiper1(17) ## [1] 12.00056 valores &lt;-c(17, 18.1, 18.5, 18.9, 19.65) modelohiper1(valores) ## [1] 12.00056 20.11513 25.98680 36.07008 114.49047 datosnlm &lt;- cbind(X, Y) datosnlm.df &lt;- as.data.frame(datosnlm) datosnlm.df ## X Y ## 1 18.0 19 ## 2 19.0 40 ## 3 19.5 79 ## 4 19.7 130 ## 5 19.9 397 modelohiper2 &lt;- nls(Y ~ X/(a*X+b), data = datosnlm.df, start = list(a =1, b = 1)) modelohiper2 ## Nonlinear regression model ## model: Y ~ X/(a * X + b) ## data: datosnlm.df ## a b ## -0.4983 9.9655 ## residual sum-of-squares: 7.458 ## ## Number of iterations to convergence: 11 ## Achieved convergence tolerance: 7.917e-06 xo &lt;- seq(from = min(X) - 0.2, to = max(X) + 0.2, by = 0.01) yo &lt;- xo/(-0.4983*xo + 9.9655) datanlm &lt;- cbind(X, Y, xo, yo) ## Warning in cbind(X, Y, xo, yo): number of rows of result is not a multiple of ## vector length (arg 1) datanlm.df &lt;- as.data.frame(datanlm) g3 &lt;- ggplot(datanlm.df, aes(X, Y, xmin = 17.7, xmax = 20.01, ymin = -100, ymax = 500 )) g3 + geom_point(shape = 21, alpha = 0.4, fill = &quot;red&quot;, size = 1, stroke =1) + geom_line(aes(x = xo, y = yo), colour = &quot;darkblue&quot;) Ejemplo 2: Considere los datos de la siguiente tabla: x Y 1 4 2 7 4 20 6 40 A partir de los datos, estime el coeficiente \\(\\beta\\) de la ecuaci√≥n de regresi√≥n \\(y = 3 + x^\\beta\\), transformando el modelo a un modelo a un modelo de Regresi√≥n Lineal Simple mediante el m√©todo de m√≠nimos cuadrados. Para escoger el modelo, se recomienda primeramente construir un gr√°fico de dispersi√≥n para ver la tendencia de los datos: # Creamos la tabla de valores X &lt;- c(1, 2, 4, 6) Y &lt;- c(4, 7, 20, 40) datos3 &lt;- cbind(X, Y) # se juntan las columnas datos3.df &lt;- as.data.frame(datos3) # se crea un objeto dataframe names(datos3.df) # verificamos los nombres de las columnas ## [1] &quot;X&quot; &quot;Y&quot; # Se crea un gr√°fico de dipsersi√≥n para ver de manera exporatoria los datos g1 &lt;- ggplot(datos3.df, aes(X, Y)) g1 + geom_point(shape = 21, alpha = 0.4, fill = &quot;blue&quot;, size = 1, stroke = 1) De los datos anteriores, se considera que un buen modelo de regresi√≥n No lineal para los datos, puede ser el Modelo Potencial, es decir: | Modelo | Transformaci√≥n | | \\(y = a \\cdot x^\\beta\\) | Aplicando logaritmo natural: \\(ln(y) = ln(\\alpha) + \\beta \\cdot ln(x)\\) | | Condiciones: | Cambios de variable: $ y_1 = ln(y); ; x_1 = ln(x); ; _0 = ln(); ; _1 = $ | | Si \\(\\beta &gt; 0\\), el modelo pasa por \\((0,0)\\) | Modelo lineal obtenido: \\(y_1 = \\beta_0 + \\beta_1 \\cdot x_1\\) | Foto Note que el modelo propuesto, discrepa del modelo base en una constante, pero esto no limita a que se pueda linealizar, sin embargo, no de puede adoptar las recomendaciones de la imagen tal cu√°l se detallan, sino que podemos hacer la transformaci√≥n como sigue. \\[ y = 3 + x^\\beta \\\\ y-3 = x^\\beta \\\\ ln(y-3) = ln(x^\\beta) \\\\ ln(y-3) = \\beta \\; ln(x) \\\\ \\] Procedemos con las modificaciones en la tabla de datos, para transformar el modelo en un caso lineal: Seg√∫n la transformaci√≥n recomendada y adaptada a esta variante del modelo, se debe hacer los siguientes cambios de variable: \\(X_2 = \\ln(x), Y_2 = \\ln(y-3), b_0 = \\ln(1) = 0, b_1 = \\beta\\) para luego suministrarle estos valores a la funci√≥n lm de R para crear una MRLS. Note que en este caso como \\(b_0 = 0\\) se concluye que el modelo pasa por el origen, es decir, por el punto \\((0,0)\\) y eso se ver√° reflejado en la nueva tabla como se muestra a continuaci√≥n: # Se modifican los datos de la tabla original X2 &lt;- log(X) Y2 &lt;- log(Y-3) datos4 &lt;- cbind(X2, Y2) datos4.df &lt;- as.data.frame(datos4) modelolm &lt;- lm(Y2 ~ 0 + X2, data = datos4.df) #Intercepto igual a cero modelolm ## ## Call: ## lm(formula = Y2 ~ 0 + X2, data = datos4.df) ## ## Coefficients: ## X2 ## 2.024 Del modelo anterior se tiene que: \\[ \\beta = 2.024 \\] Por lo que haciendo nuevamente la transformaci√≥n, el modelo buscado ser√≠a: \\[ y = 3 + x^{2.024} \\] Los siguiente c√≥digos ayudar√°n a mostrar gr√°ficamente el modelo obtenido con respecto a los datos del gr√°fico de dispersi√≥n: # Se genera una secuencia de puntos, para simular continuidad en la gr√°fica X ## [1] 1 2 4 6 Y ## [1] 4 7 20 40 xo &lt;- seq(from = min(X), to = max(X) , by = 0.001) yo &lt;- 3 + xo^2.024 # Graficamos dispersi√≥n y el modelo de ajuste en un mismo plot plot(X,Y, main = &quot;Modelo de RNLS f(x)=3 + x^2.024&quot;, col = &quot;darkblue&quot;, lwd = 2) lines(xo, yo, type = &quot;l&quot;) Otra opci√≥n para el gr√°fico es usar ggplot2, como se muestra en el siguente c√≥digo: data &lt;- cbind(X, Y, xo, yo) # se juntan las columnas ## Warning in cbind(X, Y, xo, yo): number of rows of result is not a multiple of ## vector length (arg 1) data.df &lt;- as.data.frame(data) # se crea un objeto dataframe names(data.df) # verificamos los nombres de las columnas ## [1] &quot;X&quot; &quot;Y&quot; &quot;xo&quot; &quot;yo&quot; # Se crea un gr√°fico de dispersi√≥n para ver de manera exporatoria los datos y se sobrepone el modelo de RNLS que encontramos f(x)=3 + x^2.02569. Note que dentro de las opciones, para dar un mejor acabado al gr√°fico, se limita el intervalo de &quot;x&quot; e &quot;y&quot; g3 &lt;- ggplot(data.df, aes(X, Y, xmin = 0, xmax = 7, ymin = -1, ymax = 50 )) g3 + geom_point(shape = 21, alpha = 0.4, fill = &quot;red&quot;, size = 1, stroke =1) + geom_line(aes(x = xo, y = yo), colour = &quot;darkblue&quot;) + labs(colour = &quot;Modelo RNLS&quot;) Tome en cuenta que los vectores \\(X\\) e \\(Y\\) son m√°s peque√±os que los vectores \\(Xo\\) y \\(Yo\\) que fueron creados solamente con fines est√©ticos de la graficaci√≥n, entonces, R se encarga de equilibrar en dimensi√≥n los vectores generando secuencias repqedidas de los vectores m√°s \\(X\\) e \\(Y\\) hasta completar las filas, pero, sin alterar los pares ordenados originales. Seguidamente a manera de ilustraci√≥n, se muestran las tablas: head(datos.df) ## X Y ## 1 18.0 19 ## 2 19.0 40 ## 3 19.5 79 ## 4 19.7 130 ## 5 19.9 397 head(data.df, 15) ## X Y xo yo ## 1 1 4 1.000 4.000000 ## 2 2 7 1.001 4.002025 ## 3 4 20 1.002 4.004052 ## 4 6 40 1.003 4.006081 ## 5 1 4 1.004 4.008113 ## 6 2 7 1.005 4.010146 ## 7 4 20 1.006 4.012181 ## 8 6 40 1.007 4.014219 ## 9 1 4 1.008 4.016258 ## 10 2 7 1.009 4.018300 ## 11 4 20 1.010 4.020344 ## 12 6 40 1.011 4.022389 ## 13 1 4 1.012 4.024437 ## 14 2 7 1.013 4.026487 ## 15 4 20 1.014 4.028539 Seguidamente se determina el IC para los par√°metros \\(\\alpha\\) y \\(\\beta\\): confint(lm(Y2 ~ X2, data = datos2.df),level = 0.95) ## 2.5 % 97.5 % ## (Intercept) -0.4781531 -0.461396 ## X2 9.2425203 9.563962 Nota: El IC que de obtiene para los estimadores de los par√°metros a partir de la funci√≥n lm, no siempre pueden ser generalizados a los modelos no lineales. Por ejemplo, para el caso de los modelos exponenciales, como los par√°metors \\(\\alpha\\) y \\(\\beta\\)sufren una transformaci√≥m al linealizar el modelo, respectivamente por \\(\\ln(b_0)\\) y \\(\\ln(b_1)\\), hacen que los Intervalos de Confianza que se obtienen a partir de la funci√≥n lmno se puedan extrapolar o aplicar para \\(\\alpha\\) y \\(\\beta\\). datosnlm2 &lt;- cbind(X, Y) datosnlm2.df &lt;- as.data.frame(datosnlm2) datosnlm2.df ## X Y ## 1 1 4 ## 2 2 7 ## 3 4 20 ## 4 6 40 modelolm2 &lt;- nls(Y ~ 3 + X^b, data = datosnlm2.df, start = list( b = 1)) modelolm2 ## Nonlinear regression model ## model: Y ~ 3 + X^b ## data: datosnlm2.df ## b ## 2.018 ## residual sum-of-squares: 0.3894 ## ## Number of iterations to convergence: 5 ## Achieved convergence tolerance: 9.931e-06 Grafiquemos el modelo: xo &lt;- seq(from = min(X), to = max(X) , by = 0.001) yo &lt;- 3 + xo^2.018 datanlm2 &lt;- cbind(X, Y, xo, yo) # se juntan las columnas ## Warning in cbind(X, Y, xo, yo): number of rows of result is not a multiple of ## vector length (arg 1) datanlm2.df &lt;- as.data.frame(datanlm2) # se crea un objeto dataframe names(datanlm2.df) # verificamos los nombres de las columnas ## [1] &quot;X&quot; &quot;Y&quot; &quot;xo&quot; &quot;yo&quot; g3 &lt;- ggplot(datanlm2.df, aes(X, Y, xmin = 0, xmax = 7, ymin = -1, ymax =50 )) g3 + geom_point(shape = 21, alpha = 0.4, fill = &quot;red&quot;, size = 1, stroke =1) + geom_line(aes(x = xo, y = yo), colour = &quot;darkblue&quot;) + labs(colour = &quot;Modelo RNLS&quot;) A manera de pr√°ctica, se comparten los siguientes ejercicios: Ejercicio 49 Considere los datos en la siguiente tabla: \\(X\\) 0 4 5 6 7 8 \\(Y\\) 2 37 80 172 360 756 Escoja y justifique un modelo de regresi√≥n para y como funci√≥n de x. R/ Exponencial Encuentre una ecuaci√≥n de regresi√≥n para el modelo escogido. R/ \\(y = 1.9648 \\; (2.10265)^x\\) Ejercicio 50 Los siguientes datos, que representan las velocidades promedio para las diferentes distancias de cinco corredores, todos con mas de 70 a√±os de edad: Distancia \\((d)\\) 1.6 3 5 10 42 Vel. prom. \\((V)\\) 4.7 4.2 4.1 3.9 3.8 Determine la ecuaci√≥n de regresi√≥n no lineal simple (potencial) de \\(v\\) en funci√≥n de \\(d\\). R/ \\(v = 4.604d^{-0.05}\\) Determine un IC del \\(95\\%\\) para \\(\\alpha \\; (v=ad^\\beta, \\; \\text{asuma las hip√≥tesis de regresi√≥n})\\). R/ \\(]4.10688482, \\; 5.16208568[\\) "],["regresion-lineal-multiple.html", "Cap√≠tulo 13 Regresion lineal multiple 13.1 Regresion Lineal Multiple (RLM) 13.2 Regresi√≥n No Lineal Multiple (RNLM)", " Cap√≠tulo 13 Regresion lineal multiple En este secci√≥n, se abordar√°n algunos ejemplos de Regresi√≥n M√∫ltiple, dando especial atenci√≥n al caso lineal. Como de constumbre, iniciemos cargando algunos paquetes de utilidad: library(stats) library(bbmle) ## Loading required package: stats4 ## ## Attaching package: &#39;bbmle&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## slice 13.1 Regresion Lineal Multiple (RLM) Ejemplo 1 En la siguiente tabla, se registran las siguiente observaciones: \\(X_1\\) \\(X_2\\) \\(y\\) 0 1 1 1 0 4 1 -1 6 0 0 3 -1 1 0 Estime la ecuaci√≥n de regresi√≥n de \\(Y\\) en funci√≥n de \\(X_1\\), \\(X_2\\). Calcule el coeficiente de determinaci√≥n y correlaci√≥n del modelo. Determine el valor esperado aproximado de \\(Y\\) cuando $X_1 = 2 $ y \\(X_2 = 3\\) Soluci√≥n Primeramente se genera la matriz asociada al sistema: X &lt;- matrix(c(1,0,1,1,1,0,1,1,-1,1,0,0,1,-1,1), nrow = 5, byrow = TRUE) X ## [,1] [,2] [,3] ## [1,] 1 0 1 ## [2,] 1 1 0 ## [3,] 1 1 -1 ## [4,] 1 0 0 ## [5,] 1 -1 1 # La instrucci√≥n genera un vector columna Y &lt;- cbind(c(1,4,6,3,0)) Y ## [,1] ## [1,] 1 ## [2,] 4 ## [3,] 6 ## [4,] 3 ## [5,] 0 Seguidamente, usando el teorema siguiente: \\[ b = (X^t \\; X)^{-1} (X^t \\;Y) \\] Para el trabajo en R tome en cuenta las siguientes instrucciones: Sea M una matriz de orden n, as√≠ solve(M): Calcila la matriz inversa de M t(M): Calcula la matriz transpuesta de M %*%: Corresponde a la multiplicaci√≥n matricial Para calcular las estimaciones buscadas, hacemos el siguiente c√°lculo: estimaciones.b1 &lt;- solve(t(X) %*% X) %*% (t(X) %*% Y) estimaciones.b1 ## [,1] ## [1,] 3 ## [2,] 1 ## [3,] -2 As√≠, el modelo de regresi√≥n buscado ser√≠a: \\[ y = 3 + X_1 -2X_2 \\] Otra forma de estimar el modelo, es haciendo uso de la funci√≥n lm que se us√≥ para el modelo de Regresi√≥n Lineal Simple, como se muestra a continuaci√≥n: modelo &lt;- lm(Y ~ X[ ,2]+X[ ,3]) modelo ## ## Call: ## lm(formula = Y ~ X[, 2] + X[, 3]) ## ## Coefficients: ## (Intercept) X[, 2] X[, 3] ## 3 1 -2 Veamos la calidad del modelo, mediante su coeficiente de determinaci√≥n y de correlaci√≥n: # Coefieciente de determinaci√≥n R2 &lt;- summary(modelo)$r.squared ## Warning in summary.lm(modelo): essentially perfect fit: summary may be ## unreliable R2 ## [1] 1 # Coeficiente de correlaci√≥n R &lt;- sqrt(R2) R ## [1] 1 Seguidamente, se crean una funci√≥n para realizar las estimaciones modeloRLM1 &lt;- function(x1,x2){ y &lt;- 3 + x1 - 2*x2 return(y) } modeloRLM1(2,3) ## [1] -1 Ejemplo 2 Se pustula que la altura de un beb√©√© \\((y)\\) tiene una relaci√≥n lineal con su edad en d√≠as \\((x_1)\\), su altura al nacer en cm \\((x_2)\\), su peso en kg al nacer \\((x_3)\\) y el aumento en tanto por ciento de su peso actual respecot de su peso al nacer \\((x_4)\\). En una muestra de 9 ni√±os se obtuvieron los siguientes resultados: y x1 x2 x3 x4 57.5 78 48.2 2.75 29.5 52.8 69 45.5 2.15 26.3 61.3 77 46.3 4.41 32.2 67 88 49 5.52 36.5 53.5 67 43 3.21 27.2 62.7 80 48 4.32 27.7 56.2 74 48 2.31 28.3 68.5 94 53 4.3 30.3 69.2 102 58 3.71 28.7 Estime la ecuaci√≥n de regresi√≥n de \\(Y\\) en funci√≥n de \\(x_1, x_2, x_3 \\; \\text{ y } x_4\\). Calcule el coerficiente de determinaci√≥n y correlaci√≥n del modelo. Soluci√≥n Primeramente, generamos la Matriz asociada al sistema y el vector soluci√≥n: X &lt;- matrix(c(1,78,48.2,2.75,29.5,1,69,45.5,2.15,26.3, 1,77,46.3,4.41,32.2,1,88,49,5.52,36.5, 1,67,43,3.21,27.2,1,80,48,4.32,27.7, 1,74,48,2.31,28.3,1,94,53,4.3,30.3, 1,102,58,3.71,28.7), nrow=9, byrow = TRUE) X ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 78 48.2 2.75 29.5 ## [2,] 1 69 45.5 2.15 26.3 ## [3,] 1 77 46.3 4.41 32.2 ## [4,] 1 88 49.0 5.52 36.5 ## [5,] 1 67 43.0 3.21 27.2 ## [6,] 1 80 48.0 4.32 27.7 ## [7,] 1 74 48.0 2.31 28.3 ## [8,] 1 94 53.0 4.30 30.3 ## [9,] 1 102 58.0 3.71 28.7 y.bebes &lt;- cbind(c(57.5,52.8,61.3,67,53.5,62.7,56.2,68.5,69.2)) y.bebes ## [,1] ## [1,] 57.5 ## [2,] 52.8 ## [3,] 61.3 ## [4,] 67.0 ## [5,] 53.5 ## [6,] 62.7 ## [7,] 56.2 ## [8,] 68.5 ## [9,] 69.2 Seguidamente, se resuelve el sistema para obtener las estimaciones de los par√°metros buscados: estimaciones.b &lt;- solve(t(X) %*% X) %*% (t(X) %*% y.bebes) estimaciones.b ## [,1] ## [1,] 7.14753240 ## [2,] 0.10009447 ## [3,] 0.72641738 ## [4,] 3.07583698 ## [5,] -0.03004215 Por tanto, el modelo de Regresi√≥n Lineal M√∫ltiple buscado, ser√≠a: \\[ \\hat{y} = 7.14753240 + + 0.10009447x_1 + 0.72641738x_2 + 3.07583698x_3 - 0.03004215x_4 \\] Para comprender el modelo de una mejor manera, se escribe como sigue: \\[ \\hat{y} = 7.14753240 + 0.10009447 \\textit{Edad} + 0.72641738\\textit{Altura} + 3.07583698\\textit{Peso} - 0.03004215\\textit{Aumento} \\] Podemos observar, por ejemplo, que cu√°nto m√°s edad tenga el ni√±o, m√°s altura tiene, cu√°nto m√°s peso al nacer, m√°s altura tiene pero cu√°nto m√°s haya aumentado su peso respecto de su peso al nacer, su altura disminuye aunque dicha disminuci√≥n es min√∫scula. Calculemos el modelo usando la funci√≥n lm: modbebes &lt;- lm(y.bebes ~ X[,2] + X[,3] + X[,4] + X[,5]) modbebes ## ## Call: ## lm(formula = y.bebes ~ X[, 2] + X[, 3] + X[, 4] + X[, 5]) ## ## Coefficients: ## (Intercept) X[, 2] X[, 3] X[, 4] X[, 5] ## 7.14753 0.10009 0.72642 3.07584 -0.03004 Con la funci√≥n summary aplicada al modelo, es posible determinar si todas las variables utilizadas en el modelo de RLM son significativas: summary(modbebes) ## ## Call: ## lm(formula = y.bebes ~ X[, 2] + X[, 3] + X[, 4] + X[, 5]) ## ## Residuals: ## 1 2 3 4 5 6 7 8 ## -0.04053 -0.12898 0.21498 -0.43238 -0.64610 0.22143 0.52245 1.12764 ## 9 ## -0.83852 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.14753 16.45961 0.434 0.6865 ## X[, 2] 0.10009 0.33971 0.295 0.7829 ## X[, 3] 0.72642 0.78590 0.924 0.4076 ## X[, 4] 3.07584 1.05918 2.904 0.0439 * ## X[, 5] -0.03004 0.16646 -0.180 0.8656 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.861 on 4 degrees of freedom ## Multiple R-squared: 0.9908, Adjusted R-squared: 0.9815 ## F-statistic: 107.3 on 4 and 4 DF, p-value: 0.0002541 Finalmente, se calcula el coeficiente de determinaci√≥n y de correlaci√≥n para el modelo: # Coeficiente de determinaci√≥n R2 &lt;- summary(lm(y.bebes ~ X[,2] + X[,3] + X[,4] + X[,5]))$r.squared R2 ## [1] 0.9907683 # Coeficiente de correlaci√≥n R &lt;- sqrt(R2) R ## [1] 0.9953735 Analizando los valores de P para cada coeficiente, vemos que el √∫nico que aporta de manera significativa al modelo es \\(X[, 4]\\) que corresponde a \\(x_3\\) de los datos originales (peso en \\(\\textit{kg}\\) del ni√±o al nacer), esto sugiere que hagamos un modelo usando solo RLS con esta variable: modbebesRLS &lt;- lm(y.bebes ~ X[,4]) modbebesRLS ## ## Call: ## lm(formula = y.bebes ~ X[, 4]) ## ## Coefficients: ## (Intercept) X[, 4] ## 45.298 4.315 summary(modbebesRLS) ## ## Call: ## lm(formula = y.bebes ~ X[, 4]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.6496 -2.1172 -1.2392 0.9339 7.8929 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 45.298 5.254 8.621 5.64e-05 *** ## X[, 4] 4.315 1.390 3.105 0.0172 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.394 on 7 degrees of freedom ## Multiple R-squared: 0.5793, Adjusted R-squared: 0.5192 ## F-statistic: 9.64 on 1 and 7 DF, p-value: 0.0172 summary(modbebesRLS)$r.squared ## [1] 0.5793379 Podemos comparar los modelos: AICctab(modbebes, modbebesRLS, base = T, delta = T, sort = T, weights =T, nobs = 9) ## AICc dAICc df weight ## modbebesRLS 60.7 0.0 3 0.988 ## modbebes 69.5 8.8 6 0.012 Como AIC es menor para el modelo de RLS modbebesRLS, se podr√≠a preferir a este en lugar el modelo de RLM modbebes. 13.2 Regresi√≥n No Lineal Multiple (RNLM) Ejemplo 1 La tabla a trabjar es la siguiente: \\(x\\) \\(y\\) \\(z\\) 3 5 -46 8 9 -110 13 4 10 16 6 -12 20 2 64 Modelo a trabajar: $ z = _0 + _1 x + _2 y + _3 y^2$ Se crea la tabla en R de la siguiente manera: M &lt;- matrix(c(3,5,8,9,13,4,16,6,20,2), nrow = 5, byrow = TRUE) M ## [,1] [,2] ## [1,] 3 5 ## [2,] 8 9 ## [3,] 13 4 ## [4,] 16 6 ## [5,] 20 2 # La instrucci√≥n genera un vector columna, que representa el vector soluci√≥n z &lt;- cbind(c(-46,-110,10,-12,64)) z ## [,1] ## [1,] -46 ## [2,] -110 ## [3,] 10 ## [4,] -12 ## [5,] 64 Para linealizar el modelo, se debe hacer el siguiente cambio de variable: \\(x_3\\) = \\(y^2\\) \\(x_1\\) = \\(x\\) \\(x_2\\) = \\(y\\) \\(z_2\\) = \\(z\\) \\(b_0\\) = \\(\\beta_0\\) \\(b_1\\) = \\(\\beta_1\\) \\(b_2\\) = \\(\\beta_2\\) \\(b_3\\) = \\(\\beta_3\\) Transformamos la tabla original, para que se ajuste al modelo de Regresi√≥n Lineal M√∫ltiple: x &lt;- cbind(c(1,1,1,1,1), M[ ,c(1, 2)], M[ ,2]^2 ) x ## [,1] [,2] [,3] [,4] ## [1,] 1 3 5 25 ## [2,] 1 8 9 81 ## [3,] 1 13 4 16 ## [4,] 1 16 6 36 ## [5,] 1 20 2 4 Con esta nueva matriz, resolvemos el siguiente modelo: \\[ z_2 = b_0 + b_1 x_1 + b_2 x_2 + b_3 x_3 \\] como si fuese un caso de (Regresi√≥n Lineal M√∫ltiple) RLM, de la siguiente manera: estimaciones.b &lt;- solve(t(x) %*% x) %*% (t(x) %*% z) estimaciones.b ## [,1] ## [1,] 2 ## [2,] 4 ## [3,] -7 ## [4,] -1 Recordenmos tambi√©n que el modelo se puede obtener usando la funi√≥n lm: modelo1 &lt;- lm(z ~ x[,2] + x[,3] + x[,4]) modelo1 ## ## Call: ## lm(formula = z ~ x[, 2] + x[, 3] + x[, 4]) ## ## Coefficients: ## (Intercept) x[, 2] x[, 3] x[, 4] ## 2 4 -7 -1 Por tanto, el modelo de Regresi√≥n Lineal M√∫ltiple buscado, ser√≠a: \\[ \\hat{z} = 2 + 4x - 7y - y^2 \\] Evaluamos el modelos para los valores de \\(x = 2\\) y \\(y = 7\\) b &lt;- estimaciones.b modeloRNLM1 &lt;- function(x,y){ z &lt;- b[1,] + b[2,]*x + b[3,]*y + b[4, ]*y^2 return(z) } modeloRNLM1(2,7) ## [1] -88 Ejemplo 2: La tabla a trabjar es la siguiente: \\(x\\) \\(y\\) \\(z\\) 1 0.5 0.06 1.5 1 6.7 2 2 512 1 2 64 Modelo a trabajar: \\(z = \\beta_0 x^{\\beta_1} y^{\\beta_2}\\) Se crea la tabla en R de la siguiente manera: M2 &lt;- matrix(c(1,0.5,1.5,1,2,2,1,2), nrow = 4, byrow = TRUE) M2 ## [,1] [,2] ## [1,] 1.0 0.5 ## [2,] 1.5 1.0 ## [3,] 2.0 2.0 ## [4,] 1.0 2.0 # La instrucci√≥n genera un vector columna, que representa el vector soluci√≥n z &lt;- cbind(c(0.06,6.7,512,64)) z ## [,1] ## [1,] 0.06 ## [2,] 6.70 ## [3,] 512.00 ## [4,] 64.00 Se procede a la siguiente transformaci√≥n del modelo original, con el fin de buscar una linealizaci√≥n del mismo: \\[ \\ln(z) = \\ln(\\beta_0) + \\beta_1 \\ln(x) + \\beta_2 \\ln(y) \\] Para linealizar el modelo, se debe hacer el siguiente cambio de variable: \\(b_0\\) = \\(\\ln(\\beta_0)\\) \\(b_1\\) = \\(\\beta_1\\) \\(b_2\\) = \\(\\beta_2\\) \\(x_1\\) = \\(\\ln(x)\\) \\(x_2\\) = \\(\\ln(y)\\) \\(z_2\\) = \\(\\ln(z)\\) Tranformamos la tabla original, para que se ajuste al modelo de RLM: x2 &lt;- cbind(c(1,1,1,1), log(M2[ ,c(1, 2)])) x2 ## [,1] [,2] [,3] ## [1,] 1 0.0000000 -0.6931472 ## [2,] 1 0.4054651 0.0000000 ## [3,] 1 0.6931472 0.6931472 ## [4,] 1 0.0000000 0.6931472 z2 &lt;- log(z) z2 ## [,1] ## [1,] -2.813411 ## [2,] 1.902108 ## [3,] 6.238325 ## [4,] 4.158883 Con esta nueva matriz, resolvemos el siguiente modelo: \\[ z_2 = b_0 + b_1 x_2 +b_2 x_2 \\] como si fuese una caso de RLM, de la siguiente manera: estimaciones.b &lt;- solve(t(x2) %*% x2) %*% (t(x2) %*% z2) estimaciones.b ## [,1] ## [1,] 0.6744198 ## [2,] 3.0078412 ## [3,] 5.0260234 Recordemos que estos coeficientes se pueden calcular con la funci√≥n lm de R: modelo1 &lt;- lm(z2 ~ x2[,2] + x2[,3]) modelo1 ## ## Call: ## lm(formula = z2 ~ x2[, 2] + x2[, 3]) ## ## Coefficients: ## (Intercept) x2[, 2] x2[, 3] ## 0.6744 3.0078 5.0260 Recordemos los cambios de variables que se utilizaron para las estimaciones de los par√°metros: \\(b_0\\) = \\(\\ln(\\beta_0)\\) \\(b_1\\) = \\(\\beta_1\\) \\(b_2\\) = \\(\\beta_2\\) De esta manera, para obterner el valor bucado, se precede con el siguiente despeje: \\(\\beta_0\\) = \\(e^{b_0}\\) Hacemos este c√°lculo en R para obtener nuevamente el vector con los valores de las estimaciones para los betas: b &lt;- estimaciones.b beta &lt;- c(exp(b[1, ]) , b[2, ], b[3, ]) beta ## [1] 1.962894 3.007841 5.026023 Por tanto, el modelo de RNLM buscado, ser√≠a: \\[ z = (1.962894)x^{3.007841} y^{5.026023} \\] Evaluamos el modelos para los valores de \\(x = 2\\) y \\(y = 7\\) b &lt;- estimaciones.b modeloRNLM2 &lt;- function(x1,x2){ z &lt;- b[1,]* x1^b[2,]*x2^b[3,] return(z) } modeloRNLM2(2,7) ## [1] 95909.87 "],["referencias.html", "Referencias", " Referencias Cabrero, Y. &amp; Garc√≠a, A. (2015). An√°lisis estad√≠stico de datos espaciales con QGIS y R. Universidad Nacional de Educaci√≥n a Distancia (UNED), Espa√±a. Chang, W. (2013). Practical Recipes for Visualizing Data: R Graphics Cookbook. O‚Äô Reilly Media, Inc, Canada. Garc√≠a, A. (2016). Estad√≠stica aplicada con R. Universidad Nacional de Educaci√≥n a Distancia (UNED), Espa√±a. Garc√≠a, A. (2014). M√©todos avanzados de estad√≠stica aplicada: m√©todos robustos y de remuestreo. Universidad Nacional de Educaci√≥n a Distancia (UNED), Espa√±a. Garc√≠a, A. (2015). M√©todos avanzados de estad√≠stica aplicada: t√©cnicas avanzadas. Universidad Nacional de Educaci√≥n a Distancia (UNED), Espa√±a. Sanabria, G. (2011). Comprendiendo la estad√≠stica inferencial. Editorial Tecnol√≥gica de Costa Rica. Wickham, H. &amp; Grolemund, G. (2017). R for Data Science. O‚Äô Reilly Media, Inc, Canad√°. Wickham, H. (2016). Ggplot2: Elegant Graphics for Data Analysis. Springer. body { font-family: Arial, sans-serif; } /* Primera Tabla Tabla */ .tabla-container { width: 100%; max-width: 800px; margin: auto; border-collapse: collapse; } .tabla-container th, .tabla-container td { border: 1px solid black; padding: 8px; text-align: left; } .tabla-header { background-color: #003366; justify-content: center; /* Alinea horizontalmente al centro */ align-items: center; /* Alinea verticalmente al centro */ color: white; text-align: center; padding: 10px 0; font-size: 18px; } .tabla-subheader { background-color: #0066cc; color: white; } .check-options th { background-color: white; color: black; text-align: center; font-size: 18px; } .check-options input { margin-right: 5px; } .sub-col th { border: none; /* A√±ade esta l√≠nea para quitar los bordes */ } "],["anexos.html", "Anexos Especificaciones del proyecto I Parte: Explicacion de los datos II Parte: Analisis Inferencial (IC) III Parte: Analisis Inferencial (pruebas de hipotesis de una y dos poblaciones) IV Parte: Analisis Inferencial (Otras pruebas de hip√≥tesis) V Parte: : Analisis de regresi√≥n Fases del proyecto y detalles de entrega Especificaciones del proyecto II Fase Espesificaciones del proyecto Fase III II Parte: Modelos de regresion lineal III PARTE: Modelos de regresion no lineal Solucion III Parcial de Estadistica", " Anexos Especificaciones del proyecto Estimado estudiante, el presente documento es una gu√≠a para la elaboraci√≥n del proyecto del curso que tiene un valor del 50% sobre la nota final. La gu√≠a incluye una descripci√≥n de cada una de las partes a realizar y la fecha de entrega. El trabajo serealizar√° en grupos m√°ximo de 4 personas. I Parte: Explicacion de los datos Para la realizaci√≥n de este proyecto, cada grupo deber√° hacer una revisi√≥n de varios datasets disponibles en R para uso libre. Se recomiendan las siguientes opciones, pero si el grupo considerar que puede proponer otra base de datos, tiene libertad de hacerlo: Descripci√≥n del dataset Anotaciones Paquete: nycflights13 https://www.rdocumentation.org/packages/nycflights13/versions/1.0.1 Base de datos de vuelos saliendo de New York Paquete: Datos https://www.rdocumentation.org/packages/datos/versions/0.3.0 Datos diversos disponibles en la base de R, cuyas variables fueron traducidas al espa√±ol. Paquete: wooldridge https://cran.r-project.org/web/packages/wooldridge/wooldridge.pdf Datos econom√©tricos en ingl√©s, incluye diferentes variables. Otros paquetes de R con datasets: https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html Recomendaciones de diferentes paquetes que contienen datasets de uso libre en R. Para cada dataset seleccionado, se debe presentar la siguiente informaci√≥n en el documento escrito: Dataset: nombre Descripci√≥n General: Describa los aspectos m√°s importantes relacionados con la base de datos a utilizar: lugar, si fue resultado de un trabajo de investigaci√≥n u otra raz√≥n, fechas, lugares, raz√≥n que justific√≥ la toma de los datos, etc. Adem√°s, indique en esta secci√≥n la composici√≥n de la base de datos: tama√±o, cantidad de mediciones (filas), cantidad de variables (columnas), describa cada variable (a qu√© se refiere la medida, unidad de medida usada), si tiene datos faltantes. Para esta secci√≥n puede apoyarse en funciones de R como str(), summary(), recursos gr√°ficos entre otros. Resumen de variables seleccionadas Una poblaci√≥n Dos poblaciones Poblaci√≥n 1 Poblaci√≥n 2 Variables Tipo Par√°metro por estimar (IC) Var1 Cualitativa Proporci√≥n, diferencia de proporciones Var2 Cuantitativa Media, varianza Var3 Cuantitativa Diferencia de medias Var4 Cuantitativa Cociente de varianzas Tome en cuenta que: 1. Una misma variable puede ser usada en varias pruebas Si desea, puede usar una variable distinta para cada prueba o variar entreel caso de una o dos poblaciones En sustituci√≥n de variables cualitativas, puede usar tambi√©n variablesbinarias que cumplen una funci√≥n similar (s√≠ o no, 1 o 0, etc) II Parte: Analisis Inferencial (IC) Realice intervalos de confianza que involucren una y dos poblaciones (Al menosun IC de: un promedio usando distribuci√≥n \\(z\\), un promedio usando distribuci√≥n \\(t\\), una proporci√≥n, una variancia, una diferencia de promedios usando distribuci√≥n \\(z\\), una diferencia de promedios usando distribuci√≥n \\(t\\), una diferencia de proporciones y un cociente de variancias). Debe indicar las hip√≥tesis asumidas (por ejemplo: la poblaci√≥n \\(X\\) se asume quesigue una distribuci√≥n normal). Deben explicar cada uno de los resultados, es decir, las conclusiones obtenidas.En el caso de dos poblaciones recuerde indicar si es posible asumir igualdad de medias, proporciones o varianzas. Tome en cuenta que en clase no se estudiaron funciones que permitieran calcular intervalos de confianza para la media o diferencia de medias de los casos donde se conoce la varianza o cuando esta no se conoce, pero el tama√±o de la muestra es lo suficientemente grande (n ‚â• 30), es decir, los casos en los que el IC se calcula a partir de la distribuci√≥n normal (Distribuci√≥n z). Para trabajar los casos de intervalos de confianza de este tipo (uno para una poblaci√≥n y otro para dos poblaciones) deber√°n investigar sobre cu√°l o cu√°les funciones de R podr√≠a utilizar, por lo que se le recomienda estudiar los paquetes BSDA, stests, PASWR2. Para cada caso investigado, deben explicar el formato de la funci√≥n y aplicarlo en el caso que est√©n trabajando. Sean claros en indicar si la funci√≥n aplica solo para una poblaci√≥n o para dos poblaciones, podr√≠a ser que alguna de ellas tenga usos espec√≠ficos y otras sean m√°s generales para abordar ambos casos. El siguiente ejemplo muestra una forma de proceder: Ahora si se automatiza el proceso se puede usar una funci√≥n de R llamada varTest del paquete EnvStats, cuya estructura ser√≠a varTest(X,conf.level)$conf.int. X: vector que contiene la muestra de datos conf.level: nivel de confianza III Parte: Analisis Inferencial (pruebas de hipotesis de una y dos poblaciones) Realice pruebas de hip√≥tesis que involucren una y dos poblaciones (Al menos unapruebade hip√≥tesis de: un promedio, una proporci√≥n, una variancia, diferencia depromedios,diferencia de proporciones y cociente de variancias) Debe indicar las conclusiones obtenidas y tambi√©n las hip√≥tesis asumidas (por ejemplo,la poblaci√≥n X se asume que sigue una distribuci√≥n normal) IV Parte: Analisis Inferencial (Otras pruebas de hip√≥tesis) Realice una Bondad de Ajuste para determinar si una de las variablescuantitativas sigue o no una distribuci√≥n normal. Realice una Bondad de Ajuste para determinar si una de las variables cuantitativasigue o no una distribuci√≥n no normal (escoja una que no sea normal). Realice una prueba de independencia entre las variables cualitativas de unamisma poblaci√≥n. Realice un ANOVA entre una variable cuantitativa y otra cualitativa de unamismapoblaci√≥n. Debe indicar las conclusiones obtenidas V Parte: : Analisis de regresi√≥n Realice un an√°lisis de regresi√≥n lineal entre las variables cuantitativas de una misma poblaci√≥n. (estimaci√≥n puntual, estimaci√≥n por intervalo de los par√°metros, intervalo de predicci√≥n, coeficiente de correlaci√≥n) Escoja una regresi√≥n NO lineal (de las vistas) que se ajuste m√°s para las variables cuantitativas de una misma poblaci√≥n. Justifique su escogencia. Realice un an√°lisis de regresi√≥n no lineal escogida entre las variables cuantitativas de una misma poblaci√≥n. (estimaci√≥n puntual, estimaci√≥n por intervalo de los par√°metros, intervalo de predicci√≥n, coeficiente de correlaci√≥n) Fases del proyecto y detalles de entrega Fase 1 Fase 2 Fase 3 Valor total 15% 15% 20% Entrega de informe detallado del an√°lisis realizado que involucra las partes: Fases I y II Valor 12% Fase III Valor 12% Fases IV y V Valor 16% Fecha de entrega del informe: A m√°s tardar: 17 de abril A m√°s tardar: 12 de mayo A m√°s tardar: 2 de junio Exposici√≥n del trabajo realizado Valor 3% 3% 4% Observaciones generales: Los datasets y las variables elegidas en la primera fase, podr√≠an mantenerse o cambiarse seg√∫n los requerimientos en cada una de estas. Se dar√° prioridad a los estudiantes para que conformen sus grupos de trabajo, caso contrario, el profesor asignar√° los miembros en cada uno de estos. Los grupos se mantendr√°n invariantes a lo largo del semestre. En caso de que algunos estudiantes se retiren del curso, se valorar√° la reasignaci√≥n de los miembros de ese grupo al que pertenec√≠an, siempre justificado en una sobrecarga de trabajo. Una vez definidos los grupos, se crear√° un canal espec√≠fico para el grupo dentro del equipo del curso en la plataforma Teams. Todos los materiales que se generen como parte de este trabajo, deben concentrarse en este canal. Cada grupo deber√° crear una Bit√°cora de minutas de cada una de las reuniones,donde en cada una de ellas aparezca el n√∫mero de minuta, fecha, presentes, horade inicio, agenda, acuerdos y hora de cierre. Se recomienda que las reuniones sean realizadas en Teams y de requerir ser grabadas, estas quedan autom√°ticamente disponible en la secci√≥n se archivos del canal. La primera minuta deber√° contener una distribuci√≥n de tareas por persona y un plan de trabajo que visibilice el alcance de la meta en el plazo. El informe debe crearse en RStudio y exportarse como documento de Word. Este informe debe subirse en la secci√≥n de tareas que se crear√° dentro del canal privado del grupo. No es necesario que se adjunten los documentos Rmd, solo en caso de que estos sean solicitados. Todos los c√°lculos num√©ricos o estad√≠sticos, estimaciones, gr√°ficos de an√°lisis, trabajo con la base de datos, deber√° realizarse en RStudio. Sobre la nota del informe en cada fase. El profesor dar√° una nota inicial del proyecto. Cada estudiante deber√° valorar con un porcentaje el trabajo de cada uno de sus compa√±eros de equipo y su propio trabajo. Esto se debe realizar mediante un formulario al cu√°l se le brindar√° el acceso. Porcentaje promedio: es el promedio ponderado de los porcentajes obtenidos para cada estudiante, la valoraci√≥n de su trabajo pesar√° un 60% y las valoraciones dadas por sus compa√±eros un 40%. La nota de cada estudiante se obtiene sacando el porcentaje promedio obtenido de la nota inicial. Ejemplo: suponga que la fase I el grupo 1 estuvo conformado por los estudiantes A, B, C y D: Nota inicial del informe da por el profesor Valoraci√≥n del trabajo realizado dada por Promedio de valoraciones Nota obtenida del informe de la fase I A B C D A 90 100 100 100 100 100 90 B 90 70 70 70 90 72.67 65.4 C 90 10 60 50 40 26 23.4 D 90 100 80 90 100 96 86.4 Sobre la exposici√≥n: Las exposiciones se realizan en el horario de clases posterior a la entrega del informe, para lo cual deber√° reservar una cita seg√∫n horario que disponga el profesor. La exposici√≥n de la fase 1 y 2 se realizar√° fuera del horario de clase. La exposici√≥n de la fase 3 se realizar√° en la √∫ltima clase de la semana 16. Deben estar todos los integrantes del grupo, y pueden preparar una presentaci√≥n no mayor a los 8 minutos. Todos los estudiantes deber√°n exponer de manera equitativa. Finalizada la presentaci√≥n realizar√°n algunas preguntas te√≥ricas sobre el trabajo realizado. El profesor puede elegir quien de los integrantes del grupo debe responder. Desglose de la nota (ser√° la misma para todos los integrantes del grupo): Presentaci√≥n y manejo del tiempo: 50% Respuesta a las preguntas: 50% Especificaciones del proyecto II Fase La presente gu√≠a pretenda dar directrices para la entrega de la segunda fase del proyecto. III parte: Analisis Inferencial (pruebas de hipotesis de una y dos poblaciones) Para esta segunda entrega, puede utilizar el mismo dataset usado para la primera entrega del proyecto, pero tambi√©n puede agregar una nuevo dataset si as√≠ se prefiere. En caso de agregar nuevos dataset, debe incluir en esta segunda entrega una descripci√≥n de este con los mismos elementos que se solicitaron para la entrega anterior. Complete el siguiente cuadro indicando el tipo de variable a utilizar y su respectiva prueba de hip√≥tesis. Presente de manera separada el caso de una y dos poblaciones: /* Segunda Tabla */ .table-centered { width: 100%; border-collapse: collapse; } .table-centered th, .table-centered td { border: 1px solid black; padding: 8px; text-align: center; /* Centrar horizontalmente */ vertical-align: middle; /* Centrar verticalmente */ } .table-centered th { background-color: #f2f2f2; } .header { font-weight: bold; text-align: center; } .checkbox { vertical-align: top; } Resumen de variables seleccionadas Una poblaci√≥n Variables Tipo Prueba de hip√≥tesis para: Var1 Cualitativa Proporci√≥n, media Var2 Cuantitativa Varianza .tabla-container { width: 100%; max-width: 800px; margin: auto; border-collapse: collapse; } .tabla-container th, .tabla-container td { border: 1px solid black; padding: 8px; text-align: left; } .tabla-header { background-color: #003366; justify-content: center; /* Alinea horizontalmente al centro */ align-items: center; /* Alinea verticalmente al centro */ color: black; text-align: center; padding: 10px 0; font-size: 18px; } .tabla-subheader { background-color: #0066cc; color: black; } .check-options td { background-color: white; color: black; text-align: center; font-size: 18px; } .check-options input { margin-right: 5px; } .sub-col td { border: none; /* A√±ade esta l√≠nea para quitar los bordes */ } Resumen de variables seleccionadas Dos poblaciones Poblaci√≥n 1 Poblaci√≥n 2 Variables Tipo Prueba de hip√≥tesis para: Var1 Cualitativa diferencia de proporciones o medias Var2 Cuantitativa Cociente de varianzas La segunda entrega deber√° incluir todo lo elaborado en la primera entrega con las correcciones respectivas Adicionalmente a lo indicado en el punto anterior, deber√°n incluirse an√°lisis de pruebas de hip√≥tesis para una poblaci√≥n (Al menos una prueba de hip√≥tesis de: un promedio con distribuci√≥n z, un promedio con distribuci√≥n T, una proporci√≥n,una variancia) y dos poblaciones (diferencia depromedios con distribuci√≥n z, diferencia de promedios con distribuci√≥n T, diferencia de proporciones y cocientede variancias). En el caso de la prueba de cociente de varianzas, esta puede ser considerada como previo a la prueba T para diferencia de promedios, considerando que esta requiere saber si se puede asumir varianzas iguales o diferentes. Para cada caso debe indicar las condiciones asumidas y comprobarlas (si es posible con las herramientas estudiadas hasta ahora). Tome en cuenta las condiciones especiales de los casos de proporciones, varianzas y pruebas T. Las hip√≥tesis nulas y alternativas, en cada caso, deben ser planteadas por ustedes dejando de manera expl√≠cita en el documento a estas. Adem√°s, indique en cada caso si la prueba a utilizar es de cola izquierda, cola derecha, dos colas. Para cada caso se debe interpretar la informaci√≥n resumen que provee R en cada una de las pruebas, para eso utilice el siguiente cuadro para el reporte: Resumen de la prueba Valor observado (escoja entre \\(t_{obs}, z_{obs}, X_{obs}^2, f_{obs}\\)) ____________________________ Grados de libertad (cuando corresponda) ____________________________ Estad√≠stico de prueba (escoja entre \\(\\bar{x}, \\hat{p}, s^2, \\bar{x_1} \\text{ y } \\bar{x_2}, \\hat{p_1}, \\frac{s_1^2}{s_2^1}\\)) ____________________________ Regi√≥n de aceptaci√≥n ____________________________ Regi√≥n de rechazo ____________________________ Nivel de confianza ____________________________ Conclusi√≥n Ind√≠quese \\(H_0\\) es rechazada o no rechaza dado que se encuentre o no evidencia suficiente en contra a partir de lo observado con el valor \\(P\\) y la regi√≥n de aceptaci√≥n seg√∫n corresponda la interpretaci√≥n en R, como fue visto en clases. Debe aparecer el c√≥digo en R utilizado al aplicar cada una de las pruebas, as√≠ como las salidas de estos c√≥digos. Fases del proyecto y detalles de entrega Fase 1 Fase 2 Fase 3 Valor total 15% 15% 20% Entrega de informe detallado del an√°lisis realizado que involucra las partes: Partes I y II, valor 12% Parte III, valor 12% Parte IV y V, valor 16% Exposici√≥n del trabajo realizado Valor 3% Valor 3% Valor 4% Observaciones generales: Cada grupo deber√° crear una Bit√°cora de minutos de cada una de las reuniones, donde en cada una de ellas aparezca el n√∫mero de minuta, fecha, presentes, hora de inicio, agenda, acuerdos y hora de cierre. La primera minuta deber√° contener una distribuci√≥n de tareas por persona y un plan de trabajo que visibilice el alcance de la meta en el plazo. Se adjuntar√° una plantilla de minuta, por si desean considerarla como base: El informe debe crearse en RStudio y exportarse como documento de Word. Este informe debe subirse en la secci√≥n de tareas que se crear√° en el grupo general, pero s√≥lo se le dar√° acceso a las personas que realizaron la primera entrega. No es necesario que se adjunten los documentos Rmd, solo en caso de que estos sean solicitados. Todos los c√°lculos num√©ricos o estad√≠sticos, estimaciones, gr√°ficos de an√°lisis, trabajo con la base de datos, deber√° realizarse en RStudio. La autoevaluaci√≥n, coevaluaci√≥n y exposici√≥n, se rigen bajo las mismas reglas explicadas para la primera entrega. Espesificaciones del proyecto Fase III I Parte: Otras pruebas de hipotesis en R En esta secci√≥n se presentar√°n algunos casos relacionados con pruebas de hip√≥tesis de bondad de ajuste, ANOVA¬¥s e independencia. Deben posterior a la lectura del caso, identificar el tipo de prueba que mejor se adapte a la situaci√≥n. Caso 1 Utilice la base de datos KidsFeet paquete mosaicData como evidencia para para realizar un estudio de normalidad de la longitud del pie (length) de los ni√±os (B: boys) es igual que el de las ni√±as (G: girls). Para emitir su conclusi√≥n, siga el siguiente proceso: Para este ejercicio, explique como la siguiente instrucci√≥n permite agrupar los datos para ni√±os y ni√±as: feetsplit &lt;- split(feet$length,feet$sex) Para cada datset (ni√±os y ni√±as), haga un estudio gr√°fico de la normalidad. Para esto elabore el gr√°fico que contenga tanto la funci√≥n de densidad para cada caso como su respectiva curva normal te√≥rica a partir de su media y desviaci√≥n est√°ndar. ¬øSe puede intuir una posible normalidad para los datos?. explique brevemente. Para cada dataset (ni√±os y ni√±as) elabore un gr√°fico QQ-plot y haga la interpretaci√≥n en cada caso, desde el punto de vista si es posible asumir normalidad. Realice las pruebas formales de normalidad S-W test, A-D test,K-S-L test. ¬øEs posible aplicar D‚ÄôAgostino-Pearson?. En caso de ser posible, realice la prueba. Haga una an√°lisis de la custoris y simetr√≠a de los datos usando las funciones respectivas del paquete moments. No es necesario que realice el gr√°fico tal como se mostr√≥ en clases, solo observe los resultados para una posterior interpretaci√≥n. Caso 2 Realice todo lo solicitado el Caso 1, pero utilizando los datos de biceps de la tabla medidas_cuerpo. Para obtener la base de datos, realice los siguiente: Descargue la base de datos desde la url como sigue: url &lt;- &#39;https://raw.githubusercontent.com/fhernanb/datos/master/medidas_cuerpo&#39; variable &lt;- read.table(file=url, header=T) Recuerde que puede darle el nombre que desee a la variable. Analice cada prueba de normalidad como se solicit√≥ en el Caso 1, utilizando todos los datos de la varible biceps, NO haga separaci√≥n alguna por sexo u otra categor√≠a en este an√°lisis. Una vez realizado todo los c√°lculos de pruebas de normalidad para los Casos 1 y 2, complete la siguiente tabla con la informaci√≥n que corresponda en cada una de las celdas: Caso 3 La siguiente tabla resume los datos de obtenidos de v√≠ctimas de cr√≠menes elegidas al azar (seg√∫n datos del Departamento de Justicia de USA): Homicidio Robo Asalto El criminal era un extra√±o 12 379 727 El criminal era un conocido o pariente 39 106 642 Con los datos anteriores, ¬øser√≠a posible considerarque el tipo de delito es independiente de la condici√≥n del delincuente?, o por el contrario, ¬øexiste alguna relaci√≥n entre el tipo de delito con respecto al quien comete el acto? Use un nivel de significancia de 5%. Adem√°s, complete a partir de los resultados de la prueba, lo que se solicita en la siguiente tabla: Caso 4 Analice con detenimiento la siguiente situaci√≥n: La seguridad de los autom√≥viles se determina mediante diversas pruebas. Una de ellas consiste en hacer chocar un autom√≥vil contra una barrera fija a \\(35 \\textit{ mi/h }\\) con un maniqu√≠ colocado en el asiento del conductor. A una de las medidas utilizadas para cuantificar el impacto del choque sobre el conductor se le conoce como Desaceleraci√≥n de pecho y se mide en unidades de fuerza de gravedad (\\(g\\)). Los valores m√°s grandes indican mayores cantidades de desaceleraci√≥n, las cu√°les pueden provocar lesiones graves en los conductores. La siguiente tabla muestra mediciones de desaceleraciones de pecho obtenidas a partir de pruebas de choques de diferentes tipos de veh√≠culos: Autos compactos Autos medianos Autos grandes 44 41 32 43 49 37 44 43 38 54 41 45 38 47 37 43 44 33 42 37 38 45 34 45 50 43 42 Con los datos anteriores, ¬øes posible considerar que el tama√±o del autom√≥vil puede variar en cuanto a la seguridad de sus pasajeros o por el contrario, es igualmente riesgoso?. Use un nivel de significancia del 5%. Con los datos que imprime la prueba,complete la informaci√≥n requerida en la siguiente tabla: En caso de detectar alguna diferencia en cuanto a la seguridad que puede brindar al tama√±o del veh√≠culo, ¬øes posible en cu√°les existe una verdadera diferencia significativa?. De ser as√≠, realice la prueba que corresponda e interprete el resultado. II Parte: Modelos de regresion lineal En esta secci√≥n se analiz√°n casos relacionados con los modelos de Regresi√≥n Lineal Simple (RLS) y m√∫ltiple (RLM), as√≠ como los modelos de Regresi√≥n no Lineal Simple (RNLS) Caso 5 Cargue los datos EdadPesoGrasas.txt como se muestra a continuaci√≥n: grasas &lt;- read.table(&#39;http://verso.mat.uam.es/~joser.berrendero/datos/EdadPesoGrasa s.txt&#39;, header = TRUE) Para dichos datos, realice lo siguiente: Elabore un an√°lisis de correlaci√≥n completo entre todas las variables y haga una interpretaci√≥n de lo que observa. Debe utilizar al menos un recurso gr√°fico y uno num√©rico. Seleccione las dos variables con mayor coeficiente de correlaci√≥n y genere un modelo RLS de mejor ajuste para ambas variables. Defina claramente qui√©n es la variable respuesta y qui√©n la variable explicativa. Analice la calidad del modelo generado a partir de su coeficiente de correlaci√≥n y de determinaci√≥n. Genere un gr√°fico que muestre tanto los datos de dispersi√≥n como la recta de mejor ajuste. Interprete lo que observa en el gr√°fico. Realice la prueba de normalidad para los residuos e indique si se cumple la condici√≥n. Calcule el intervalo de confianza de 95% para los coeficientes del modelo. Para una edad de 27 a√±os, determine un IC de 95% para \\(\\mu_{Y|x=27}\\) y un intervalo de predicci√≥n para los valores de Y asociados a dicha edad. Interprete el resultado para ambos casos. ¬øEs significativa la linealidad para estas variables?, ¬øes posible considerar dependencia lineal entre estas? Haga la prueba de hip√≥tesis correspondiente para responder a estas preguntas. Caso 6 Sup√≥ngase que el departamento de ventas de una empresa quiere estudiar la influencia que tiene la publicidad a trav√©s de distintos medios de comunicaci√≥n, sobre el n√∫mero de ventas de un producto. Se dispone de un conjunto de datos que contiene los ingresos (en millones) conseguido por ventas en 200 regiones, as√≠ como la cantidad de presupuesto, tambi√©n en millones, destinado a anuncios por radio, TV y peri√≥dicos en cada una de ellas. Los datos se encuentran en el archivo DatosVentas.csv. Para estos datos, realice los siguiente: Instale y cargue las librer√≠as bbmle y DALEX Generacion de los modelos Genere un primer modelo denominado mod0 el cu√°l ser√° un modelo RLS, usando como variables respuesta ventas y como variables exploratoria a tv. Una vez calculados los coeficientes en R para las variables y el intercepto, escriba la ecuaci√≥n del modelo estimado. Genere, usando la funci√≥n lm de R, un primer Modelo RLM donde las variables predictoras o exploratorias sean tv, radio y periodico, la variable respuesta ventas. Escriba la ecuaci√≥n provisional del modelo que se desea determinar. Guarde el modelo en una variable que debe llamar mod1 Una vez calculados los coeficientes en R para las variables y el intercepto, escriba la ecuaci√≥n del modelo estimado. De los 4 coeficientes calculados en R, ¬øcu√°les de ellos son estad√≠sticamente significativos (aportan al modelo) y cu√°les no lo son?. Explique su respuesta, apoy√°ndose en los datos del modelo obtenidos en R. Seguidamente, genere un segundo Modelo RLM usando nuevamente la funci√≥n lm, pero en este caso contemple SOLO las variables cuyos coeficientes resultaron ser estad√≠sticamente significativos en el an√°lisis anterior. Guarde este modelo en una variable que debe llamar mod2. Seg√∫n los datos, ¬øson todos los coeficiente significativos? Justifique su respuesta. Usando los mismo datos, genere un Modelo de RNLM de la forma \\(\\text{ventas} = b_0 + b_1 \\text{tv} + b_2 \\text{radio} + b_3 \\left(\\text{tv} * \\text{radio} \\right)\\). Se recomienda usar nuevamente la funci√≥n lm y guarde el modelo en una varible que deber√° llamar mod3. Una vez que se tengan los datos del modelo, indique si los coeficientes calculados son estad√≠sticamente significativos o no, justificando adecuadamente su respuesta. Seleccionando el mejor modelo Para esta secci√≥n, deber√° seleccionar el mejor modelo entre los 4 ya generados en la I Parte de esta prueba, es decir: mod0, mod1, mod2 y mod3. Para hacer una adecuada escogencia, debe utilizar 4 criterios a saber: Coeficiente de correlaci√≥n y coeficiente de determinaci√≥n Criterio de Informaci√≥n de Akaike (AIC), el cual, representa una medida de la calidad relativa de un modelo estad√≠stico, para un conjunto dado de datos. Como tal, el AIC proporciona un medio para la selecci√≥n del modelo. AIC maneja un trade-off entre la bondad de ajuste del modelo y la complejidad del modelo, basado en el principio de que un mejor modelo debe adem√°s de la precisi√≥n, ser simple en cuanto a que debe utilizar la menor cantidad de variables predictoras (Principio de parsimonia). Los residuales, que est√°n conformados por todas las diferencias entre el valor obtenido en la muestra con respecto al estimado por el modelo. Recuerde que mientras m√°s grande sean los residuales, m√°s se alejan los puntos del modelo y este se vuelve menos confiable. Comparaci√≥n de modelos mediante An√°lisis de Varianzas, es decir, un ANOVA para los modelos. Para este estudio deber√° usar la funci√≥nanova() del paquetestats. Una vez definida la ruta, realice lo siguiente: Calcule los coefiencientes de correlaci√≥n y de determinaci√≥n de los modelos mod0, mod1, mod2 y mod3 y haga una comparaci√≥n entre estos modelos a partir de este criterio, ¬øCu√°l de los 3 modelos es mejor?. Explique su escogencia. Esta informaci√≥n deber√° ser presentada en la siguiente tabla: Tome el modelo 2 (mod2) y explique el significado de los coefiecientes de correlaci√≥n y de determinaci√≥n para ese caso. Usando la funci√≥n AICctab del paquete bbmle, calcule los valores del indicador AIC para cada uno de los modelos y con base en ellos, defina el orden de estos de mejor a peor. El criterio que debe usar es menor AIC, mejor el modelo. Instrucci√≥n para R: AICctab(mod1, mod2, mod3, base = T, delta = T, sort = T, weights = T, nobs = #) Nota: debe completar el par√°metro nobs (n√∫mero de observaciones), seg√∫n la corresponda a la base de datos. El an√°lisis de los residuales se trabajar√° solo con los modelos mod0, mod2 y mod3 debido a que el modelo 1 y 2 resultaron ser similares. Para este trabajo debe usar algunas funciones del paquete DALEX. Seguidamente se detallan los pasos a seguir: Cree los Explain Models exp_lm0 &lt;- explain(mod0, data = base de datos, label = &quot;lm&quot;, y = variable respuesta) exp_lm2 &lt;- explain(mod2, data = base de datos, label = &quot;lm&quot;, y = variablerespuesta) exp_lm3 &lt;- explain(mod3, data = base de datos, label = &quot;lm&quot;, y = variable respuesta) Cree los Performance Models a partir de los Explain Models lm0 &lt;- model_performance(exp_lm0) lm2 &lt;- model_performance(exp_lm2) lm3 &lt;- model_performance(exp_lm3) Grafique ambos modelos plot(lm0,lm2, lm3) Interprete el gr√°fico y escoja el mejor modelo, usando el criterio: curva menor o m√°s baja, es mejor. Explique a partir del gr√°fico, por qu√© este criterio tiene sentido para justificar que un modelo es mejor que otro. Finalmente y como √∫ltimo criterio, realice el an√°lisis de varianza. Para escoger el mejor modelo solamente debe tomar en cuenta el valor de Residual Sum of Squares(RSS), donde a menor valor, mejor es el modelo, es decir, los puntos est√°n m√°s ajustados. Considere la siguiente instrucci√≥n para realizar este an√°lisis: anova(mod0,mod1, mod2, mod3) III PARTE: Modelos de regresion no lineal Caso 7 Para esta secci√≥n deber√° generar dos modelos de RNLS usando los datos de bones de la base de datos jaws, la cu√°l contiene informaci√≥n sobre la longitud de la mand√≠bula de los venados, seg√∫n la edad. var &lt;- read.table(&quot;nombre.txt&quot;,header=T) Luego, construya una gr√°fico de dispersi√≥n para los datos: ggplot(datos,aes(x = ..., y = ...)) + geom_point() # en lugar de geom_point(), tambi√©n puede usar geom_jitter() Usando la funci√≥n nls() del paquete stats, van a generar un modelo de RNLS de la forma \\(y = a(1 - e^{-c \\cdot x} )\\). A este modelo as√≠gnele el nombre de model1. Use como valores iniciales a = 120 y c = 0.064. Escriba la ecuaci√≥n del modelo usando los valores para los par√°metros obetinos en R. Ejemplo de referencia: model2&lt;-nls(bone~a*(1-exp(-c*age)), data = deer,start=list(a=120,c=0.064)) Realice el gr√°fico del modelo 1 (model1) junto con su gr√°fico de dispersi√≥n. Deber√°n crear un segundo modelo a partir de los modelos estudiados en clase. Analice con detenimiento la forma de los datos y haga una selecci√≥n apropiada. Una vez escogido el modelo, haga una proceso de linealizaci√≥n y estime los par√°metros a partir de un modelo de RLS. Use los valores de las estimaciones de los coeficientes del modelo de RLS obtenidos en el punto anterior, como los valores iniciales para generar el modelo de RNLS a partir de la funci√≥n nls(). Genere el Modelo de RNLS y escriba la ecuaci√≥n resultante. Adem√°s, realice el gr√°fico respectivo de este modelo junto con el gr√°fico de dispersi√≥n de los datos. Utilice la funci√≥n anova para comparar ambos modelos. ¬øcu√°l modelos es el mejor?, gr√°ficamente, ¬øse puede llegar a esa misma conclusi√≥n?. Solucion III Parcial de Estadistica Cargamos librer√≠as: library(bbmle) library(DALEX) ## Welcome to DALEX (version: 2.4.3). ## Find examples and detailed introduction at: http://ema.drwhy.ai/ ## Additional features will be available after installation of: ggpubr. ## Use &#39;install_dependencies()&#39; to get all suggested dependencies ## ## Attaching package: &#39;DALEX&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## explain library(stats) Base de datos a trabajar: tv &lt;- c(230.1, 44.5, 17.2, 151.5, 180.8, 8.7, 57.5, 120.2, 8.6, 199.8, 66.1, 214.7, 23.8, 97.5, 204.1, 195.4, 67.8, 281.4, 69.2, 147.3, 218.4, 237.4, 13.2, 228.3, 62.3, 262.9, 142.9, 240.1, 248.8, 70.6, 292.9, 112.9, 97.2, 265.6, 95.7, 290.7, 266.9, 74.7, 43.1, 228, 202.5, 177, 293.6, 206.9, 25.1, 175.1, 89.7, 239.9, 227.2, 66.9, 199.8, 100.4, 216.4, 182.6, 262.7, 198.9, 7.3, 136.2, 210.8, 210.7, 53.5, 261.3, 239.3, 102.7, 131.1, 69, 31.5, 139.3, 237.4, 216.8, 199.1, 109.8, 26.8, 129.4, 213.4, 16.9, 27.5, 120.5, 5.4, 116, 76.4, 239.8, 75.3, 68.4, 213.5, 193.2, 76.3, 110.7, 88.3, 109.8, 134.3, 28.6, 217.7, 250.9, 107.4, 163.3, 197.6, 184.9, 289.7, 135.2, 222.4, 296.4, 280.2, 187.9, 238.2, 137.9, 25, 90.4, 13.1, 255.4, 225.8, 241.7, 175.7, 209.6, 78.2, 75.1, 139.2, 76.4, 125.7, 19.4, 141.3, 18.8, 224, 123.1, 229.5, 87.2, 7.8, 80.2, 220.3, 59.6, 0.7, 265.2, 8.4, 219.8, 36.9, 48.3, 25.6, 273.7, 43, 184.9, 73.4, 193.7, 220.5, 104.6, 96.2, 140.3, 240.1, 243.2, 38, 44.7, 280.7, 121, 197.6, 171.3, 187.8, 4.1, 93.9, 149.8, 11.7, 131.7, 172.5, 85.7, 188.4, 163.5, 117.2, 234.5, 17.9, 206.8, 215.4, 284.3, 50, 164.5, 19.6, 168.4, 222.4, 276.9, 248.4, 170.2, 276.7, 165.6, 156.6, 218.5, 56.2, 287.6, 253.8, 205, 139.5, 191.1, 286, 18.7, 39.5, 75.5, 17.2, 166.8, 149.7, 38.2, 94.2, 177, 283.6, 232.1) radio &lt;- c(37.8, 39.3, 45.9, 41.3, 10.8, 48.9, 32.8, 19.6, 2.1, 2.6, 5.8, 24, 35.1, 7.6, 32.9, 47.7, 36.6, 39.6, 20.5, 23.9, 27.7, 5.1, 15.9, 16.9, 12.6, 3.5, 29.3, 16.7, 27.1, 16, 28.3, 17.4, 1.5, 20, 1.4, 4.1, 43.8, 49.4, 26.7, 37.7, 22.3, 33.4, 27.7, 8.4, 25.7, 22.5, 9.9, 41.5, 15.8, 11.7, 3.1, 9.6, 41.7, 46.2, 28.8, 49.4, 28.1, 19.2, 49.6, 29.5, 2, 42.7, 15.5, 29.6, 42.8, 9.3, 24.6, 14.5, 27.5, 43.9, 30.6, 14.3, 33, 5.7, 24.6, 43.7, 1.6, 28.5, 29.9, 7.7, 26.7, 4.1, 20.3, 44.5, 43, 18.4, 27.5, 40.6, 25.5, 47.8, 4.9, 1.5, 33.5, 36.5, 14, 31.6, 3.5, 21, 42.3, 41.7, 4.3, 36.3, 10.1, 17.2, 34.3, 46.4, 11, 0.3, 0.4, 26.9, 8.2, 38, 15.4, 20.6, 46.8, 35, 14.3, 0.8, 36.9, 16, 26.8, 21.7, 2.4, 34.6, 32.3, 11.8, 38.9, 0, 49, 12, 39.6, 2.9, 27.2, 33.5, 38.6, 47, 39, 28.9, 25.9, 43.9, 17, 35.4, 33.2, 5.7, 14.8, 1.9, 7.3, 49, 40.3, 25.8, 13.9, 8.4, 23.3, 39.7, 21.1, 11.6, 43.5, 1.3, 36.9, 18.4, 18.1, 35.8, 18.1, 36.8, 14.7, 3.4, 37.6, 5.2, 23.6, 10.6, 11.6, 20.9, 20.1, 7.1, 3.4, 48.9, 30.2, 7.8, 2.3, 10, 2.6, 5.4, 5.7, 43, 21.3, 45.1, 2.1, 28.7, 13.9, 12.1, 41.1, 10.8, 4.1, 42, 35.6, 3.7, 4.9, 9.3, 42, 8.6) periodico &lt;- c(69.2, 45.1, 69.3, 58.5, 58.4, 75, 23.5, 11.6, 1, 21.2, 24.2, 4, 65.9, 7.2, 46, 52.9, 114, 55.8, 18.3, 19.1, 53.4, 23.5, 49.6, 26.2, 18.3, 19.5, 12.6, 22.9, 22.9, 40.8, 43.2, 38.6, 30, 0.3, 7.4, 8.5, 5, 45.7, 35.1, 32, 31.6, 38.7, 1.8, 26.4, 43.3, 31.5, 35.7, 18.5, 49.9, 36.8, 34.6, 3.6, 39.6, 58.7, 15.9, 60, 41.4, 16.6, 37.7, 9.3, 21.4, 54.7, 27.3, 8.4, 28.9, 0.9, 2.2, 10.2, 11, 27.2, 38.7, 31.7, 19.3, 31.3, 13.1, 89.4, 20.7, 14.2, 9.4, 23.1, 22.3, 36.9, 32.5, 35.6, 33.8, 65.7, 16, 63.2, 73.4, 51.4, 9.3, 33, 59, 72.3, 10.9, 52.9, 5.9, 22, 51.2, 45.9, 49.8, 100.9, 21.4, 17.9, 5.3, 59, 29.7, 23.2, 25.6, 5.5, 56.5, 23.2, 2.4, 10.7, 34.5, 52.7, 25.6, 14.8, 79.2, 22.3, 46.2, 50.4, 15.6, 12.4, 74.2, 25.9, 50.6, 9.2, 3.2, 43.1, 8.7, 43, 2.1, 45.1, 65.6, 8.5, 9.3, 59.7, 20.5, 1.7, 12.9, 75.6, 37.9, 34.4, 38.9, 9, 8.7, 44.3, 11.9, 20.6, 37, 48.7, 14.2, 37.7, 9.5, 5.7, 50.5, 24.3, 45.2, 34.6, 30.7, 49.3, 25.6, 7.4, 5.4, 84.8, 21.6, 19.4, 57.6, 6.4, 18.4, 47.4, 17, 12.8, 13.1, 41.8, 20.3, 35.2, 23.7, 17.6, 8.3, 27.4, 29.7, 71.8, 30, 19.6, 26.6, 18.2, 3.7, 23.4, 5.8, 6, 31.6, 3.6, 6, 13.8, 8.1, 6.4, 66.2, 8.7) ventas &lt;- c(22.1, 10.4, 9.3, 18.5, 12.9, 7.2, 11.8, 13.2, 4.8, 10.6, 8.6, 17.4, 9.2, 9.7, 19, 22.4, 12.5, 24.4, 11.3, 14.6, 18, 12.5, 5.6, 15.5, 9.7, 12, 15, 15.9, 18.9, 10.5, 21.4, 11.9, 9.6, 17.4, 9.5, 12.8, 25.4, 14.7, 10.1, 21.5, 16.6, 17.1, 20.7, 12.9, 8.5, 14.9, 10.6, 23.2, 14.8, 9.7, 11.4, 10.7, 22.6, 21.2, 20.2, 23.7, 5.5, 13.2, 23.8, 18.4, 8.1, 24.2, 15.7, 14, 18, 9.3, 9.5, 13.4, 18.9, 22.3, 18.3, 12.4, 8.8, 11, 17, 8.7, 6.9, 14.2, 5.3, 11, 11.8, 12.3, 11.3, 13.6, 21.7, 15.2, 12, 16, 12.9, 16.7, 11.2, 7.3, 19.4, 22.2, 11.5, 16.9, 11.7, 15.5, 25.4, 17.2, 11.7, 23.8, 14.8, 14.7, 20.7, 19.2, 7.2, 8.7, 5.3, 19.8, 13.4, 21.8, 14.1, 15.9, 14.6, 12.6, 12.2, 9.4, 15.9, 6.6, 15.5, 7, 11.6, 15.2, 19.7, 10.6, 6.6, 8.8, 24.7, 9.7, 1.6, 12.7, 5.7, 19.6, 10.8, 11.6, 9.5, 20.8, 9.6, 20.7, 10.9, 19.2, 20.1, 10.4, 11.4, 10.3, 13.2, 25.4, 10.9, 10.1, 16.1, 11.6, 16.6, 19, 15.6, 3.2, 15.3, 10.1, 7.3, 12.9, 14.4, 13.3, 14.9, 18, 11.9, 11.9, 8, 12.2, 17.1, 15, 8.4, 14.5, 7.6, 11.7, 11.5, 27, 20.2, 11.7, 11.8, 12.6, 10.5, 12.2, 8.7, 26.2, 17.6, 22.6, 10.3, 17.3, 15.9, 6.7, 10.8, 9.9, 5.9, 19.6, 17.3, 7.6, 9.7, 12.8, 25.5, 13.4) datos.ventas &lt;- data.frame(tv, radio, periodico, ventas) Exportamos la base de datos, para facilit√°rsela a los estudiantes: #write.csv(datos.ventas, file=&quot;DatosVentas.csv&quot;) La idea es generar 3 modelos y excoger el que mejor explica los datos Modelo 0: Regresi√≥n lineal simple mod0 &lt;- lm(ventas ~ tv , data = datos.ventas) summary(mod0) ## ## Call: ## lm(formula = ventas ~ tv, data = datos.ventas) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.3860 -1.9545 -0.1913 2.0671 7.2124 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.032594 0.457843 15.36 &lt;2e-16 *** ## tv 0.047537 0.002691 17.67 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.259 on 198 degrees of freedom ## Multiple R-squared: 0.6119, Adjusted R-squared: 0.6099 ## F-statistic: 312.1 on 1 and 198 DF, p-value: &lt; 2.2e-16 Ecuaci√≥n del modelo 0:\\(\\text{ventas} = 7.032594 + + 0.047537 \\cdot \\text{tv}\\) Modelo 1: Regresion lineal multiple con todas las variables Seguidamente se crea una modelo de regresi√≥n Lineal M√∫ltiple que toma en consideraci√≥n a todas las variables. mod1 &lt;- lm(ventas ~ tv + radio + periodico, data = datos.ventas) summary(mod1) ## ## Call: ## lm(formula = ventas ~ tv + radio + periodico, data = datos.ventas) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.8277 -0.8908 0.2418 1.1893 2.8292 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.938889 0.311908 9.422 &lt;2e-16 *** ## tv 0.045765 0.001395 32.809 &lt;2e-16 *** ## radio 0.188530 0.008611 21.893 &lt;2e-16 *** ## periodico -0.001037 0.005871 -0.177 0.86 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.686 on 196 degrees of freedom ## Multiple R-squared: 0.8972, Adjusted R-squared: 0.8956 ## F-statistic: 570.3 on 3 and 196 DF, p-value: &lt; 2.2e-16 Ecuaci√≥n del modelo 1: \\(\\text{ventas} = 2.9389 + 0.0448 \\text{tv} + 0.1885 \\text{radio} - 0.001 \\text{periodico}\\) Se identifica por el p-value que el coeficiente parcial de variable periodico no contribuye de forma significativa al modelo, por lo que se concluye que las variables tv y radio est√°n relacionadas con la cantidad de ventas. Modelo 2: Regresion Lineal Multiple con Variables TV y Radio Seguidamente se crea el segundo modelo: mod2 &lt;- lm(ventas ~ tv + radio , data = datos.ventas) summary(mod2) ## ## Call: ## lm(formula = ventas ~ tv + radio, data = datos.ventas) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.7977 -0.8752 0.2422 1.1708 2.8328 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.92110 0.29449 9.919 &lt;2e-16 *** ## tv 0.04575 0.00139 32.909 &lt;2e-16 *** ## radio 0.18799 0.00804 23.382 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.681 on 197 degrees of freedom ## Multiple R-squared: 0.8972, Adjusted R-squared: 0.8962 ## F-statistic: 859.6 on 2 and 197 DF, p-value: &lt; 2.2e-16 Ecuaci√≥n del modelo 2: \\(\\text{ventas} = = 2.9211 + 0.04575 \\text{tv} + 0.18799 \\text{radio}\\) Note que el \\(R^2\\) mejor√≥ de manera importante 13.2.1 Modelo 3: Regresion no Lineal Multiple (Con Interacci√≥n) El siguiente modelo agrega al modelo de regresi√≥n lineal m√∫ltiple, un componente de interacci√≥n entre las variables. mod3 &lt;- lm(ventas ~ tv + radio + tv*radio , data = datos.ventas) summary(mod3) ## ## Call: ## lm(formula = ventas ~ tv + radio + tv * radio, data = datos.ventas) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.3366 -0.4028 0.1831 0.5948 1.5246 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.750e+00 2.479e-01 27.233 &lt;2e-16 *** ## tv 1.910e-02 1.504e-03 12.699 &lt;2e-16 *** ## radio 2.886e-02 8.905e-03 3.241 0.0014 ** ## tv:radio 1.086e-03 5.242e-05 20.727 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9435 on 196 degrees of freedom ## Multiple R-squared: 0.9678, Adjusted R-squared: 0.9673 ## F-statistic: 1963 on 3 and 196 DF, p-value: &lt; 2.2e-16 Otra forma de hacerlo, es generando una nueva columna a la tabla: vector &lt;- NULL vector[seq(1,200,1)] &lt;- cbind(c(1)) datos.ventas2 &lt;- cbind(vector, datos.ventas[ ,c(1, 2)], datos.ventas[ ,1]*datos.ventas[ ,2], datos.ventas$ventas ) names(datos.ventas2) ## [1] &quot;vector&quot; ## [2] &quot;tv&quot; ## [3] &quot;radio&quot; ## [4] &quot;datos.ventas[, 1] * datos.ventas[, 2]&quot; ## [5] &quot;datos.ventas$ventas&quot; ## [1] &quot;vector&quot; ## [2] &quot;tv&quot; ## [3] &quot;radio&quot; ## [4] &quot;datos.ventas[, 1] * datos.ventas[, 2]&quot; ## [5] &quot;datos.ventas$ventas&quot; names (datos.ventas2)[1] = &quot;Unos&quot; names (datos.ventas2)[4] = &quot;tvradio&quot; names (datos.ventas2)[5] = &quot;ventas&quot; names(datos.ventas2) ## [1] &quot;Unos&quot; &quot;tv&quot; &quot;radio&quot; &quot;tvradio&quot; &quot;ventas&quot; Seguidamente se genera el modelo inclouyendo la interacci√≥n: mod3 &lt;- lm(ventas ~ tv + radio + tvradio , data = datos.ventas2) summary(mod3) ## ## Call: ## lm(formula = ventas ~ tv + radio + tvradio, data = datos.ventas2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.3366 -0.4028 0.1831 0.5948 1.5246 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.750e+00 2.479e-01 27.233 &lt;2e-16 *** ## tv 1.910e-02 1.504e-03 12.699 &lt;2e-16 *** ## radio 2.886e-02 8.905e-03 3.241 0.0014 ** ## tvradio 1.086e-03 5.242e-05 20.727 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9435 on 196 degrees of freedom ## Multiple R-squared: 0.9678, Adjusted R-squared: 0.9673 ## F-statistic: 1963 on 3 and 196 DF, p-value: &lt; 2.2e-16 Ecuaci√≥n del modelo 3: \\(\\text{ventas} = = 6.75 + 0.0191 \\text{tv} + 0.0289 \\text{radio} + 0.0011 \\text{tvradio}\\) # Modelo 1 summary(mod0)$r.squared ## [1] 0.6118751 sqrt(summary(mod0)$r.squared) ## [1] 0.7822244 # Modelo 1 summary(mod1)$r.squared ## [1] 0.8972106 sqrt(summary(mod1)$r.squared) ## [1] 0.947212 # Modelo 2 summary(mod2)$r.squared ## [1] 0.8971943 sqrt(summary(mod2)$r.squared) ## [1] 0.9472034 # Modelo 3 summary(mod3)$r.squared ## [1] 0.9677905 sqrt(summary(mod3)$r.squared) ## [1] 0.9837635 El estudiante debe dar una interpretaci√≥n. El mejor modelo seg√∫n \\(R^2\\) y \\(R\\) es el Modelo 3, sin embargo no discrimina entre los modelos 1 y 2, pero el modelo 0 parece ser el peor de todos. Seguidamente, hacemos una comparaci√≥n entre ambos modelos usando sus residuos. Use el comando: AICctab(mod0, mod1, mod2, mod3, base = T, delta = T, sort= T, weights = T, nobs = 200) # Paquete bbmle AICctab(mod0, mod1, mod2, mod3, base = T, delta = T, sort = T, weights = T, nobs = 200) ## AICc dAICc df weight ## mod3 550.6 0.0 5 1 ## mod2 780.6 230.0 4 &lt;0.001 ## mod1 782.7 232.1 5 &lt;0.001 ## mod0 1044.2 493.6 3 &lt;0.001 Note que sigue siendo el modelo 3 el mejor, seguido por el modelo 2. Tercera comparaci√≥n #paquete DALEX #exp_lm1 &lt;- explain(mod1, data = datos.ventas, label = &quot;lm&quot;, y =datos.ventas$ventas) exp_lm0 &lt;- explain(mod0, data = datos.ventas, label = &quot;lm&quot;, y = datos.ventas$ventas) ## Preparation of a new explainer is initiated ## -&gt; model label : lm ## -&gt; data : 200 rows 4 cols ## -&gt; target variable : 200 values ## -&gt; predict function : yhat.lm will be used ( default ) ## -&gt; predicted values : No value for predict function target column. ( default ) ## -&gt; model_info : package stats , ver. 4.4.1 , task regression ( default ) ## -&gt; predicted values : numerical, min = 7.065869 , mean = 14.0225 , max = 21.12245 ## -&gt; residual function : difference between y and yhat ( default ) ## -&gt; residuals : numerical, min = -8.385982 , mean = -3.250733e-15 , max = 7.212369 ## A new explainer has been created! exp_lm2 &lt;- explain(mod2, data = datos.ventas, label = &quot;lm&quot;, y = datos.ventas$ventas) ## Preparation of a new explainer is initiated ## -&gt; model label : lm ## -&gt; data : 200 rows 4 cols ## -&gt; target variable : 200 values ## -&gt; predict function : yhat.lm will be used ( default ) ## -&gt; predicted values : No value for predict function target column. ( default ) ## -&gt; model_info : package stats , ver. 4.4.1 , task regression ( default ) ## -&gt; predicted values : numerical, min = 3.595686 , mean = 14.0225 , max = 24.78353 ## -&gt; residual function : difference between y and yhat ( default ) ## -&gt; residuals : numerical, min = -8.7977 , mean = -6.834533e-15 , max = 2.832837 ## A new explainer has been created! exp_lm3 &lt;- explain(mod3, data = datos.ventas2, label = &quot;lm&quot;, y = datos.ventas2$ventas) ## Preparation of a new explainer is initiated ## -&gt; model label : lm ## -&gt; data : 200 rows 5 cols ## -&gt; target variable : 200 values ## -&gt; predict function : yhat.lm will be used ( default ) ## -&gt; predicted values : No value for predict function target column. ( default ) ## -&gt; model_info : package stats , ver. 4.4.1 , task regression ( default ) ## -&gt; predicted values : numerical, min = 6.994718 , mean = 14.0225 , max = 28.16216 ## -&gt; residual function : difference between y and yhat ( default ) ## -&gt; residuals : numerical, min = -6.336578 , mean = -4.494044e-15 , max = 1.52462 ## A new explainer has been created! class(mod1) ## [1] &quot;lm&quot; Se crea un Model Performance para cada modelo, a partir de los Model Explainer ya creados: mp_lm0 &lt;- model_performance(exp_lm0) mp_lm1 &lt;- model_performance(exp_lm2) mp_lm2 &lt;- model_performance(exp_lm3) Finalmente, se grafican los modelos de desempe√±o: plot( mp_lm1, mp_lm2, mp_lm0) Finalmente, se realiza la prueba de anova stats::anova(mod0, mod1, mod2, mod3, test=&quot;F&quot;) ## Analysis of Variance Table ## ## Model 1: ventas ~ tv ## Model 2: ventas ~ tv + radio + periodico ## Model 3: ventas ~ tv + radio ## Model 4: ventas ~ tv + radio + tvradio ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 198 2102.53 ## 2 196 556.83 2 1545.71 272.0407 &lt;2e-16 *** ## 3 197 556.91 -1 -0.09 0.0312 0.8599 ## 4 196 174.48 1 382.43 134.6139 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
